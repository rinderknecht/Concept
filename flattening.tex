\section{Aplatissement}
\label{sec:flattening}
\index{pile!aplatissement|(}

Concevons une fonction~\fun{flat/1}\index{flat@\fun{flat/1}} telle que
l'appel \(\fun{flat}(s)\), où \(s\)~est une pile, est réécrit en une
pile contenant seulement les éléments de~\(s\) qui ne sont pas
eux-mêmes des piles, dans le même ordre d'écriture. Si \(s\)~ne
contient aucune pile, alors \(\fun{flat}(s) \equiv s\). Passons en
revue quelques exemples\index{pile!aplatissement!exemple} pour saisir
le concept:
\begin{equation*}
\fun{flat}(\el) \twoheadrightarrow \el; \quad
\fun{flat}([\el,[\el]]) \twoheadrightarrow \el;\quad
\fun{flat}([\el,[1,[2,\el],3],\el]) \twoheadrightarrow [1,2,3].
\end{equation*}
Tout d'abord, concentrons-nous sur l'écriture des membres gauches des
règles, de façon à assurer que notre définition est \emph{complète}
(toutes les données sont filtrées). Une pile est vide ou non. Si elle
ne l'est pas, le problème en question apparaît clairement: nous devons
distinguer les éléments qui sont eux-mêmes des piles. Cela est
simplement réalisé en ordonnant les motifs de telle sorte que \(\el\)
et \(\cons{x}{s}\) \emph{en tant qu'éléments} soient écrits avant le
cas général~\(y\):\index{flat@\fun{flat/1}|(}
\begin{equation*}
\begin{array}{r@{\;}l@{\;}l}
\fun{flat}(\el)                   & \xrightarrow{\smash{\psi}}   & \fbcode{CCCCCCC}\,;\\
\fun{flat}(\cons{\el}{t})         & \xrightarrow{\smash{\omega}} & \fbcode{CCCCCCC}\,;\\
\fun{flat}(\cons{\cons{x}{s}}{t}) & \xrightarrow{\smash{\gamma}} & \fbcode{CCCCCCC}\,;\\
\fun{flat}(\cons{y}{t})           & \xrightarrow{\smash{\delta}} & \fbcode{CCCCCCC}\,.
\end{array}
\end{equation*}
Nous savons que \(y\)~dans la dernière ligne n'est pas une pile, sinon
l'avant-dernier ou l'antépénultième motif l'aurait filtrée. Presque tous les mem\-bres droits sont aisés à deviner maintenant:
\begin{equation*}
\begin{array}{r@{\;}l@{\;}l}
\fun{flat}(\el)                   & \xrightarrow{\smash{\psi}}   & \el;\\
\fun{flat}(\cons{\el}{t})         & \xrightarrow{\smash{\omega}} & \fun{flat}(t);\\
\fun{flat}(\cons{\cons{x}{s}}{t}) & \xrightarrow{\smash{\gamma}} & \fbcode{CCCCCCC}\,;\\
\fun{flat}(\cons{y}{t})           & \xrightarrow{\smash{\delta}} & \cons{y}{\fun{flat}(t)}.
\end{array}
\end{equation*}
\index{flat@\fun{flat/1}|)}La conception du membre droit restant peut
être guidée selon deux principes légèrement différents. Si nous
regardons de nouveau les définitions de~\fun{rev\(_0\)/1}
\index{rev0@\fun{rev\(_0\)/1}|(} et~\fun{rev/1}\index{rev@\fun{rev/1}}
à la section~\ref{sec:reversal}, nous comprenons que la première avait
été conçue avec le résultat en tête, comme si les flèches atteignaient
directement une valeur qui est alors décomposée en fonction des
variables du membre gauche correspondant:
\begin{equation*}
\fun{rev}_0(\el) \rightarrow \el;\qquad
\fun{rev}_0(\cons{x}{s}) \rightarrow \fun{cat}(\fun{rev}_0(s),[x]).
\end{equation*}
\index{rev0@\fun{rev\(_0\)/1}|)}Par contraste,
\fun{rev/1}\index{rev@\fun{rev/1}} compte sur une autre fonction,
\fun{rcat/2}\index{rcat@\fun{rcat/2}}, pour accumuler des résultats
partiels, comme si les flèches ne parcourraient qu'une courte
distance, ne contribuant que très peu et indirectement à la valeur
finale, typiquement via un accumulateur:
\begin{equation*}
\fun{rev}(s) \xrightarrow{\smash{\epsilon}} \fun{rcat}(s,\el).\quad\;\;
\fun{rcat}(\el,t) \xrightarrow{\smash{\zeta}} t;\quad\;\;
\fun{rcat}(\cons{x}{s},t) \xrightarrow{\smash{\eta}}
\fun{rcat}(s,\cons{x}{t}).
\end{equation*}
La première approche pourrait être appelée \emph{conception à grands
  pas}\index{conception!grands pas}, et l'autre \emph{conception à
  petits pas}\index{conception!petits pas}. Un autre point de vue
consiste à voir que la première utilise le contexte de l'appel
récursif pour construire la valeur, alors que la seconde repose
exclusivement sur un argument (l'accumulateur\index{langage
  fonctionnel!accumulateur}) et l'appel récursif est terminal. Par
exemple, à la section~\ref{sec:skipping}, nous trouvons que la
définition de \fun{sfst/2}\index{sfst@\fun{sfst/2}} suit un modèle à
grands pas, alors que \fun{sfst\(_0\)/2}\index{sfst@\fun{sfst/2}} est
un cas de modèle à petits pas.

\paragraph{Conception à grand pas}
\index{conception!grands pas}
\index{diviser pour régner}
\label{big-step}

Abstraitement, une conception à grands pas signifie que les membres
droits sont constitués d'appels récursifs sur des sous-structures, par
exemple, dans le cas de la règle~\(\gamma\), les sous-structures de
\(\cons{\cons{x}{s}}{t}\) sont~\(x\), \(s\), \(t\) et
\(\cons{x}{s}\). En réfléchissant à la manière dont la valeur peut
être composée à l'aide de
\(\fun{flat}(\cons{x}{s})\)\index{flat@\fun{flat/1}} et
\(\fun{flat}(t)\), nous obtenons une nouvelle version,
\fun{flat\(_0\)/1}\index{flat0@\fun{flat$_0$/1}}, à la
\fig~\vref{fig:flat0}.
\begin{figure}
\begin{equation*}
\boxed{%
\begin{array}{r@{\;}l@{\;}l}
\fun{flat}_0(\el)                   & \xrightarrow{\smash{\psi}}
                                    & \el;\\
\fun{flat}_0(\cons{\el}{t})         & \xrightarrow{\smash{\omega}}
                                    & \fun{flat}_0(t);\\
\fun{flat}_0(\cons{\cons{x}{s}}{t}) & \xrightarrow{\smash{\gamma}}
        & \fun{cat}(\fun{flat}_0(\cons{x}{s}),\fun{flat}_0(t));\\
\fun{flat}_0(\cons{y}{t})           & \xrightarrow{\smash{\delta}}
                                    & \cons{y}{\fun{flat}_0(t)}.
\end{array}}
\end{equation*}
\caption{Aplatir une pile avec \fun{flat\(_0\)/1}}
\label{fig:flat0}
\index{pile!aplatissement!définition}
\end{figure}

Considérons un exemple à la \fig~\vref{fig:flat0_ex},
\begin{figure}
\begin{equation*}
\boxed{%
\begin{array}{r@{\;}l@{\;}l}
\fun{flat}_0([\el,[[1],2],3])
& \xrightarrow{\smash{\omega}}
& \fun{flat}_0([[[1],2],3])\\
& \xrightarrow{\smash{\gamma}}
& \fun{cat}(\underline{\fun{flat}_0([[1],2])},\fun{flat}_0([3]))\\
& \xrightarrow{\smash{\gamma}}
& \fun{cat}(\fun{cat}(\underline{\fun{flat}_0([1])},\fun{flat}_0([2])),\fun{flat}_0([3]))\\
& \xrightarrow{\smash{\delta}}
& \fun{cat}(\fun{cat}([1|\underline{\fun{flat}_0(\el)}],\fun{flat}_0([2])),\fun{flat}_0([3]))\\
& \xrightarrow{\smash{\psi}}
& \fun{cat}(\fun{cat}([1],\underline{\fun{flat}_0([2])}),\fun{flat}_0([3]))\\
& \xrightarrow{\smash{\delta}}
& \fun{cat}(\fun{cat}([1],[2|\underline{\fun{flat}_0(\el)}]),\fun{flat}_0([3]))\\
& \xrightarrow{\smash{\psi}}
& \fun{cat}(\fun{cat}([1],[2]),\underline{\fun{flat}_0([3])})\\
& \xrightarrow{\smash{\delta}}
& \fun{cat}(\fun{cat}([1],[2]),[3|\underline{\fun{flat}_0(\el)}])\\
& \xrightarrow{\smash{\psi}}
& \fun{cat}(\fun{cat}([1],[2]),[3])\\
& \twoheadrightarrow & [1,2,3].
\end{array}
}
\end{equation*}
\caption{\(\fun{flat}_0([\el,[[1],2],3]) \twoheadrightarrow [1,2,3]\)}
\label{fig:flat0_ex}
\index{pile!aplatissement!exemple}
\end{figure}
où l'appel qui va être réécrit juste après est souligné en cas
d'ambiguïté. Remarquons que la stratégie d'évaluation par
valeurs\index{langage fonctionnel!appel par valeurs}
(section~\ref{sec:functional}) ne spécifie pas l'ordre d'évaluation
des arguments d'un appel: dans notre exemple, nous avons retardé
l'évaluation de \(\fun{cat}([1],[2])\) \index{cat@\fun{cat/2}|(}
jusqu'à ce que celle de
\fun{flat\(_0\)/1}\index{flat0@\fun{flat$_0$/1}} soit terminée. Quand
nous déduisons une récurrence ou une trace compliquée, nous pourrions
à la place tenter de compter le nombre de fois que chaque règle est
utilisée, pour toute évaluation. Un appel à
\fun{flat\(_0\)/1}\index{flat0@\fun{flat$_0$/1}} implique
\begin{itemize}

  \item utiliser la règle~\(\omega\) une seule fois pour chaque pile
    donnée à l'origine;

  \item utiliser la règle~\(\psi\) une fois que le fond que la pile
    originelle est atteint \emph{et} une fois pour chaque pile vide
    \(t\) à la règle~\(\gamma\);

  \item utiliser la règle~\(\delta\) une fois pour chaque élément qui
    n'est pas une pile lui-même;

  \item utiliser la règle~\(\gamma\) une fois pour chaque pile
    imbriquée non-vide;

  \item appeler \fun{cat/2}\index{cat@\fun{cat/2}|)} une fois pour
    chaque pile imbriquée non-vide.

\end{itemize}
Nous connaissons maintenant les paramètres du coût:
\begin{enumerate}

  \item la longueur de\index{flat0@\fun{flat$_0$/1}}
    \(\fun{flat}_0(s)\), notée~\(n\);

  \item le nombre de piles imbriquées non-vides données, dénoté
    par~\(\Gamma\);

  \item le nombre de piles imbriquées vides, dénoté par~\(\Omega\).

\end{enumerate}
Notons que le coût ici dépend de la taille du résultat au lieu de
celle des données. Nous pouvons, par ailleurs, reformuler l'analyse
ci-dessus dans les termes suivants: la règle~\(\psi\) est employée \(1
+ \Gamma\)~fois, la règle~\(\omega\) est utilisée \(\Omega\)~fois, la
règle~\(\gamma\) est appliquée \(\Gamma\)~fois, la règle~\(\delta\)
est employée \(n\)~fois. Donc le coût dû seulement aux règles
définissant \fun{flat\(_0\)/1}\index{flat0@\fun{flat$_0$/1}} est \(1 +
n + \Omega + 2\Gamma\). Par exemple, dans le cas de
\(\fun{flat}_0([\el,[[1],2],3])\), nous trouvons la valeur correcte
\(1 + 3 + 1 + 2 \cdot 2 = 9 = \len{\omega\gamma^2(\delta\psi)^3}\).

En ce qui concerne le coût des appels à \fun{cat/2}, son associativité
\index{cat@\fun{cat/2}} établie à la page~\pageref{proof_assoc_cat} et
l'équation~\eqref{ineq_cat_assoc} \vpageref{ineq_cat_assoc} suggèrent
qu'il existe des configurations des données de
\fun{flat\(_0\)/1}\index{flat0@\fun{flat$_0$/1}} qui mènent à des
coûts supérieurs, quand les paramètres \(n\), \(\Omega\) et~\(\Gamma\)
sont fixés. Un schéma d'appel semblable à
\fun{cat/2}\index{cat@\fun{cat/2}} avec un coût quadratique est aussi
produit en appelant \fun{rev\(_0\)/1}\index{rev0@\fun{rev\(_0\)/1}},
comme on peut le vérifier à la \fig~\vref{fig:rev0_321}, après la
première application de la règle~\(\alpha\). Le membre droit de la
règle~\(\gamma\) est
\(\fun{cat}(\fun{flat}_0(\cons{x}{s}),\fun{flat}_0(t))\)
\index{flat0@\fun{flat$_0$/1}} et il implique que les arguments de
\fun{cat/2}\index{cat@\fun{cat/2}} peuvent être des piles vides.

Étant donnés un nombre \(\Gamma\) de n{\oe}uds \fun{cat},
\(n\)~n{\oe}uds qui ne sont pas des piles (\(x_1\), \dots, \(x_n\)),
quels sont les arbres de syntaxe abstraite conduisant à un extremum du
coût? Nous avons trouvé que le coût minimum de
\fun{cat/2}\index{cat@\fun{cat/2}} est obtenu lorsque tous les
n{\oe}uds \fun{cat} constituent la \emph{branche}\index{arbre!branche}
la plus à droite dans l'arbre de syntaxe abstraire. (Une branche est
une suite de n{\oe}uds où l'un est le parent du suivant, de la racine
à une feuille.) Si \(\Omega \geqslant \Gamma\), la configuration
minimale est montrée à la \fig~\ref{fig:cat_min1}
\begin{figure}
\centering
\subfloat[Si \(\Omega \geqslant \Gamma\), le minimum est \(\Gamma\).
\label{fig:cat_min1}]{\includegraphics[bb=66 660 200 722]{cat_min1}}
\quad
\subfloat[Si \(\Omega < \Gamma\), le minimum est \(2\Gamma-\Omega\).
\label{fig:cat_min2}]{\includegraphics[bb=70 643 230 721]{cat_min2}}
\caption{Coûts minimums pour la concaténation avec \fun{flat\(_0\)/1}}
\label{fig:cat_min}
\end{figure}
(au moins une pile vide doit être placée dans toute pile non-vide dont
l'aplatissement résulte en une pile vide). Sinon, l'arbre de syntaxe
abstraite de coût minimum est donné à la \fig~\ref{fig:cat_min2}, où
toutes les piles vides disponibles (\(\Omega\)) sont utilisées par les
n{\oe}uds \fun{cat} les plus profonds. Nous en concluons que le coût
minimum\index{pile!aplatissement!coût minimum}
est\index{flat0@$\B{\fun{flat}_0}{n}$}
\(\B{\fun{flat}_0}{n,\Omega,\Gamma} = 1 + n + \Omega + 3\Gamma +
\min\{\Omega,\Gamma\}\).

Le coût maximum\index{pile!aplatissement!coût maximum} à la
\fig~\ref{fig:cat_max}
\begin{figure}
\centering
\subfloat[Coût maximum \((n+1)\Gamma\)\label{fig:cat_max}]{
\includegraphics[bb=71 660 188 721]{cat_max}}
\qquad
\subfloat[$\protect\fun{flat}(\cons{\cons{x}{s}}{t})$\label{fig:lift1}]%
{\includegraphics[bb=55 661 122 721]{flat_embed}}
\qquad
\subfloat[$\protect\fun{flat}(\cons{x,s}{t})$\label{fig:lift2}]%
{\includegraphics[bb=57 661 120 721]{flat_lift}}
\caption{Coût maximum et rotation à droite}
\end{figure}
se présente pour le symétrique de l'arbre à la
\fig~\ref{fig:cat_min1}. Nous
avons\index{flat0@$\W{\fun{flat}_0}{n,\Omega,\Gamma}$}
\(\W{\fun{flat}_0}{n,\Omega,\Gamma} = \Omega + (n+3)(\Gamma+1) - 2\).

% Wrapping figure better declared before a paragraph
%
\begin{wrapfigure}[7]{r}[0pt]{0pt}
% [7] vertical lines
% {r} mandatory right placement
\centering
\includegraphics[bb=71 658 220 709]{flat}% ... 721
\caption{Aplatissement}
\label{fig:flat}
\index{pile!aplatissement!définition}
\end{wrapfigure}

\paragraph{Conception à petits pas}
\index{conception!petits pas}

Une approche alternative pour aplatir une pile consiste, dans la
règle~\(\gamma\), à hisser~\(x\) d'un niveau parmi les piles
imbriquées. En termes d'arbres de syntaxe abstraite, cette opération
est une \emph{rotation à droite}\index{arbre binaire!rotation} de
l'arbre associé à l'argument, comme cela est montré aux
\figs~\vrefrange{fig:lift1}{fig:lift2}, où la nouvelle fonction est
nommée \fun{flat/1}\index{flat@\fun{flat/1}|(} et est définie à la
\fig~\vref{fig:flat}. Déroulons à nouveau l'exemple de la
\fig~\vref{fig:flat0_ex} à la \fig~\vref{fig:flat_ex} avec
\fun{flat/1}. La différence de coût avec
\fun{flat\(_0\)/1}\index{flat0@\fun{flat$_0$/1}} réside dans le nombre
de fois que la règle~\(\gamma\) est utilisée: une fois pour chaque
élément de toutes les piles imbriquées.

Par conséquent, le coût
\index{pile!aplatissement!coût}\label{cost_flat} est \(1 + n + \Omega
+ \Gamma + L\), où \(L\)~est la somme des longueurs de toutes les
piles imbriquées.

\paragraph{Comparaison}

Examinons les coût suivants:
\begin{equation*}
\begin{array}{@{}r@{\;}c@{\;}r@{\;}c@{\;}r@{\;}c@{\;}l@{}}
\Call{\fun{flat}([[[[[1,2]]]]])}
  &=& 12 &<& 23 &=& \Call{\fun{flat\(_0\)}([[[[[1,2]]]]])};\\
\Call{\fun{flat}([\el,[[1],2],3])}
  &=& 10 &<& 14 &=& \Call{\fun{flat\(_0\)}([\el,[[1],2],3])};\\
\Call{\fun{flat}([\el,[[1,[2]]],3])}
  &=& 12 &<& 19 &=& \Call{\fun{flat\(_0\)}([\el,[[1,[2]]],3])};\\
\Call{\fun{flat}([[\el,\el,\el]])}
  &=&  8 &>&  7 &=& \Call{\fun{flat\(_0\)}([[\el,\el,\el]])}.
\end{array}
\end{equation*}
\begin{figure}
\begin{equation*}
\boxed{%
\begin{array}{r@{\;}l@{\;}l}
\fun{flat}([\el,[[1],2],3])
& \xrightarrow{\smash{\omega}} & \fun{flat}([[[1],2],3])\\
& \xrightarrow{\smash{\gamma}} & \fun{flat}([[1],[2],3])\\
& \xrightarrow{\smash{\gamma}} & \fun{flat}([1,\el,[2],3])\\
& \xrightarrow{\smash{\delta}} & [1|\fun{flat}([\el,[2],3])\\
& \xrightarrow{\smash{\omega}} & [1|\fun{flat}([[2],3])]\\
& \xrightarrow{\smash{\gamma}} & [1|\fun{flat}([2,\el,3])]\\
& \xrightarrow{\smash{\delta}} & [1,2|\fun{flat}([\el,3])]\\
& \xrightarrow{\smash{\omega}} & [1,2|\fun{flat}([3])]\\
& \xrightarrow{\smash{\delta}} & [1,2,3|\fun{flat}(\el)]\\
& \xrightarrow{\smash{\psi}}   & [1,2,3].
\end{array}}
\end{equation*}
\caption{\(\fun{flat}([\el,[[1],2],3]) \twoheadrightarrow [1,2,3]\)}
\label{fig:flat_ex}
\index{pile!aplatissement!exemple}
\end{figure}
Un peu d'algèbre révèle que\index{flat@$\C{\fun{flat}}{n,\Omega,\Gamma}$}
\index{flat0@$\B{\fun{flat}_0}{n,\Omega,\Gamma}$}
\begin{equation*}
\C{\fun{flat}}{n,\Omega,\Gamma}
\leqslant
\B{\fun{flat}_0}{n,\Omega,\Gamma}
\Leftrightarrow
\begin{cases}
  L \leqslant 3\Gamma - \Omega,
                         & \text{si \(\Omega \geqslant \Gamma\)};\\
  L \leqslant 2\Gamma,   & \text{sinon.}
\end{cases}
\end{equation*}
\index{flat@\fun{flat/1}|)} Ce critère n'est pas pratique à vérifier
et n'est pas concluant si les inégalités à droite échouent. La
situation empire si nous choisissons à la place \(L \leqslant 2\Gamma
\Rightarrow \smash[t]{\C{\fun{flat}}{n,\Omega,\Gamma}} \leqslant
\smash[t]{\C{\fun{flat}_0}{n,\Omega,\Gamma}}\), parce que cette
condition est trop forte lorsque \(\Omega\)~est grand. Examinons alors
ce qui advient à l'autre extrême, quand \(\Omega = 0\). Un exemple
comme \([0,[1,[2]],3,[4,5,[6,7],8],9]\) nous induit à penser que s'il
n'y a pas de piles vides, la longueur de chaque pile est inférieure ou
égale au nombre de ses éléments qui ne sont pas des piles, en comptant
aussi leur occurrence dans des piles imbriquées (il y a égalité
lorsqu'il n'y a pas de piles imbriquées). Par conséquent, en ajoutant
toutes ces inégalités, le résultat \(\Omega = 0 \Rightarrow L
\leqslant C\) s'ensuit, où \(C\)~est le coût de la réécriture des
appels à~\fun{cat/2}\index{cat@\fun{cat/2}}
dans~\fun{flat\(_0\)/1}\index{flat0@\fun{flat$_0$/1}}. Puisque nous
avons \(\C{\fun{flat}}{n,\Omega,\Gamma} = (1 + n + \Omega + \Gamma) +
L\) et \(\C{\smash{\fun{flat}_0}}{n,\Omega,\Gamma} = (1 + n + \Omega +
\Gamma) + (C + \Gamma)\), nous concluons qu'en l'absence de piles
vides, \fun{flat/1}\index{flat@\fun{flat/1}} est plus rapide.

\mypar{Terminaison}
\label{flattening_termination}
\index{pile!aplatissement!terminaison|(}

Comme nous l'avons vu à propos de la version simplifiée de la fonction
de Ackermann (section~\ref{par:ackermann}, \vpageref{par:ackermann}),
la terminaison est la conséquence de l'existence d'un ordre bien fondé
\((\succ)\) sur les appels récursifs, qui est induit par la relation
de réécriture \((\rightarrow)\), c'est-à-dire \(x \rightarrow y
\Rightarrow x \succ y\). Un ordre bien fondé pour les piles est
l'\emph{ordre des sous-termes immédiats}, satisfaisant \(\cons{x}{s}
\succ s\) et \(\cons{x}{s} \succ x\). Puisqu'une conception à grand
pas effectue des appels récursifs sur les sous-termes
(section~\ref{par:well-founded}, \vpageref{par:well-founded}), elle
facilite les preuves de terminaison fondées sur un tel
ordre. Souvenons-nous ainsi de la définition de
\fun{flat\(_0\)/1}\index{flat0@\fun{flat$_0$/1}|(} à la
\fig~\ref{fig:flat0}, page~\pageref{fig:flat0}. Étant donné que
\fun{cat/2}\index{cat@\fun{cat/2}} est indépendant de
\fun{flat\(_0\)/1}, nous établissons sa terminaison séparément en
employant l'ordre des sous-termes immédiats sur son premier
argument. Supposons donc que \fun{cat/2} termine et prouvons la
terminaison de \fun{flat\(_0\)/1}. Parce que les appels récursifs de
\fun{flat\(_0\)/1} ne contiennent que des constructeurs (de piles),
nous pouvons essayer d'ordonner leurs arguments
\citep{ArtsGiesl_1996}. Ici encore, le même ordre fonctionne:
\(\cons{y}{t} \succ t\) (règle~\(\delta\) et la règle~\(\omega\) quand
\(y=\el\)), \(\cons{\cons{x}{s}}{t} \succ t\) et
\(\cons{\cons{x}{s}}{t} \succ \cons{x}{s}\) (règle~\(\gamma\)). La
terminaison s'ensuit.\hfill\(\Box\)

\par\vspace\baselineskip

Rappelons-nous ensuite de la définition de
\fun{flat/1}\index{flat@\fun{flat/1}} à la \fig~\vref{fig:flat} et
prouvons sa terminaison. Ici, l'ordre que nous avons employé pour
\fun{flat\(_0\)/1} échoue: \(\cons{\cons{x}{s}}{t} \nsucc
\cons{x,s}{t} = \cons{x}{\cons{s}{t}}\). Nous pourrions alors viser
une plus grande généralité avec l'\emph{ordre des sous-termes
  propres}\index{induction!ordre des sous-termes propres},
c'est-à-dire la stricte inclusion d'un terme dans un autre, mais,
malgré l'encourageante inégalité \(\cons{x}{s} \succ x\), nous
échouons avec \(t \nsucc \cons{s}{t}\). Nous avons besoin de plus
d'abstraction, ce que nous permet la définition d'une
\emph{mesure}\index{terminaison!mesure} sur les piles
\citep{Giesl_1995a}.\index{flat0@\fun{flat$_0$/1}|)} Une mesure \(\measure{\cdot}\) est une injection de l'ensemble des
termes considérés vers un ensemble bien ordonné (\(A,\succ\)), qui est
\emph{monotone} par rapport à une relation de réécriture donnée
\((\rightarrow)\), c'est-à-dire, \(x \rightarrow y \Rightarrow
\measure{x} \succ \measure{y}\). En fait, nous n'allons considérer que
des \emph{paires de dépendance}
\citep{ArtsGiesl_2000}\index{terminaison!paire de dépendance},
c'est-à-dire, des paires d'appels dont les premières composantes sont
les membres gauches d'une règle et les secondes composantes sont les
appels dans les membres droits de la même règle. Ceci est plus facile
que de travailler directement avec \(x\)~et~\(y\) dans \(x \rightarrow
y\), car seuls les sous-termes de~\(y\) sont pris en compte. Les
paires sont\index{flat@\fun{flat/1}} \((\fun{flat}(\cons{\el}{t}),
\fun{flat}(t))_\omega\), \((\fun{flat}(\cons{\cons{x}{s}}{t}),
\fun{flat}(\cons{x,s}{t}))_\gamma\) et \((\fun{flat}(\cons{y}{t}),
\fun{flat}(t))_\delta\), avec \(y \not\in S\). Nous pouvons en fait
laisser tomber les noms de fonction, car toutes les paires portent sur
\fun{flat/1}\index{flat@\fun{flat/1}}. Une classe de mesures
fréquemment utilisée pour sa simplicité est celle des injections
monotones dans (\(\mathbb{N},>\)), donc cherchons une mesure
satisfaisant
\begin{equation*}
\measure{\cons{\cons{x}{s}}{t}} > \measure{\cons{x,s}{t}};\quad
\measure{\cons{y}{t}} > \measure{t},
\;\text{si \(y \not\in S\) ou \(y=\el\)}.
\end{equation*}
Par exemple, prenons la \emph{mesure polynomiale}\index{terminaison!mesure polynomiale} suivante:
\begin{equation*}
\measure{\cons{x}{s}} := 1 + 2\cdot\measure{x} + \measure{s};\quad
\measure{y} := 0,\;\text{si \(y \not\in S\) ou \(y=\el\)}.
\end{equation*}
Nous avons \(\measure{\cons{\cons{x}{s}}{t}} = 3 + 4\cdot\measure{x} +
2\cdot\measure{s} + \measure{t}\) et, pour l'autre pile,
\(\measure{\cons{x,s}{t}} = 2 + 2\cdot\measure{x} + 2\cdot\measure{s}
+ \measure{t}\). Parce que \(\measure{x} \in \mathbb{N}\), pour
tout~\(x\), nous avons \(\measure{\cons{\cons{x}{s}}{t}} >
\measure{\cons{x,s}{t}}\). La seconde inégalité est obtenue plus vite:
\(\measure{\cons{y}{t}} = 1 + \measure{t} > \measure{t}\). Ceci
implique la terminaison de
\fun{flat/1}\index{flat@\fun{flat/1}}.\index{pile!aplatissement!terminaison|)}\hfill\(\Box\)

\cite{Giesl_1997} aborde la terminaison de fonctions mutuellement
récursives. Les programmes fonctionnels, en tant que cas particuliers
de systèmes de réécriture de termes, ont été étudiés par
\cite{Giesl_1995b} et \cite{GieslWaltherBrauburger_1998}.

% Wrapping figure better declared before a paragraph
%
\begin{wrapfigure}[6]{r}[0pt]{0pt}
% [6] vertical lines
% {r} mandatory right placement
\centering
\includegraphics[bb=71 644 227 721]{flat1}
\caption{Aplatissement alternatif}
\label{fig:flat1}
\index{pile!aplatissement!définition}
\end{wrapfigure}
\paragraph{Exercices}

\begin{enumerate}

  \item Définir les fonctions \fun{omega/1}, \fun{gamma/1} et
    \fun{lambda/1}, calculant, respectivement, \(\Omega\), \(\Gamma\)
    et \(L\).

  \item Comparez les coûts de \fun{flat/1}\index{flat@\fun{flat/1}} et
    \fun{flat\(_1\)/1} \index{flat1@\fun{flat$_1$/1}} définies à la
    \fig~\ref{fig:flat1} (voir~(\(\leadsto\))).

\end{enumerate}
\index{pile!aplatissement|)}
