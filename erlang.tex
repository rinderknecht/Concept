\chapter{Traduction en \Erlang}
\index{langage fonctionnel!Erlang@\Erlang|(}

Traduire notre langage fonctionnel en \Erlang est en fait une tâche
très aisée. La section~\ref{sec:implementation} dans l'introduction
proposait déjà un petit exemple. Au-delà de la nécessité d'en-têtes
pour les modules, certaines conventions lexicales doivent être
respectées, et nous devons avoir une certaine compréhension des
mécanismes mis en jeu par le compilateur pour le partage de données
par synonymie. De plus, nous expliquerons en termes du modèle de la
mémoire à la section~\ref{sec:memory} comment les concepts de
\emph{pile de contrôle} (ou \emph{pile des appels}) et le \emph{tas}
émergent, mais aussi nous présenterons une technique d'optimisation
mise en {\oe}uvre par la plupart des compilateurs de langages
fonctionnels: l'\emph{optimisation des appels
  terminaux}.\index{mémoire!optimisation des appels terminaux}

\paragraph{Lexique et syntaxe}

En \Erlang, les piles sont appelées \emph{listes}. Néanmoins, nous
continuerons à employer le mot «~pile~» pour permettre une lecture
uniforme de ce livre.

La première lettre des variables est composée en majuscule, par
exem\-ple, \emph{data} devient~\erlcode{Data} et~\(x\)
devient~\erlcode{X}.

Les constructeurs de données\index{langage fonctionnel!constructeur de
  données} constants sont traduits sans leur paire de parenthèses; par
exemple, \(\fun{absent}()\) devient \erlcode{absent} en
\Erlang. Lorsque des arguments sont présents, un \(n\)-uplet est
utilisé. Un \(n\)-uplet en \Erlang est écrit avec des accolades, pour
les distinguer des parenthèses des appels de fonction, donc
\(\pair{x}{y}\)~est traduit par \erlcode{\{X,Y\}}. Ainsi,
\(\fun{one}(s)\) devient \erlcode{\{one,S\}} en \Erlang si \fun{one/1}
est un constructeur, sinon \erlcode{one(S)}, si \erlcode{one/1} est
une fonction. En \Erlang, un constructeur constant est appelé un
\emph{atome}.\index{langage fonctionnel!Erlang@\Erlang!atome}

Quand une variable dans un motif est inutilisée dans le membre droit,
elle peut être remplacée par un souligné, donc
\begin{equation*}
\begin{array}{@{}r@{\;}l@{\;}l@{}}
\fun{len}(\el)         & \rightarrow & 0;\\
\fun{len}(\cons{x}{s}) & \rightarrow & 1 + \fun{len}(s).
\end{array}
\end{equation*}
peut être traduit en \Erlang de la façon suivante:
\begin{verbatim}
len(   []) -> 0;
len([_|S]) -> 1 + len(S).
\end{verbatim}
En ce qui concerne la syntaxe, nous devons traduire les règles de
réécriture conditionnelles en utilisant le mot-clé
\texttt{\textbf{when}} et écrire la condition du côté gauche. Par
exemple, considérons à nouveau l'insertion simple à la
section~\ref{sec:straight_ins}:
\begin{equation*}
\begin{array}{@{}r@{\;}l@{\;}l@{}}
\fun{ins}(\cons{y}{s},x) & \rightarrow &
\cons{y}{\fun{ins}(s,x)}, \,\text{si \(x \succ y\)};\\
\fun{ins}(s,x) & \rightarrow & \cons{x}{s}.
\end{array}
\end{equation*}
Cette définition est traduite en \Erlang ainsi:
\begin{alltt}
ins([Y|S],X) \textbf{when X > Y} -> [Y|ins(S,X)];
ins(    S,X)            -> [X|S].
\end{alltt}
Notons qu'en \Erlang, \erlcode{X > Y} implique que
\erlcode{X}~et~\erlcode{Y} sont des entiers ou des atomes (qui sont
ordonnés alphabétiquement). En \Erlang, une règle de réécriture est
appelée une~\emph{clause}. Son membre gauche est appelé la \emph{tête}
et son membre droit le \emph{corps}. La condition d'une clause est
appelée la \emph{garde}. En passant, les conventions lexicales, la
syntaxe et le vocabulaire d'\Erlang ont été indirectement calqués sur
le langage de programmation \Prolog
\citep{SterlingShapiro_1994,Bratko_2000}. La structure d'une clause
\Erlang est résumée à la \fig~\vref{fig:clause}.
\begin{figure}[t]
\centering
\includegraphics[bb=214 602 397 646]{clause}
\caption{Structure d'une clause en \Erlang}
\label{fig:clause}
\end{figure}

Enfin, un commentaire débute par \erlcode{\%} et porte jusqu'à la fin
de la ligne.

\paragraph{Systèmes d'inférence}

La traduction de programmes définis par un système d'inférence
consiste soit à raffiner le système de telle sorte que la nouvelle
version ne contienne plus aucune règle d'inférence (voir par exemple
la \fig~\vref{fig:per} et la \fig~\ref{fig:per0}) et nous traduisons
alors en \Erlang, ou bien nous utilisons directement en \Erlang une
construction appelée \texttt{\textbf{case}}, qui est une expression
conditionnelle générale. Considérons à nouveau la
\fig~\vref{fig:per}. Une traduction directe en \Erlang est
\begin{verbatim}
per(ext)           -> {true,0};
per({int,_,T1,T2}) ->
  case per(T1) of
       false -> false;
    {true,H} -> case per(T2) of
                  {true,H} -> {true,H+1};
                         _ -> false
                end
  end.
\end{verbatim}
Remarquons que nous avons traduit la règle d'inférence avec deux
\texttt{\textbf{case}} au lieu d'un, parce qu'il serait inefficace de
calculer à la fois \erlcode{per(T1)} et \erlcode{per(T2)} si la valeur
de \erlcode{per(T1)} était \erlcode{false}. De plus, une variable dans
le motif d'un \texttt{\textbf{case}} peut être liée à une valeur
définie avant (en \OCaml, cela n'est pas possible), donc \erlcode{case
  per(T2) of \{true,H\} -> ...} implique implicitement que \erlcode{H}
possède la même valeur que la variable \erlcode{H} dans la
conditionnelle \erlcode{case per(T1) of ... ; \{true,H\} -> ...}

Considérons un autre exemple à la \fig~\vref{fig:comp}. Il est traduit
ainsi:
\begin{verbatim}
comp({int,_,ext,ext}) -> true;
comp({int,_,T1,T2})   -> case comp(T1) of
                           false -> false;
                               _ -> comp(T2)
                         end;
comp(ext)             -> false.
\end{verbatim}
Si la valeur de \(\fun{comp}(t_2)\) est \(\fun{false}()\), alors la
règle \(\fun{comp}(t) \rightarrow \fun{false}()\) est sélectionnée. Ce
changement de règle, ou \emph{rebroussement}, n'est pas possible en
\Erlang: une fois que l'appel courant a filtré la tête d'une clause,
les têtes restantes ne seront pas examinées. En factorisant l'appel
\(\fun{comp}(t_1)\), nous résolvons ce problème et la règle
d'inférence devient un seul cas à traiter.

La fonction à la \fig~\vref{fig:pre2b0} devient, quant à elle:
\begin{verbatim}
pre2b0(S) -> case pre2b1(S) of
               {T,[]} -> T
             end.

pre2b1([ext|S]) -> {ext,S};
pre2b1([X|S])   ->
  case pre2b1(S) of
    {T1,S1} -> case pre2b1(S1) of
                 {T2,S2} -> {{int,X,T1,T2},S2}
               end
  end.
\end{verbatim}
Ici, nous avons une situation avec des \texttt{\textbf{case}} dont
l'unique motif ne peut échouer (le motif est dit
\emph{irréfutable}). \Erlang fournit une syntaxe plus courte pour ce
genre d'usage:
\begin{verbatim}
pre2b0(S) -> {T,[]}=pre2b1(S), T.

pre2b1([ext|S]) -> {ext,S};
pre2b1([X|S])   -> {T1,S1}=pre2b1(S),
                   {T2,S2}=pre2b1(S1),
                   {{int,X,T1,T2},S2}.
\end{verbatim}
Considérons un exemple où les règles d'inférence ne sont pas
utilisées, mais où nous réalisons que certaines fonctions se
comportent uniquement comme des expressions conditionnelles. Nous en
voyons un exemple à la \fig~\vref{fig:bst}, avec les fonctions
\fun{norm/1} et \fun{cmp/3}:
\begin{verbatim}
bst(T) -> case bst1(T,infty) of false -> false;
                                    _ -> true
          end.

bst1(ext,M)           -> M;
bst1({bst,X,T1,T2},M) -> case bst1(T2,M) of
                                  infty -> bst1(T1,X);
                           N when N > X -> bst1(T1,X);
                                      _ -> false
                         end.
\end{verbatim}
Remarquons que nous avons dû renommer une variable~\(m\)
en~\erlcode{N}, pour éviter la liaison erronée avec la
variable~\erlcode{M} avant. Est-ce que la définition de \fun{bst/1} à
la \fig~\ref{fig:bst} aurait été plus courte si nous avions utilisé
des règles d'inférence?

La recherche de motifs dans un texte avec l'algorithme de Morris et
Pratt\index{recherche de motifs!algorithme de Morris et Pratt} a
abouti à une définition avec des règles d'inférence aux
\figs~\vrefrange{fig:fail}{fig:mp_def}. En incluant ici la solution à
l'exercice~\vref{factoring_trick}, nous traduisons ce système en
\Erlang de la façon suivante:
\begin{verbatim}
fail(        _,0) -> -1;
fail([{A,K}|P],I) -> fp(P,A,K,I-1).

fp(_,_,-1,_) -> 0;
fp(P,A, K,I) -> case suf(P,I-K-1) of
                  [{A,_}|_] -> K + 1;
                  [{_,J}|Q] -> fp(Q,A,J,K)
                end.

suf(    P,0) -> P;
suf([_|P],I) -> suf(P,I-1).

mp(P,T) -> PP=pp(P), mp(PP,T,PP,0,0).

mp(        [],    _, _,I,J) -> {factor,J-I};
mp(         _,   [], _,_,_) -> absent;
mp( [{A,_}|P],[A|T],PP,I,J) -> mp(P,T,PP,I+1,J+1);
mp([{_,-1}|_],[_|T],PP,0,J) -> mp(PP,T,PP,0,J+1);
mp( [{_,K}|_],    T,PP,_,J) -> mp(suf(PP,K),T,PP,K,J).

pp(X) -> pp(X,[],0).

pp(   [],_,_) -> [];
pp([A|X],P,I) -> U={A,fail(P,I)}, [U|pp(X,[U|P],I+1)].
\end{verbatim}


\paragraph{La boucle interactive \Erlang}

Les programmes que nous avons écrits jusqu'à présent ne sont pas des
programmes \Erlang complets, pour cela ils doivent être des
\emph{modules}. Un module est une unité de compilation contenant une
collection de définitions. Le nom du module doit être le nom de base
du fichier contenant le module. Par exemple, le module suivant nommé
\erlcode{math1},
\begin{alltt}
\textbf{-module(math1).}\hfill% \emph{Sans l'extension} .erl
\textbf{-export([fact/1]).}
fact(1)            -> 1;
fact(N) when N > 1 -> N * fact(N-1).
\end{alltt}
doit être écrit dans un fichier nommé \erlcode{math1.erl}. La ligne
\erlcode{-export} liste tous les noms des fonctions qui peuvent être
appelées depuis l'extérieur du module, c'est-à-dire, depuis un autre
module ou depuis la \emph{boucle interactive \Erlang.} Une boucle
interactive est une application qui lit des commandes entrées par un
usager, les interprète, affiche un résultat ou un message d'erreur et
attend d'autres commandes.

Pour tester quelques exemples avec \erlcode{fact/1}, nous devons
d'abord exécuter la boucle interactive. Selon le système
d'exploitation, l'environnement de programmation peut varier
grandement. Ici, nous supposerons une interface textuelle, comme
celles disponibles via un terminal du système d'exploitation \Unix, ou
ses dérivés. La boucle interactive \Erlang est une application qui
nous permet de compiler à la demande des modules et d'appeler des
fonctions de ceux-ci. Son nom est probablement~\erlcode{erl}. Nous
montrons le début d'une session:
\begin{alltt}
\$ erl
Erlang R14B04 (erts-5.8.5) [source] [smp:4:4] [rq:4]
[async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.8.5  (abort with ^G)
1> \(\talloblong\)
\end{alltt}
La première ligne est la commande qui lance la boucle. La dernière
ligne est l'invite, le nombre~\texttt{1} signifiant que celle-ci
attend sa première commande. Remarquons que l'invite du terminal est
dénotée par le symbole du dollar américain (\erlcode{\$}). Le
caractère \(\talloblong\) dénote l'invite clignotante de la boucle
\Erlang où la saisie a lieu. Si nous voulons fermer la boucle et
revenir à l'interprète de commandes du terminal, il suffit de saisir
«~\erlcode{q().}~» (anglais, \emph{quit}). Chaque commande doit être
terminée par un point~(\erlcode{.}) et suivie par la pression sur la
touche «~retour~» (ou «~entrée~»).
\begin{alltt}
1> q().
ok
2> \$ \textvisiblespace
\end{alltt}
Le caractère \erlcode{\textvisiblespace} représente le lieu où les
commandes pour le système d'exploitation sont saisies. Mais avant de
sortir de la boucle \Erlang, la première action est souvent d'appeler
le compilateur \Erlang pour traiter un module que nous voulons
utiliser. Cela est réalisé par la commande~«~\erlcode{c}~», dont
l'argument est le nom du module. Dans notre exemple, le nom de fichier
est \texttt{math1.erl}:
\begin{alltt}
1> c(math1).
\{ok,math1\}
2> \(\talloblong\)
\end{alltt}
La compilation a été un succès, comme l'atome \erlcode{ok} le
montre. Calculons quelques factorielles maintenant:
\begin{alltt}
2> math1:fact(4).
24
3> math1:fact(-3).
** exception error: no function clause matching
math1:fact(-3)
4> \(\talloblong\)
\end{alltt}
Cette erreur est: «~Pas de clause filtrant \texttt{math1:fact(-3)}.~»
Nous ne copierons que rarement les commandes et les résultats de la
boucle \Erlang, nous n'écrirons même pas les modules complètement
parce que nous voulons nous concentrer sur la conception et déléguer
les aspects pratiques à un manuel d'utilisateur.

\section{Mémoire}
\label{sec:memory}
\index{mémoire|(}

Passons en revue quelques programmes sous l'angle de l'utilisation de
la mémoire plutôt que du coût. Dans l'introduction, nous avons affirmé
que l'essence d'une expression est une représentation
bidimensionnelle, à savoir un arbre, plutôt qu'une ligne de texte
ponctué. À la section~\vref{sec:skipping}, nous avons présenté les
notions syntaxiques de contexte d'un appel et de forme terminale d'une
définition. Nous avons aussi supposé que des structures de données
identiques apparaissant dans un motif et dans le membre droit
correspondant sont en réalité partagées.

Dans cette section, nous développons ces concepts et représentations,
et nous montrons comment ils permettent une meilleure compréhension de
la gestion de la mémoire par l'environnement d'exécution d'un langage
fonctionnel, tel qu'il est produit par un compilateur.

Néanmoins, ces sujets dépendent fortement du compilateur et de
l'architecture matérielle, donc il serait imprudent de poursuivre une
description trop détaillée. Par conséquent, il est suffisant et
pertinent ici de fournir un modèle raffiné qui est fondé sur les
graphes orientés sans circuits uniquement, à savoir, les arbres de
syntaxe abstraite avec partage explicite.\index{arbre!$\sim$ de
  syntaxe abstraite}\index{graphe orienté sans circuits} Typiquement,
une mesure de la quantité de mémoire nécessaire au total sera le
nombre de n{\oe}uds de ces arbres, ou une catégorie de ceux-ci, comme
les n{\oe}uds d'empilage\index{n{\oe}ud d'empilage}.

\paragraph{Addition d'entiers}

Voici la définition de \erlcode{sum/1}, qui additionne les entiers
dans une pile donnée:
\begin{alltt}
sum([N])   -> N;
sum([N|S]) -> N + sum(S).
\end{alltt}
Pour plus de lisibilité, étiquetons les flèches:
\begin{alltt}
sum([N])   \(\xrightarrow{\smash[t]{\alpha}}\) N;
sum([N|S]) \(\xrightarrow{\smash[t]{\beta}}\) N + sum(S).
\end{alltt}
Nous avons, par exemple,
\begin{alltt}
sum([1|[2|[3|[]]]]) \(\xrightarrow{\smash[t]{\beta}}\) 1 + sum([2|[3|[[]]]])
                    \(\xrightarrow{\smash[t]{\beta}}\) 1 + (2 + sum([3|[]]))
                    \(\xrightarrow{\smash[t]{\alpha}}\) 1 + (2 + (3))
                    \(=\) 6.
\end{alltt}

Que pouvons-nous dire à propos de l'efficacité et de l'usage de la
mémoire de \erlcode{sum/1}? Le nombre de réécritures clairement égale
le nombre d'entiers dans la pile parce que chaque entier est
filtré. Donc, si la fonction est initialement appelée sur une pile de
\(n\)~entiers, la nombre de pas pour atteindre le résultat est~\(n\):
\(n-1\) fois par la clause~\clause{\beta}, et une fois avec la
clause~\clause{\alpha}. En prenant une pile un peu plus longue, nous
pouvons entrevoir l'usage de la mémoire:
\begin{alltt}
sum([1|[2|[3|[4|[]]]]]) \(\xrightarrow{\smash[t]{\beta}}\) 1 + sum([2|[3|[4|[]]]])
                        \(\xrightarrow{\smash[t]{\beta}}\) 1 + (2 + sum([3|[4|[]]]))
                        \(\xrightarrow{\smash[t]{\beta}}\) 1 + (2 + (3 + sum([4|[]])))
                        \(\xrightarrow{\smash[t]{\alpha}}\) 1 + (2 + (3 + (4)))
                        \(=\) 10\textrm{.}
\end{alltt}
Ceci nous amène à examiner uniquement les tailles des membres droits:
\begin{alltt}
sum([1|[2|[3|[4|[]]]]]) \(\xrightarrow{\smash[t]{\beta}}\) \fbcode{1 + sum([2|[3|[4|[]]]])}
                        \(\xrightarrow{\smash[t]{\beta}}\) \fbcode{1 + (2 + sum([3|[4|[]]]))}
                        \(\xrightarrow{\smash[t]{\beta}}\) \fbcode{1 + (2 + (3 + sum([4|[]])))}
                        \(\xrightarrow{\smash[t]{\alpha}}\) \fbcode{1 + (2 + (3 + (4)))}\,\textrm{.}
\end{alltt}
Il semble que l'usage total de la mémoire augmente lentement et
ensuite diminue brutalement après la dernière réécriture. Mais, en
omettant les espaces, nous obtenons
\begin{verbatim}
sum([1|[2|[3|[4|[]]]]]) -> 1+sum([2|[3|[4|[]]]])
                        -> 1+(2+sum([3|[4|[]]]))
                        -> 1+(2+(3+sum([4|[]])))
                        -> 1+(2+(3+(4))).
\end{verbatim}
Il semble maintenant que les expressions sont de taille constante
jusqu'à ce que la clause~\(\alpha\) soit appliquée. De plus, même si
(\erlcode{+}) était écrit \erlcode{plus}, son occurrence ne devrait
pas être considérée comme prenant plus de mémoire que (\erlcode{+})
parce que les noms ne sont que des étiquettes. Que penser par ailleurs
des parenthèses et des espaces? Devraient-elles être prises en compte
pour l'allocation de mémoire? Toutes ces considérations montrent que
nous avons besoin d'une compréhension plus fine de la manière dont les
fonctions \Erlang et les données sont représentées à l'exécution mais,
parce que ces encodages dépendent fortement des compilateurs et des
architectures matérielles, il ne faudrait pas ici exiger une
description trop détaillée. Le modèle qui convient sont les
\emph{arbres de syntaxe abstraite} et les \emph{graphes orientés sans
  circuits}, vus dans l'introduction. Ceux-ci nous permettent de tirer
des conclusions à propos de l'usage de la mémoire, qui tiennent modulo
une constante de proportionnalité.

\paragraph{Concaténation de piles}
\index{mémoire!concaténation de piles|(}

La définition à la \fig~\vref{def:cat} est
\begin{equation*}
\fun{cat}(        \el,t) \xrightarrow{\smash{\alpha}} t;\qquad
\fun{cat}(\cons{x}{s},t) \xrightarrow{\smash{\beta}}
                                 \cons{x}{\fun{cat}(s,t)}.
\end{equation*}
La mesure pertinente de l'usage mémoriel ici est le nombre de
n{\oe}uds d'empilage\index{n{\oe}ud d'empilage} créés par la
règle~\(\beta\). Clairement, l'appel \(\fun{cat}(s,t)\) créé
\(n\)~n{\oe}uds de ce type, où \(n\)~est la longueur de la pile~\(s\).

\index{mémoire!concaténation de piles|)}

\paragraph{Retournement de piles}
\index{mémoire!retournement de piles|(}

La définition de~\fun{rev\(_0\)/1} à la section~\ref{sec:reversal}:
\begin{equation*}
\fun{rev}_0(\el) \xrightarrow{\smash{\gamma}} \el;\qquad
\fun{rev}_0(\cons{x}{s}) \xrightarrow{\smash{\delta}}
                         \fun{cat}(\fun{rev}_0(s),[x]).
\end{equation*}
La pile vide dans le membre droit de la règle~\(\gamma\) est partagée
avec le motif. Bien sûr, la même chose peut être dite de tout
constructeur constant. Nous savons déjà combien de ces n{\oe}uds sont
créés par les appels à \fun{cat/2} et, puisque la longueur de~\(s\)
dans l'appel récursif \(\fun{rev}_0(s)\) est diminuée de~\(1\), le
nombre d'empilages est \(\sum_{k=1}^{n-1}k = \tfrac{1}{2}n(n-1)\), si
la pile originelle contient \(n\)~éléments. Nous devons ajouter un
empilage pour chaque \([x]\), soit~\(n\). Au total: \(n(n+1)/2\).

La définition optionnelle~\eqref{def:rev} du retournement,
\vpageref{def:rev}, est
\begin{equation*}
\fun{rev}(s) \xrightarrow{\smash{\epsilon}} \fun{rcat}(s,\el).\quad\;\;
\fun{rcat}(\el,t) \xrightarrow{\smash{\zeta}} t;\quad\;\;
\fun{rcat}(\cons{x}{s},t) \xrightarrow{\smash{\eta}}
                          \fun{rcat}(s,\cons{x}{t}).
\end{equation*}
Le nombre total d'empilages est~\(n\), la longueur de la pile donnée.
\index{mémoire!retournement de piles|)}

\paragraph{Interclassement}
\index{mémoire!interclassement|(}

Quantifions la mémoire nécessaire pour trier par interclassement
\(n=2^p\)~clés, de façon ascendante. Tout d'abord, le nombre de piles
créées est le nombre de n{\oe}uds de l'arbre d'interclassement: \(2^p
+ 2^{p-1} + \ldots + 2^0 = 2^{p+1}-1 = 2n - 1\). Il y a un n{\oe}ud
d'empilage\index{n{\oe}ud d'empilage} pour chaque clé, ce qui nous
amène à déterminer la somme des longueurs des piles créées: \((p+1)2^p
= n\lg n + n\). Ceci est le nombre total de n{\oe}uds d'empilage. Dans
le cas de la variante descendante, seulement la première moitié des
piles, l'originelle inclue, sont retournées, donc allouent de la
mémoire. Ainsi, le nombre total de n{\oe}uds d'empilage créés est
\(\tfrac{1}{2}n\lg n\).

\index{mémoire!interclassement|)}

%\section{Context of a call}
\paragraph{Contexte d'appel}
\index{langage fonctionnel!contexte d'appel|(}
\index{mémoire!contexte d'appel|(}

Nous voulons maintenant parvenir à une meilleure compréhension de
l'influence du contexte d'un appel récursif sur
l'évaluation. Définissons une fonction \fun{sum/1} telle que l'appel
\(\fun{sum}(s)\) est la somme des entiers dans la pile~\(s\):
\begin{equation*}
\fun{sum}([n]) \xrightarrow{\smash{\alpha}} n;\qquad
\fun{sum}(\cons{n}{s}) \xrightarrow{\smash{\beta}} n + \fun{sum}(s).
\end{equation*}
Considérons à la \fig~\vref{fig:sum_ast} l'arbre de syntaxe abstraite
de l'expression \(1+(2+\fun{sum}([3,4]))\) et l'appel de fonction
qu'elle contient à la \fig~\ref{fig:sum_call}.
\begin{figure}
\centering
\subfloat[Expression\label{fig:sum_ast}]{%
  \includegraphics[bb=71 627 134 721]{sum_ast}
}
\qquad
\subfloat[Instances du contexte \(n +
  \texttt{\textvisiblespace}\)\label{fig:sum_ctxt}]{%
  \includegraphics[bb=55 627 135 721]{sum_ctxt}
}
\quad
\subfloat[Appel\label{fig:sum_call}]{%
  \includegraphics[bb=71 663 110 731]{sum_call}
}
\qquad
\subfloat[Argument\label{fig:sum_arg}]{%
  \includegraphics[bb=64 679 118 731]{sum_arg}
}
\caption{\(1+(2+\fun{sum}([3,4]))\)}
\end{figure}
En prenant comme origine le n{\oe}ud \fun{sum}, l'arbre de syntaxe
abstraite peut être divisé en la partie sous celui-ci, à savoir
l'argument à la \fig~\ref{fig:sum_arg}, et la partie au-dessus, nommée
\emph{instances du contexte}, à la \fig~\ref{fig:sum_ctxt}.

Le principal intérêt des arbres de syntaxe abstraite est qu'aucune
parenthèse n'est nécessaire, parce qu'une sous-expression est dénotée
par un sous-arbre, en d'autres termes, un arbre est inclus dans un
autre. De plus, les espaces sont absentes aussi et ainsi l'essentiel
est mis en valeur. Pour illustrer le gain en visibilité, considérons à
nouveau la précédente évaluation dans sa totalité, de gauche à droite
(le n{\oe}ud qui va être réécrit est encadré), à la
\fig~\ref{fig:sum1234}.
\begin{figure}
\centering
\includegraphics[bb=72 620 412 721]{sum1234}
\caption{Évaluation de \(\fun{sum}([1,2,3,4])\)}
\label{fig:sum1234}
\end{figure}
Il est clair maintenant que les instances du contexte s'accumulent et
croissent en proportion inverse de la taille de l'argument: les
entiers se déplacent un par un de l'argument vers le contexte et
l'opération associée passe d'être un n{\oe}ud
d'empilage\index{n{\oe}ud d'empilage} à devenir une addition. Par
conséquent, si nous utilisons comme unité de mesure un n{\oe}ud, la
mémoire totale utilisée est en effet constante, sauf pour la dernière
réécriture.

Examinons à nouveau l'exemple filé et ce qui advient du contexte, à
chaque réécriture, à la \fig~\vref{fig:sum1234_stack}.
\begin{figure}
\centering
\includegraphics{sum1234_stack}
\caption{Contextes pour l'évaluation de \(\fun{sum}([1,2,3,4])\)}
\label{fig:sum1234_stack}
\end{figure}
Cet exemple montre que les instances du contexte croissent, cependant
que la taille de l'argument décroît de telle manière que la mémoire
totale utilisée reste constante.

\index{langage fonctionnel!contexte d'appel|)}

\index{mémoire!contexte d'appel|)}

\paragraph{Forme terminale}
\label{sec:tail}
\index{langage fonctionnel!forme terminale|(}

Considérons la fonction \erlcode{sum/1}, qui somme les entiers dans
une pile donnée:
\begin{verbatim}
sum([N])   -> N;
sum([N|S]) -> N + sum(S).
\end{verbatim}
et cherchons une définition équivalente en forme terminale,
\erlcode{sum0/1}. Tout comme avec la factorielle à
l'équation~\eqref{eq:fact_tf} \vpageref{eq:fact_tf}, l'idée est
d'utiliser un argument supplémentaire pour accumuler les résultats
partiels. Ce type d'argument est appelé un \emph{accumulateur}. La
nouvelle version devrait alors ressembler à
\begin{alltt}
sum0(T)       -> sum0(T,\fbcode{0}).
sum0([M],N)   -> \fbcode{sum0(M+N,S)}\,;
sum0([M|S],N) -> \fbcode{sum0(M+N,S)}\,.
\end{alltt}
ou, de manière équivalente,
\begin{alltt}
sum0(T)       -> sum0(\fbcode{0},T).
sum0(N,[M])   -> \fbcode{sum0(M+N,S)}\,;
sum0(N,[M|S]) -> \fbcode{sum0(M+N,S)}\,.
\end{alltt}
Remarquons que, tout comme avec \erlcode{sum/1}, l'appel
\erlcode{sum0([])} échoue sans crier gare et on peut questionner ce
comportement. En effet, il pourrait être inapproprié dans le cadre de
l'ingénierie du logiciel, où la programmation à grande échelle
d'applications robustes est requise, mais ce livre se concentre sur la
programmation à petite échelle, donc les programmes présentés ici sont
fragiles à dessein; en d'autres termes, ils peuvent échouer sur des
entrées invalides au lieu d'informer l'appelant avec un avertissement,
un message d'erreur ou, encore mieux, s'arranger pour que le
compilateur lui-même rejette de tels programmes.

Puisque nous avons décidé qu'un accumulateur est nécessaire, nous
devons concevoir clairement la nature des données qu'il
contient. Comme nous l'avons dit précédemment, un accumulateur
contient une partie du résultat final. D'un autre point de vue, un
accumulateur est une trace partielle de toutes les réécritures
précédentes. Ici, étant donné que le résultat final est un entier,
nous garderons à l'esprit que l'accumulateur doit être un nombre.

Nous n'avons pas besoin de remplir le canevas ci-dessus (les cadres)
de la première ligne à la dernière: ceci est un programme, pas une
rédaction. Peut-être que la meilleure méthode consiste à écrire les
membres gauches des clauses, à nous assurer qu'aucun ne manque et
qu'aucun n'est inutile (en prenant en compte l'ordre implicite
d'écriture). Deuxièmement, nous choisissons la clause dont le corps
semble être suffisamment simple. Par exemple, la première clause de
\erlcode{sum/2} semble simple car elle s'applique seulement quand un
nombre, \erlcode{M}, reste dans la pile d'entrée. Puisque
l'accumulateur~\erlcode{N} contient la somme partielle jusqu'à
présent, seul reste à traiter~\erlcode{M}. Par conséquent, la réponse
est \erlcode{M+N} ou \erlcode{N+M}:
\begin{alltt}
sum0(T)       -> sum0(\fbcode{0},T).
sum0(N,[M])   -> \textbf{M+N};
sum0(N,[M|S]) -> \fbcode{sum0(M+N,S)}\,.
\end{alltt}
Nous choisissons ensuite la deuxième clause de \erlcode{sum0/2}. Elle
s'applique quand la pile d'entrée n'est pas vide, son premier élément
étant~\erlcode{M} et les autres étant dans~\erlcode{S}. Jusqu'à
présent, la somme partielle est l'accumulateur~\erlcode{N}. Il est
clair qu'un appel récursif est nécessaire ici, parce que si le corps
était \erlcode{M+N} à nouveau, alors le reste des entiers,
\erlcode{S}, serait inutile. Donc le calcul doit reprendre avec une
nouvelle donnée:
\begin{alltt}
sum0(T)       -> sum0(\fbcode{0},T).
sum0(N,[M])   -> M+N;
sum0(N,[M|S]) -> \textbf{sum0(}\fbcode{M+N}\textbf{,}\fbcode{S}\textbf{)}.
\end{alltt}
La question maintenant est de trouver ce que la nouvelle pile et le
nouvel accumulateur devraient être dans cette dernière clause. Que
savons-nous de la pile?  \erlcode{M}~et~\erlcode{S}. Que pouvons-nous
faire avec~\erlcode{M}? En fait, la même chose que nous avons faite
plus tôt, dans la première clause de \erlcode{sum0/2}, c'est-à-dire
l'ajouter à l'accumulateur:
\begin{alltt}
sum0(T)       -> sum0(\fbcode{0},T).
sum0(N,[M])   -> M+N;
sum0(N,[M|S]) -> sum0(\textbf{M+N},\fbcode{S}).
\end{alltt}
Ainsi, le nouvel accumulateur est \erlcode{M+N}, ce qui convient car
le but de l'accumulateur est de contenir la somme partielle jusqu'au
nombre courant, qui est~\erlcode{M} ici. Quelle nouvelle pile de
nombres devrions-nous utiliser? Il est clair que~\erlcode{M} ne peut
être employé ici, parce que sa valeur a déjà été ajoutée à
l'accumulateur, et nous ne devons pas le faire deux fois. Ceci
signifie que~\erlcode{M} n'est plus utile. Il reste la
variable~\erlcode{S}, qui est ce que nous recherchons, puisqu'elle
représente tous les nombres restant à ajouter à l'accumulateur:
\begin{alltt}
sum0(T)       -> sum0(\fbcode{0},T).
sum0(N,[M])   -> M+N;
sum0(N,[M|S]) -> sum0(M+N,\textbf{S}).
\end{alltt}
La dernière chose à faire est la valeur initiale de
l'accumulateur. Nous ne devons pas nous précipiter; au contraire, il
vaut mieux y penser en dernier lieu. Quelle sorte d'opération est
effectuée sur l'accumulateur? Des additions. Sans rien savoir sur les
entiers dans~\erlcode{T}, comme c'est le cas dans la clause de
\erlcode{sum0/1}, quel entier pourrait être pris comme valeur
initiale? Il est bien connu que, pour tout~\(n\), \(n + 0 = n\), donc
\erlcode{0}~apparaît comme la seule valeur possible ici, car elle ne
change pas le total de la somme:
\begin{alltt}
sum0(T)       -> sum0(\textbf{0},T).
sum0(N,[M])   -> M+N;
sum0(N,[M|S]) -> sum0(M+N,S).
\end{alltt}
La dernière étape consiste à essayer quelques exemples après avoir
étiqueté les flèches:
\begin{alltt}
sum0(T)        \(\xrightarrow{\smash[t]{\alpha}}\) sum0(0,T).
sum0(N,[M])   \(\xrightarrow{\smash[t]{\beta}}\) M+N;
sum0(N,[M|S]) \(\xrightarrow{\smash[t]{\gamma}}\) sum0(M+N,S).
\end{alltt}
Un exemple familier est:
\begin{alltt}
sum0([1|[2|[3|[4|[]]]]])
  \(\xrightarrow{\smash[t]{\alpha}}\) sum0(0,[1|[2|[3|[4|[]]]]])
  \(\xrightarrow{\smash[t]{\gamma}}\) sum0(1+0,[2|[3|[4|[]]]])   \(=\) sum0(1,[2|[3|[4|[]]]])
  \(\xrightarrow{\smash[t]{\gamma}}\) sum0(2+1,[3|[4|[]]])       \(=\) sum0(3,[3|[4|[]]])
  \(\xrightarrow{\smash[t]{\gamma}}\) sum0(3+3,[4|[]])           \(=\) sum0(6,[4|[]])
  \(\xrightarrow{\smash[t]{\beta}}\) 4 + 6                      \(=\) 10\textrm{.}
\end{alltt}
Par contraste, souvenons-nous de l'évaluation suivante:
\begin{verbatim}
sum([1|[2|[3|[4|[]]]]]) -> 1+sum([2|[3|[4|[]]]])
                        -> 1+(2+sum([3|[4|[]]]))
                        -> 1+(2+(3+sum([4|[]])))
                        -> 1+(2+(3+(4))).
\end{verbatim}
La différence entre \erlcode{sum0/1} et \erlcode{sum/1} ne réside pas
dans le résultat (les deux fonctions sont bien équivalentes) mais dans
la manière dont les additions sont effectuées. Elles sont équivalentes
parce
\begin{equation*}
4 + (3 + (2 + (1 + 0))) = 1 + (2 + (3 + 4)).
\end{equation*}
Cette égalité est vraie parce que, pour tout nombre \(x\), \(y\) et
\(z\),\label{proof_sum}
\begin{enumerate}

  \item \label{add_assoc} l'addition est associative: \(x + (y + z) =
    (x + y) + z\),

  \item \label{add_comm} l'addition est symétrique: \(x + y = y +
    x\),

  \item \label{add_zero} zéro est une élément neutre à droite: \(x+0 =
    x\).

\end{enumerate}
Pour montrer exactement pourquoi, écrivons
(\(\eqn{\ref{add_assoc}}\)), (\(\eqn{\ref{add_comm}}\)) et
(\(\eqn{\ref{add_zero}}\)) pour dénoter, respectivement, l'usage de
l'associativité, de la symétrie et de la neutralité, et couchons les
égalités suivantes:
\begin{align*}
4 + (3 + (2 + (1 + 0)))
  &\eqn{\smash{\ref{add_zero}}}  4 + (3 + (2 + 1))\\
  &\eqn{\smash{\ref{add_comm}}}  (3 + (2 + 1)) + 4\\
  &\eqn{\smash{\ref{add_comm}}}  ((2 + 1) + 3) + 4\\
  &\eqn{\smash{\ref{add_comm}}}  ((1 + 2) + 3) + 4\\
  &\eqn{\smash{\ref{add_assoc}}} (1 + 2) + (3 + 4)\\
  &\eqn{\smash{\ref{add_assoc}}} 1 + (2 + (3 + 4)).\quad\Box
\end{align*}
Tout ceci semble bien compliqué, pour un si petit programme. Y a-t-il
un moyen de réécrire \erlcode{sum0/1} pour ne pas utiliser toutes les
hypothèses dans la preuve d'équivalence? Commençons avec la différence
la plus évidente: l'usage de zéro. Ce zéro est la valeur initiale de
l'accumulateur et son seul rôle est d'être ajouté au premier nombre de
la pile. Nous pourrions alors simplement initialiser l'accumulateur
avec ce nombre, donc la neutralité de zéro n'est plus requise:
\begin{alltt}
sum0(\textbf{[N|T]})   -> sum0(\textbf{N},T).
sum0(N,[M])   -> M+N;
sum0(N,[M|S]) -> sum0(M+N,S).
\end{alltt}
Mais cette définition de \erlcode{sum0/1} échoue sur des piles
contenant exactement un nombre, parce que \erlcode{T}~peut être la
pile vide. Donc, nous devons autoriser la pile à être vide dans la
définition de \erlcode{sum0/2}:
\begin{alltt}
sum0([N|T])   -> sum0(N,T).
\textbf{sum0(N,   []) -> N;}
sum0(N,[M|S]) -> sum0(M+N,S).
\end{alltt}
Nous pouvons maintenant aisément nous débarrasser de l'hypothèse que
l'addition est symétrique en replaçant \erlcode{M+N} par
\erlcode{N+M}:
\begin{alltt}
sum0([N|T])   -> sum0(N,T).
sum0(N,   []) -> N;
sum0(N,[M|S]) -> sum0(\textbf{N+M},S).
\end{alltt}
Étiquetons à nouveau les flèches:
\begin{alltt}
sum0([N|T])   \(\xrightarrow{\smash[t]{\alpha}}\) sum0(N,T).
sum0(N,   []) \(\xrightarrow{\smash[t]{\beta}}\) N;
sum0(N,[M|S]) \(\xrightarrow{\smash[t]{\gamma}}\) sum0(N+M,S).
\end{alltt}
et considérons encore notre exemple filé:
\begin{alltt}
sum0([1|[2|[3|[4|[]]]]])
          \(\xrightarrow{\smash[t]{\alpha}}\) sum0(1,[2|[3|[4|[]]]])
          \(\xrightarrow{\smash[t]{\gamma}}\) sum0(1+2,[3|[4|[]]])   \(=\) sum0(3,[3|[4|[]]])
          \(\xrightarrow{\smash[t]{\gamma}}\) sum0(3+3,[4|[]])       \(=\) sum0(6,[4|[]])
          \(\xrightarrow{\smash[t]{\gamma}}\) sum0(4+6,[])           \(=\) sum0(10,[])
          \(\xrightarrow{\smash[t]{\beta}}\) 10\textrm{.}
\end{alltt}
Cette fois, la suite d'additions correspond à \(((1+2)+3)+4\), que
nous savons prouver être égal à \(1+(2+(3+4))\) à l'aide de
l'associativité seulement:
\begin{equation*}
((1 + 2) + 3) + 4
  \eqn{\ref{add_assoc}} (1 + 2) + (3 + 4)
  \eqn{\ref{add_assoc}} 1 + (2 + (3 + 4)).\quad\Box
\end{equation*}
Qu'en est-il de l'efficacité et de l'usage de la mémoire par
\erlcode{sum0/1}? Il est aisé de voir que chaque réécriture par les
clauses~\clause{\beta} et~\clause{\gamma} s'occupe d'un entier
exactement, donc le nombre total d'étapes est le nombre d'entiers plus
un, dû à l'appel initial avec la clause~\clause{\alpha}. En d'autres
termes, si la pile d'entrée contient \(n\)~entiers, le nombre de
réécritures dans une évaluation est exactement \(n+1\).

Renommons \erlcode{sum0/1} en \fun{sum\(_0\)/1} à la
\fig~\vref{fig:sum0}.
\begin{figure}[b]
\begin{equation*}
\boxed{%
\begin{array}{@{}r@{\;}l@{\;}l@{}}
\fun{sum}_0(\cons{n}{t}) & \xrightarrow{\smash{\gamma}}
                         & \fun{sum}_0(n,t).\\
      \fun{sum}_0(n,\el) & \xrightarrow{\smash{\delta}} & n;\\
\fun{sum}_0(n,\cons{m}{s}) & \xrightarrow{\smash{\epsilon}}
                           & \fun{sum}_0(n+m,s).
\end{array}}
\end{equation*}
\caption{Somme d'entiers dans une pile avec \fun{sum\(_0\)/1}}
\label{fig:sum0}
\end{figure}
Considérons l'arbre de syntaxe abstraite des expressions réécrites à
la \fig~\ref{fig:sum0_1234}.
\begin{figure}
\centering
\includegraphics{sum0_1234}
\caption{Arbres de syntaxe abstraite de \(\fun{sum}_0([1,2,3,4])
  \twoheadrightarrow 10\)}
\label{fig:sum0_1234}
\end{figure}
Les arbres intermédiaires de~\(m+n\) ont été ignorés pour mettre en
valeur la décroissance stricte de la taille des arbres et la constance
de la taille du contexte.

\paragraph{Multiplication}

Envisageons la multiplication de tous les entiers d'une pile
donnée. La première chose qui devrait venir à l'esprit est que ce
problème est très similaire au précédent, seul l'opérateur
arithmétique est différent, donc la définition suivante peut être
écrite immédiatement, par modification de \erlcode{sum/1}:
\begin{verbatim}
mult([N])   -> N;
mult([N|S]) -> N * mult(S).
\end{verbatim}
Une définition en forme terminale peut être dérivée comme
\erlcode{sum0/1}:
\begin{verbatim}
mult0([N|T])   -> mult0(N,T).
mult0(N,   []) -> N;
mult0(N,[M|S]) -> mult0(N*M,S).
\end{verbatim}
La raison pour laquelle \erlcode{mult0/1} équivaut à \erlcode{mult/1}
est la même que celle qui fait que \erlcode{sum0/1} et \erlcode{sum/1}
sont équivalentes aussi: l'opérateur arithmétique (\erlcode{*}) est
associatif, tout comme (\erlcode{+}).

Quelle amélioration est ici possible et ne l'était pas avec
\erlcode{sum0/1}? En d'autres termes, qu'est-ce qui peut accélérer une
longue composition de multiplications? L'occurrence d'un zéro au
moins, par exemple. Dans ce cas, il n'est pas nécessaire de continuer
les multiplications, parce que le résultat sera nul de toute
façon. Cette optimisation peut être apportée en isolant le cas où
\erlcode{N}~est~\erlcode{0}:
\begin{alltt}
mult0([N|T])   -> mult0(N,T).
mult0(N,   []) -> N;
\textbf{mult0(N,[0|S]) -> 0;}\hfill% \emph{Amélioration.}
mult0(N,[M|S]) -> mult0(N*M,S).
\end{alltt}
Est-ce que la présence d'un zéro est fréquente? Dans le pire des cas,
il n'y a pas de zéro et donc la clause ajoutée est inutile. Mais, si
l'on sait qu'un zéro est présent dans l'entrée avec une probabilité
plus grande que pour les autres nombres, cette clause supplémentaire
peut se révéler utile au long cours, c'est-à-dire en moyenne, pour
différentes exécutions du programme. En fait, même si les nombres sont
uniformément répandu sur un interval qui inclut zéro, nous devrions
conserver la clause.
\index{langage fonctionnel!forme terminale|)}
\index{mémoire|)}
\label{sec:tail_call_opt}

\mypar{Synonymie}
\index{mémoire!synonymie|(}
\index{pile!aplatissement!synonymie|(}

À la section~\ref{sec:persistence}, nous avons supposé que le partage
entre le motif et le membre droit d'une même règle était maximal. En
pratique, les compilateurs n'assurent pas cette propriété et les
programmeurs doivent expliciter le partage lorsqu'il va au-delà de
simples variables. Par exemple, examinons à nouveau la
\fig~\vref{fig:flat0} où la fonction \fun{flat\(_0\)/1} est
définie. En \Erlang, le partage maximum à la règle~\(\gamma\) est
réalisé en nommant \(\cons{x}{s}\) dans le motif et en réutilisant ce
nom dans le membre droit. Ce nom est un \emph{synonyme} (anglais,
\emph{alias}). La syntaxe est évidente:
\begin{alltt}
flat0(         []) -> [];
flat0(     [[]|T]) -> flat0(T);
flat0([\textbf{S=[\_|\_]}|T]) -> cat(flat0(\textbf{S}),flat0(T));\hfill% \emph{Synonymie}
flat0(      [Y|T]) -> [Y|flat0(T)].
\end{alltt}
\index{pile!aplatissement!synonymie|)} \index{pile!compression|(} Un
autre exemple est la fonction \fun{red/1} (anglais, \emph{reduce}),
vue à la \fig~\vref{fig:red} et qui recopie la pile donnée tout en
écartant les éléments qui sont successivement répétés:
\begin{equation*}
\begin{array}{@{}r@{\;}l@{\;}l@{}}
\fun{red}(\el)           & \rightarrow & \el;\\
\fun{red}(\cons{x,x}{s}) & \rightarrow & \fun{red}(\cons{x}{s});\\
\fun{red}(\cons{x}{s})   & \rightarrow & \cons{x}{\fun{red}(s)}.
\end{array}
\end{equation*}
Par exemple, \(\fun{red}([4,2,2,1,1,1,2]) \twoheadrightarrow
[4,2,1,2]\). La traduction en \Erlang avec partage maximum est
\begin{alltt}
red(         []) -> [];
red([X|\textbf{S=[X|\_]}]) -> red(\textbf{S});
red(      [X|S]) -> [X|red(S)].
\end{alltt}
\index{pile!compression|)}

\index{tri par interclassement!synonymie|(}
\noindent Un autre cas important est l'interclassement à la
\fig~\vref{fig:mrg}:
\begin{equation*}
\begin{array}{@{}r@{\;}l@{\;}l@{}}
\fun{mrg}(\el,t)         & \rightarrow & t;\\
\fun{mrg}(s,\el)         & \rightarrow & s;\\
\fun{mrg}(\cons{x}{s},\cons{y}{t}) & \rightarrow
& \cons{y}{\fun{mrg}(\cons{x}{s},t)},\;\text{si \(x \succ y\)};\\
\fun{mrg}(\cons{x}{s},t) & \rightarrow
                         & \cons{x}{\fun{mrg}(s,t)}.
\end{array}
\end{equation*}
La meilleure traduction est
\begin{alltt}
mrg(     [],    T)            -> T;
mrg(     S,    [])            -> S;
mrg(\textbf{S=[X|\_]},[Y|T]) when X > Y -> [Y|mrg(\textbf{S},T)];
mrg(  [X|S],    T)            -> [X|mrg(S,T)].
\end{alltt}
Nous devons faire attention aux abréviations dans les notations pour
les piles. Par exemple, la fonction \fun{tms/1}, à la
\fig~\vref{fig:tms}, devrait être traduite comme suit:
\begin{alltt}
tms([X|T=[\_|U]]) -> cutr([X],T,U);
tms(          T) -> T.
\end{alltt}
\index{tri par interclassement!synonymie|)}
\index{mémoire!synonymie|)}

\index{tri par insertion!synonymie|(}
\noindent Un autre exemple est l'insertion bidirectionnelle,
\fig~\vref{fig:i2w_def}:
\begin{equation*}
\begin{array}{@{}r@{\;}l@{\;}ll@{}}
\fun{i2w}(s)         & \xrightarrow{\smash{\xi}}
                     & \fun{i2w}(s,\el,\el).\\
\fun{i2w}(\el,\el,u) & \xrightarrow{\smash{\pi}}
                     & u;\\
\fun{i2w}(\el,\cons{y}{t},u)
                     & \xrightarrow{\smash{\rho}}
                     & \fun{i2w}(\el,t,\cons{y}{u});\\
\fun{i2w}(\cons{x}{s},t,\cons{z}{u})
                     & \xrightarrow{\smash{\sigma}}
                     & \fun{i2w}(\cons{x}{s},\cons{z}{t},u),
                     & \text{si \(x \succ z\)};\\
\fun{i2w}(\cons{x}{s},\cons{y}{t},u)
                     & \xrightarrow{\smash{\tau}}
                     & \fun{i2w}(\cons{x}{s},t,\cons{y}{u}),
                     & \text{si \(y \succ x\)};\\
\fun{i2w}(\cons{x}{s},t,u)
                     & \xrightarrow{\smash{\upsilon}}
                     & \fun{i2w}(s,t,\cons{x}{u}).
\end{array}
\end{equation*}
En \Erlang, le partage maximum exige un synonyme aux clauses
\clause{\sigma}~et~\clause{\tau}:
\begin{alltt}
i2w(S)                              -> i2w(S,[],[]).
i2w(     [],   [],    U)            -> U;
i2w(     [],[Y|T],    U)            -> i2w([],T,[Y|U]);
i2w(\textbf{V=[X|\_]},    T,[Z|U]) when X > Z -> i2w(\textbf{V},[Z|T],U);
i2w(\textbf{V=[X|\_]},[Y|T],    U) when Y > X -> i2w(\textbf{V},T,[Y|U]);
i2w(  [X|S],    T,    U)            -> i2w(S,T,[X|U]).
\end{alltt}
Remarquons que les atomes (les constructeurs constants), en
particulier la pile vide \erlcode{[]}, sont automatiquement partagés,
donc, par exemple, le synonyme~\erlcode{S} dans «~\erlcode{f(S=[]) ->
  S.}~» est inutile.\index{tri par insertion!synonymie|)}

La recherche à la Andersson avec un arbre candidat bénéficie aussi de
la synonymie. Les définitions de la \fig~\vref{fig:mem3} sont
traduites au mieux ainsi:
\begin{alltt}
mem3(Y,T) -> mem4(Y,T,T).

mem4(Y,  \{bst,X,T1,_\},        T) when X > Y -> mem4(Y,T1,T);
mem4(Y,\textbf{C=\{bst,_,_,T2\}},        _)            -> mem4(Y,T2,\textbf{C});
mem4(Y,         ext,\{bst,Y,_,_\})            -> true;
mem4(_,           ext,        _)            -> false.
\end{alltt}

Parfois, la synonymie est cruciale. Par exemple, toute la discussion à
propos de la persistance, à la section~\ref{sec:persistence}, repose
sur l'existence d'un partage maximum dans chaque règle de réécriture,
mais, ici, \Erlang a besoin de synonymes pour mettre en {\oe}uvre
cette condition, donc les définitions~\eqref{eq:push_pop_persistence}
\vpageref{eq:push_pop_persistence} \emph{doivent} être traduites comme
suit:
\begin{verbatim}
push(X,H=[S|_]) -> [[X|S]|H].
pop(T=[[X|S]|_]) -> {X,[S|T]}.
\end{verbatim}

\mypar{Pile de contrôle et tas}
\index{pile!$\sim$ de contrôle|see{mémoire, pile de contrôle}}
\index{mémoire!pile de contrôle|(}
\index{mémoire!tas|(}

La mémoire\index{mémoire} est sous la supervision exclusive du
\emph{glaneur de cellules} (anglais, \emph{garbage collector}). Il
s'agit d'un processus qui a constamment accès aux graphes orientés
sans circuits et dont la tâche consiste à trouver les n{\oe}uds qui
sont devenus inutiles durant les évaluations. Il récupère alors
l'espace associé, de telle sorte que les n{\oe}uds créés après
puissent trouver assez de place. Ce chapitre a pour ambition de
démontrer que le concept de \emph{pile de contrôle} et de \emph{tas}
jaillissent naturellement quand une analyse détaillée montre comment
ces n{\oe}uds peuvent être automatiquement supprimés dès qu'ils
deviennent inutiles, facilitant ainsi le travail du glaneur de
cellules et améliorant l'efficacité de la gestion de la mémoire. Notre
étude montrera en plus que les appels à des fonctions en forme
terminale peuvent être optimisés\index{mémoire!optimisation des appels
  terminaux} pour que la quantité totale de mémoire nécessaire à
l'évaluation d'un appel soit réduite.

Pour une meilleure compréhension de la gestion de la mémoire, nous
avons besoin de rendre le partage explicite, comme dans la définition
de \fun{sum/1} à la \fig~\vref{fig:sum_dag}.
\begin{figure}
\centering
\includegraphics{sum_dag}%[bb=71 666 237 721]
\caption{Définition de \fun{sum/1} avec partage maximum}
\label{fig:sum_dag}
\end{figure}
Évaluons \(\fun{sum}([3,7,5])\) et montrons les premières réécritures
à la \fig~\vref{fig:sum375_push},
\begin{figure}[b]
\centering
\includegraphics{sum375_push}
\caption{Évaluation de \(\fun{sum}([3,7,5])\) avec un graphe (phase 1/2)}
\label{fig:sum375_push}
\end{figure}
où l'état complet de la mémoire est figuré comme une succession
d'instantanés entre des flèches hachurées. \index{graphe orienté sans
  circuit} Les flèches sont hachurées pour les distinguer de celles
dans la définition, puisque chaque règle de réécriture est appliquée
en général seulement à des parties d'arbres, et nous voulons montrer
toutes les données après chaque réécriture.

Naturellement, cela donne envie de savoir comment la valeur de l'appel
originel est finalement trouvée (\(15\)). En examinant la
\fig~\ref{fig:sum375_push} et en comparant les instantanés de la
mémoire de la gauche vers la droite, nous réalisons que les
racines~(\(+\)) ont été accumulées à la droite de l'appel originel,
jusqu'à ce qu'une référence à une valeur a été atteinte, ici
l'entier~\(5\). Ce processus est analogue à empiler des éléments, bien
que la pile en question ne contienne pas seulement des valeurs, mais
aussi des expressions comme \(7 + \fun{sum}([5])\), et nous le nommons
«~phase d'empilage.~» Ceci nous invite à effectuer l'opération inverse,
c'est-à-dire le dépilage des expressions en question de manière à
terminer l'évaluation, et que nous appelons «~phase de dépilage.~» Plus
précisément, nous voulons calculer, de la droite vers la gauche, des
\emph{valeurs} à partir des arbres qui composent le graphe, dont les
racines sont considérées des éléments dans une pile spéciale, jusqu'à
ce que l'arbre correspondant à l'appel originel est atteint et est
associé avec sa valeur, qui est, par définition, le résultat final.

Une valeur peut être \emph{immédiate}, comme les entiers, les atomes
et les piles vides, ou bien \emph{construite}, comme les piles
non-vides et les \(n\)-uplets. Nous pourrions aussi avoir affaire à
des \emph{références} à des valeurs, qui sont graphiquement
représentées par des arcs; par exemple, l'arbre le plus à droite dans
le graphe est une référence à la valeur immédiate~\(5\). \emph{Quand
  l'arbre le plus à droite est une valeur immédiate ou une référence à
  une valeur, la seconde phase de l'évaluation (vers la gauche) peut
  commencer.} Dans ce qui suit, pour gagner en concision, nous
écrirons «~valeur~» quand une référence à une valeur est aussi possible.

Bien que notre modèle d'évaluation raffiné ne fasse aucune place à la
suppression de n{\oe}uds parce que celle-ci est la tâche exclusive du
glaneur de cellules, il permet cependant le remplacement par sa valeur
de l'arc aboutissant au dernier appel réécrit. Comme nous l'avons
expliqué précédemment, ces appels ont été successivement encadrés à la
\fig~\vref{fig:sum375_push}. La phase de dépilage consiste ici à
remplacer l'arc vers le n{\oe}ud \fun{sum} précédent par un arc vers
la valeur courante. Ensuite, l'arbre ainsi modifié est évalué à son
tour, et cela mène peut-être à l'empilement d'autres arbres et des
phases subséquentes de dépilage jusqu'à ce qu'une seule valeur soit
présente dans la pile.

La phase de dépilage est montrée en action à la \fig~\vref{fig:sum375_pop},
\begin{figure}[b]
\centering
\includegraphics{sum375_pop}
\caption{Évaluation de \(\fun{sum}([3,7,5])\) (phase 2/2)}
\label{fig:sum375_pop}
\end{figure}
qui doit être lue de droite à gauche. L'état de la mémoire le plus à
droite est le résultat de la phase d'empilage précédente, à partir du
dernier état de la \fig~\ref{fig:sum375_push}. Remarquons que tous les
n{\oe}uds \fun{sum} et~(\(+\)) deviennent inutiles, pas à pas,
c'est-à-dire qu'ils ne peuvent être atteints depuis la pile (ces
n{\oe}uds se trouvent sous la ligne de base horizontale). À des fins
d'illustration, nous avons fait disparaître tous les n{\oe}uds~(\(+\))
dès que possible et trois n{\oe}uds \fun{sum} sont réclamés par le
glaneur de cellules, le premier inclus, à savoir le plus à gauche. La
flèche hachurée la plus à gauche a pour exposant~\(2\) parce qu'elle
combine à elle seule deux étapes (\(3+12 \rightarrow 15\) et écarter
le n{\oe}ud \fun{sum}), pour faire court. \emph{Un n{\oe}ud est utile
  s'il peut être atteint d'une des racines du graphe.} Gardons à
l'esprit que l'argument de l'appel originel, à savoir \([3,7,5]\),
peut ne pas être glané, selon qu'il est partagé ou non (un partage
avec un arbre hors de la figure, donc dans un contexte). Le n{\oe}ud
intermédiaire contenant la valeur~\(12\) a été glané aussi en chemin,
pour suggérer que le glanage de cellules est entrelacé avec
l'évaluation ou, en adhérant à un cadre multiprocesseur, nous dirions
que le glanage et le calcul s'exécutent en parallèle, partageant le
même espace mémoire mais sans interférences du point de vue du
programmeur (seuls les n{\oe}uds qui deviennent inatteignables sont
éliminés).

Notre exemple requiert un examen plus approfondi. En effet, nous
pouvons prédire exactement quand les n{\oe}uds \fun{sum} peuvent être
réclamés: après chaque pas en arrière (de la droite vers la gauche à
la \fig~\ref{fig:sum375_pop}), le n{\oe}ud \fun{sum} le plus à droite
devient inutile. Idem pour la valeur intermédiaire~\(12\): elle
devient inaccessible depuis les racines du graphe dès qu'elle a servi
à calculer~\(15\). La même observation peut être faite à propos des
n{\oe}uds~(\(+\)). Tous ces faits signifient que, dans notre exemple,
nous n'avons pas besoin de compter sur le glaneur de cellules pour
identifier l'inutilité de ces n{\oe}uds particuliers: mettons vraiment
en {\oe}uvre une pile d'expressions comme un méta-objet, plutôt que de
seulement s'appuyer sur une analogie et de ranger tout dans le même
espace indistinct. La mémoire gérée par le glaneur de cellules est
appelée le \emph{tas}, en contraste avec notre nouvelle pile, appelée
la \emph{pile de contrôle}. Le tas et la pile de contrôle sont
distincts et complémentaires, constituant à eux deux la mémoire
totale. Par ailleurs, pour des raisons techniques de mise en
{\oe}uvre, la pile de contrôle ne contient jamais de valeurs
construites, mais des références à celles-ci dans le tas.

Considérons comment le calcul à la \fig~\vref{fig:sum375_pop} peut
être amélioré à la \fig~\vref{fig:sum375_pop1} avec un glanage
automatique fondé sur une pile.
\begin{figure}[b]
\centering
\includegraphics{sum375_pop1}
\caption{Évaluation de \(\fun{sum}([3,7,5])\) (phase 2/2, pile et tas)}
\label{fig:sum375_pop1}
\end{figure}
Gardons en tête que la valeur \([3,7,5]\) est rangée dans le tas, pas
dans la pile de contrôle, et qu'elle peut être partagée. De plus, à
cause de l'espace limité sur une page, la dernière étape est en fait
double, comme elle l'était à la \fig~\vref{fig:sum375_pop}. Nous
pouvons saisir la croissance de la pile de contrôle à la
\fig~\vref{fig:sum375_stack_push}.
\begin{figure}
\centering
\includegraphics{sum375_stack_push}
\caption{Pile de contrôle pour évaluer \(\fun{sum}([3,7,5])\) (phase 1/2)}
\label{fig:sum375_stack_push}
\end{figure}
Les dépilages, de droite à gauche, sont présentés à la
\fig~\ref{fig:sum375_stack_pop}.
\begin{figure}
\centering
\includegraphics{sum375_stack_pop}
\caption{Pile de contrôle pour évaluer \(\fun{sum}([3,7,5])\) (phase 2/2)}
\label{fig:sum375_stack_pop}
\end{figure}

L'algorithme correspondant consiste en les étapes suivantes. Supposons
d'abord que la pile de contrôle n'est pas vide et que l'élément à son
sommet est une valeur immédiate ou une référence à une valeur, bien
que nous les qualifierons toutes deux de valeurs dans la suite.
\begin{enumerate}

  \item Tant que la pile de contrôle contient au moins deux objets,
    dépilons la valeur, mais sans l'écarter, donc un autre arbre
    devient le sommet;
    \begin{enumerate}

    \item si la racine de l'arbre au sommet est un n{\oe}ud \fun{sum},
      alors nous le dépilons et empilons à sa place la valeur;

    \item sinon, le n{\oe}ud \fun{sum} dans l'arbre possède un arc
      entrant:
      \begin{enumerate}

      \item nous changeons sa destination de telle sorte qu'il
        atteigne la valeur et nous nous débarrassons du n{\oe}ud
        \fun{sum};

      \item nous évaluons l'arbre modifié au sommet et nous itérons le
        procédé.

      \end{enumerate}

    \end{enumerate}

  \item L'unique élément restant dans la pile de contrôle est le résultat.

\end{enumerate}
En fait, nous avons permis la résidence des entiers dans la pile de
contrôle, car nous pouvions ainsi remplacer tout arbre qui consiste
seulement en une référence vers cette sorte de valeur dans le tas par
une copie de ladite valeur. Nous pouvons voir à la
\fig~\ref{fig:sum375_stack_push} que la pile de contrôle croît à
chaque étape jusqu'à ce qu'une valeur est atteinte.
\index{mémoire!tas|)} \index{mémoire!pile de contrôle|)}

\mypar{Optimisation des appels terminaux}
\index{mémoire!optimisation des appels terminaux|(}
\index{langage fonctionnel!forme terminale|(}

Étudions ce qui se passe quand nous utilisons une définition
équivalente en forme terminale, telle \fun{sum\(_0\)/1} à la
\fig~\vref{fig:sum0}. La \fig~\ref{fig:sum0_375}
\begin{figure}[!t]
\centering
\includegraphics[bb=71 630 356 721]{sum0_375_0}

\includegraphics[bb=71 626 352 721]{sum0_375_1}

\includegraphics[bb=71 636 394 721]{sum0_375_2}
\caption{\(\fun{sum}_0([3,7,5]) \twoheadrightarrow 15\)
  sans optimisation des appels terminaux}
\label{fig:sum0_375}
\end{figure}
montre seulement la première phase, qui consiste à empiler sur la pile
de contrôle l'arbre nouvellement produit par une règle et à partager
les sous-arbres dénotés par des variables (en incluant les synonymes)
qui sont présents dans le motif et le membre droit. La seconde phase
consiste à dépiler les racines accumulées de façon à reprendre les
contextes d'appels en suspend et, à la fin, le résultat final se
trouve dans la pile de contrôle.

Dans le cas de \fun{sum\(_0\)/1}, nous avons déjà trouvé le résultat
après la première phase:~\(15\). Par conséquent, dans ce cas, la
seconde phase ne contribue pas à construire la valeur, ce qui nous
amène à nous interroger sur l'utilité de conserver les arbres
antérieurs. En effet, ceux-ci deviennent inutiles après chaque
empilage et une optimisation fréquente, appelée \emph{optimisation des
  appels terminaux} et mise en {\oe}uvre par les compilateurs de
langages fonctionnels, consiste à dépiler l'arbre qui précède (celui
filtré par le motif de la règle) et à empiler le nouveau (créé par le
membre droit de la même règle). De cette manière, la pile de contrôle
ne contient qu'un élément à tout instant. Cette optimisation est
montrée à la \fig~\vref{fig:sum0_375tco}
\begin{figure}[!t]
\centering
\includegraphics[bb=71 628 327 721]{sum0_375tco0}
\includegraphics[bb=71 628 350 721]{sum0_375tco1}
\includegraphics[bb=71 636 375 721]{sum0_375tco2}
\caption{\(\fun{sum}_0([3,7,5])
  \twoheadrightarrow 15\) avec optimisation des appels terminaux}
\label{fig:sum0_375tco}
\end{figure}
et devrait être contrastée avec la série à la \fig~\vref{fig:sum0_375}.

\emph{L'optimisation des appels terminaux peut être appliquée à toutes
  les fonctions en forme terminale.} Visualisons un autre exemple:
l'évaluation de \(\fun{cat}([1,2],[3,4])\), en employant la définition
à la \fig~\vref{fig:cat_dag}, qui n'est pas en forme terminale.
\begin{enumerate}

  \item La première phase, qui consiste à empiler les arbres
  nouvellement créés sur la pile de contrôle est montré à la
  \fig~\vref{fig:cat1234_push}.

  \item La seconde phase de l'évaluation de \(\fun{cat}([1,2],[3,4])\)
  est montrée à la \fig~\vref{fig:cat1234_pop}. Elle consiste à
  remplacer de la droite vers la gauche la référence à l'appel
  précédent par la (référence à la) valeur courante, jusqu'à ce que
  l'appel initial lui-même soit ôté et seul le résultat final
  demeure. Remarquons que le second argument, \([3,4]\), est en fait
  partagé avec le résultat \([1,2,3,4]\) et qu'aucune optimisation
  n'est possible.

\end{enumerate}
\begin{figure}[!t]
\centering
\subfloat[Fin de la phase 1/2\label{fig:cat1234_push}]{
\includegraphics[bb=71 615 287 734]{cat1234_push}
%\caption{Evaluation of \(\fun{cat}([1,2],[3,4])\) (end of phase 1/2)
%\label{fig:cat1234_push}}
}
\vskip32pt
%\end{figure}
%\begin{figure}
%\centering
\subfloat[Phase 2/2\label{fig:cat1234_pop}]{
\begin{minipage}[l]{0.9\textwidth}
\centering
\includegraphics[bb=71 613 287 714]{cat1234_pop0}
\vskip4.8pt
\includegraphics[bb=71 612 287 724]{cat1234_pop1}
\vskip5pt
\includegraphics[bb=71 612 287 722]{cat1234_pop2}
\end{minipage}
}
\caption{\(\fun{cat}([1,2],[3,4]) \twoheadrightarrow [1,2,3,4]\)} %(phase 2/2)
%\label{fig:cat1234_pop}}
\end{figure}
\index{mémoire!optimisation des appels terminaux|)}

%\vspace*{-5mm}

\mypar{Transformation en forme terminale}
\label{sec:into_tail_form}
\index{pile!aplatissement!forme terminale|(}

Notre définition de \fun{flat/1} à la \fig~\vref{fig:flat}, est
facilement traduite en \Erlang comme suit: \verbatiminput{flat.def}
Elle est presque en forme terminale: seule la dernière règle possède
un appel avec un contexte non-vide. En ajoutant un accumulateur, cette
définition peut être transformée en une définition équivalente en
forme terminale. Le but de cet accumulateur est de conserver les
variables qui apparaissent dans les instances du contexte, pour que
celles-ci puissent être reconstruites et évaluées après que l'appel
courant l'est. Donc adjoignons une pile d'accumulation~\erlcode{A},
laissée telle quelle par toutes les clauses, et ajoutons une nouvelle
définition \erlcode{flat\_tf/1} qui appelle la version de
\erlcode{flat/2} augmentée avec la valeur initiale de l'accumulateur,
ici la pile vide:
\begin{alltt}
\textbf{flat_tf(T)        \(\xrightarrow{\smash{\alpha}}\) flat(T,[]).}
flat(       [],\textbf{A}) \(\xrightarrow{\smash{\beta}}\) [];\hfill% A \emph{inutile pour le moment}
flat(   [[]|T],\textbf{A}) \(\xrightarrow{\smash{\gamma}}\) flat(T,\textbf{A});
flat([[X|S]|T],\textbf{A}) \(\xrightarrow{\smash{\delta}}\) flat([X,S|T],\textbf{A});
flat(    [X|T],\textbf{A}) \(\xrightarrow{\smash{\epsilon}}\) [X|flat(T,\textbf{A})].
\end{alltt}
Maintenant, nous devons accumuler une valeur à chaque appel qui n'est
pas en forme terminale (ici, à la clause~\(\epsilon\)), et utiliser le
contenu de l'accumulateur dans toutes les clauses où il n'y a pas
d'appel (ici, à la clause~\(\alpha\)). La technique consiste à
accumuler dans la clause~\(\epsilon\) les valeurs du contexte d'appel,
\erlcode{[X|\textvisiblespace]}; en d'autres termes, nous
empilons~\erlcode{X} sur~\erlcode{A}:
\begin{alltt}
flat_tf(T)        \(\smashedrightarrow{\alpha}\) flat(T,[]).
flat(       [],A) \(\smashedrightarrow{\beta}\) [];
flat(   [[]|T],A) \(\smashedrightarrow{\gamma}\) flat(T,A);
flat([[X|S]|T],A) \(\smashedrightarrow{\delta}\) flat([X,S|T],A);
flat(    [X|T],A) \(\smashedrightarrow{\epsilon}\) flat(T,\textbf{[X|}A\textbf{]}).\hfill% \emph{Ici}
\end{alltt}
Quand l'entrée est entièrement parcourue, à la clause~\(\beta\),
l'accumulateur contient tous les éléments qui ne sont pas des piles
(tous les~\erlcode{X} de la clause~\(\epsilon\)) en ordre inverse par
rapport à la pile originelle; par conséquent, ils doivent être
retournés:
\begin{alltt}
flat_tf(T)        \(\smashedrightarrow{\alpha}\) flat(T,[]).
flat(       [],A) \(\smashedrightarrow{\beta}\) \textbf{rev(A)};
flat(   [[]|T],A) \(\smashedrightarrow{\gamma}\) flat(T,A);
flat([[X|S]|T],A) \(\smashedrightarrow{\delta}\) flat([X,S|T],A);
flat(    [X|T],A) \(\smashedrightarrow{\epsilon}\) flat(T,[X|A]).
\end{alltt}
La définition est maintenant complète et en forme terminale. Qu'en
est-il de \erlcode{flat0/1} à la \fig~\vref{fig:flat0}? Nous avons:
\verbatiminput{flat0.def} Cette définition a la particularité que
certaines de ses clauses contiennent au moins deux appels (n'oublions
pas que le fait qu'un appel soit récursif n'a rien à voir avec le fait
d'être en forme terminale ou non).

Commençons par ajouter un accumulateur à \erlcode{flat0/1} et posons
que sa valeur initiale est la pile vide:
\begin{alltt}
\textbf{flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).}\hfill% \emph{Ajout}
flat0(         [],\textbf{A}) \(\smashedrightarrow{\gamma}\) [];\hfill% A \emph{inutile pour le moment}
flat0(     [[]|T],\textbf{A}) \(\smashedrightarrow{\delta}\) flat0(T,\textbf{A});
flat0([Y=[\_|\_]|T],\textbf{A}) \(\smashedrightarrow{\epsilon}\) cat(flat0(Y,\textbf{A}),flat0(T,\textbf{A}));
flat0(      [Y|T],\textbf{A}) \(\smashedrightarrow{\zeta}\) [Y|flat0(T,\textbf{A})].
cat(   [],T)         \(\smashedrightarrow{\eta}\) T;
cat([X|S],T)         \(\smashedrightarrow{\theta}\) [X|cat(S,T)].
\end{alltt}
Décidons qu'à la clause~\(\epsilon\), le premier appel à être réécrit
est l'appel récursif \erlcode{flat0(Y,A)}, dont le
contexte est \erlcode{cat(\textvisiblespace,flat0(T,A))}. Par
conséquent, dans la clause~\(\epsilon\), sauvegardons~\erlcode{T}
dans~\erlcode{A} pour pouvoir reconstruire le contexte dans le membre
droit de~\(\gamma\), où la pile courante à traiter est vide et donc
les piles empilées dans l'accumulateur nous permettent de reprendre
l'aplatissement:
\begin{alltt}
flat0\_tf(T)              \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],\textbf{[T|}A\textbf{]}) \(\smashedrightarrow{\gamma}\) \textbf{cat(}[]\textbf{,flat0(T,A))};\hfill% \emph{Utile}
flat0(     [[]|T],    A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],    A) \(\smashedrightarrow{\epsilon}\) flat0(Y,\textbf{[T}|A\textbf{]});\hfill% \emph{Empilage}
flat0(      [Y|T],    A) \(\smashedrightarrow{\zeta}\) [Y|flat0(T,A)].
cat(   [],T)             \(\smashedrightarrow{\eta}\) T;
cat([X|S],T)             \(\smashedrightarrow{\theta}\) [X|cat(S,T)].
\end{alltt}
Mais une clause est maintenant manquante: que se passe-t-il si
l'accumulateur est vide? Par conséquent, une clause~\(\beta\) doit
être ajoutée avant la clause~\(\gamma\) pour gérer cette situation:
\begin{alltt}
flat0_tf(T)              \(\smashedrightarrow{\alpha}\) flat0(T,[]).
\textbf{flat0(         [],   []) \(\smashedrightarrow{\beta}\) [];}
flat0(         [],[T|A]) \(\smashedrightarrow{\gamma}\) cat([],flat0(T,A));
flat0(     [[]|T],    A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],    A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[T|A]);
flat0(      [Y|T],    A) \(\smashedrightarrow{\zeta}\) [Y|flat0(T,A)].
cat(   [],T)             \(\smashedrightarrow{\eta}\) T;
cat([X|S],T)             \(\smashedrightarrow{\theta}\) [X|cat(S,T)].
\end{alltt}
Nous pouvons simplifier le membre droit de la clause~\(\gamma\) parce
que la définition de \erlcode{cat/2} est devenue inutile:
\begin{alltt}
flat0\_tf(T)              \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],   []) \(\smashedrightarrow{\beta}\) [];
flat0(         [],[T|A]) \(\smashedrightarrow{\gamma}\) \textbf{flat0(T,A)};\hfill% \emph{Simplification}
flat0(     [[]|T],    A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],    A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[T|A]);
flat0(      [Y|T],    A) \(\smashedrightarrow{\zeta}\) [Y|flat0(T,A)].
\end{alltt}
La clause~\(\zeta\) n'est pas en forme terminale. Nous ne pouvons
simplement empiler~\erlcode{Y} sur l'accumulateur ainsi:
\begin{alltt}
flat0(      [Y|T],    A) \(\smashedrightarrow{\zeta}\) flat0(T,\textbf{[Y|}A\textbf{]}).\hfill% \emph{Faux}
\end{alltt}
parce que ce dernier contient des piles à aplatir ultérieurement (voir
la clause~\(\epsilon\)) et \erlcode{Y}~n'est pas une pile (cette
modification mènerait à une erreur de filtrage juste après le filtrage
de la clause~\(\gamma\), parce que tous les motifs ne filtrent que des
piles). Que pouvons-nous faire? La première idée qui vient peut-être à
l'esprit est d'ajouter un autre accumulateur pour contenir les
éléments qui ne sont pas des piles, comme~\erlcode{Y}. À la base, il
s'agirait-là exactement de la même méthode que précédemment, sauf
qu'elle serait appliquée à un autre accumulateur,
disons~\erlcode{B}. Ajoutons d'abord~\erlcode{B} partout et
initialisons-le avec \erlcode{[]}:
\begin{alltt}
flat0_tf(T)                \(\smashedrightarrow{\alpha}\) flat0(T,[],\textbf{[]}).
flat0(         [],   [],\textbf{B}) \(\smashedrightarrow{\beta}\) [];\hfill% B \emph{inutile pour le moment}
flat0(         [],[T|A],\textbf{B}) \(\smashedrightarrow{\gamma}\) flat0(T,A,\textbf{B});
flat0(     [[]|T],    A,\textbf{B}) \(\smashedrightarrow{\delta}\) flat0(T,A,\textbf{B});
flat0([Y=[\_|\_]|T],    A,\textbf{B}) \(\smashedrightarrow{\epsilon}\) flat0(Y,[T|A],\textbf{B});
flat0(      [Y|T],    A,\textbf{B}) \(\smashedrightarrow{\zeta}\) [Y|flat0(T,A,\textbf{B})].
\end{alltt}
Maintenant nous pouvons sauvegarder les variables du contexte d'appel
de la clause~\(\zeta\) dans~\erlcode{B} et ôter le contexte en
question.  À la clause~\(\beta\), nous savons que
\erlcode{B}~contient, en ordre inverse, tous les éléments qui ne sont
pas des piles, donc nous devons retourner~\erlcode{B}. Puisque la
clause~\(\beta\) ne contient pas d'autres appels, c'est la fin:
\begin{alltt}
flat0_tf(T)                \(\smashedrightarrow{\alpha}\) flat0(T,[],[]).
flat0(         [],   [],B) \(\smashedrightarrow{\beta}\) \textbf{rev(B)};
flat0(         [],[T|A],B) \(\smashedrightarrow{\gamma}\) flat0(T,A,B);
flat0(     [[]|T],    A,B) \(\smashedrightarrow{\delta}\) flat0(T,A,B);
flat0([Y=[\_|\_]|T],    A,B) \(\smashedrightarrow{\epsilon}\) flat0(Y,[T|A],B);
flat0(      [Y|T],    A,B) \(\smashedrightarrow{\zeta}\) flat0(T,A,\textbf{[Y|B]}).
\end{alltt}
Un examen supplémentaire peut mener à un programme plus simple, où les
motifs ne filtrent pas de piles imbriquées:
\begin{alltt}
flat0_tf(T)       -> flat0(T,[],[]).
flat0(   [],[],B) -> rev(B);
flat0(   [], A,B) -> flat0(A,   [],    B);
flat0(  [Y], A,B) -> flat0(Y,    A,    B);\hfill% \emph{Optimisation}
flat0([Y|T], A,B) -> flat0(Y,[T|A],    B);
flat0(    Y, A,B) -> flat0(A,   [],[Y|B]).
\end{alltt}
L'inconvénient de cette approche est qu'elle requiert de nombreux
accumulateurs en général et qu'elle est \emph{ad hoc}. Au lieu
d'ajouter un accumulateur de plus pour résoudre notre problème, nous
pourrions continuer avec un seul mais en nous assurant que les valeurs
qu'il contient sont distinguées selon leur origine, donc une valeur
d'un contexte donné n'est pas confondue avec une valeur d'un autre
contexte. (Ceci était réalisé avant en utilisant un accumulateur
différent pour différentes valeurs de contexte.) La mise en {\oe}uvre
consiste alors à mettre dans un \(n\)-uplet les valeurs d'un contexte
donné avec un atome qui joue le rôle d'un marqueur identifiant
l'expression originelle contenant l'appel. Revenons à
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) [];\hfill% A \emph{inutile pour le moment}
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) cat(flat0(Y,A),flat0(T,A));
flat0(      [Y|T],A) \(\smashedrightarrow{\zeta}\) [Y|flat0(T,A)].
cat(   [],T)         \(\smashedrightarrow{\eta}\) T;
cat([X|S],T)         \(\smashedrightarrow{\theta}\) [X|cat(S,T)].
\end{alltt}
Modifions la clause~\(\epsilon\) en choisissant \erlcode{flat0(Y,A)}
comme premier appel à réécrire. Nous choisissons l'atome~\erlcode{k1}
pour représenter un appel et nous l'accouplons avec la seule valeur du
contexte, \erlcode{T}. Nous ôtons le contexte
\erlcode{cat(\textvisiblespace,flat0(T,A))} et, dans l'appel restant,
nous empilons~\erlcode{\{k1,T\}} sur l'accumulateur~\erlcode{A}:
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) [];\hfill% A \emph{inutile pour le moment}
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) \textbf{flat0(Y,[\{k1,T\}|A])};
flat0(      [Y|T],A) \(\smashedrightarrow{\zeta}\) [Y|flat0(T,A)].
cat(   [],T)         \(\smashedrightarrow{\eta}\) T;
cat([X|S],T)         \(\smashedrightarrow{\theta}\) [X|cat(S,T)].
\end{alltt}
Le point crucial est que \erlcode{k1}~ne doit pas être empilé ailleurs
que dans la clause~\(\epsilon\), qu'il identifie. Bien sûr, ce
programme n'est plus correct, car le contexte ôté doit être
reconstruit ailleurs et appliqué à la valeur de l'appel
\erlcode{flat0(Y,[\{k1,T\}|A])}. L'accumulateur~\erlcode{A}
représente, comme précédemment, les valeurs des contextes. Où
devrions-nous extraire son contenu? La clause~\(\gamma\) ne fait aucun
usage de~\erlcode{A} et ceci est un signe. Cela signifie qu'à ce
moment-là il n'y a plus de piles à aplatir, ce qui est le bon moment
pour nous demander s'il n'y a pas encore quelque chose à faire, donc
examiner le contenu de~\erlcode{A}. Pour réaliser cette tâche, une
fonction dédiée devrait être créée, disons~\erlcode{appk/2}, telle
que~\erlcode{appk(\(V\),\(A\))} calculera la suite avec ce qui se
trouve dans l'accumulateur~\(A\), la valeur~\(V\) étant un résultat
partiel, c'est-à-dire le résultat jusqu'à présent. Par contre, s'il ne
reste rien à faire, c'est-à-dire si \(A\)~est vide, alors
\erlcode{appk(\(V\),\(A\))} est réécrit en~\(V\) et c'est fini. En
d'autres termes:
\begin{alltt}
appk(V,[\{k1,T\}|A]) \(\smashedrightarrow{\kappa}\) \fbcode{cat(\fbcode{HHHHH},flat0(T,A))}\,;
appk(V,        []) \(\smashedrightarrow{\iota}\) V.\hfill% \emph{La fin}
\end{alltt}
Le cadre vide doit être rempli par la reconstruction du contexte que nous avons ôté quand \erlcode{k1} a été sauvegardé dans l'accumulateur. Le contexte en question était
\erlcode{cat(\textvisiblespace,flat0(T,A))}, à la
clause~\(\epsilon\), donc nous avons
\begin{alltt}
appk(V,[\{k1,T\}|A]) \(\smashedrightarrow{\kappa}\) cat(\fbcode{HHHHH},flat0(T,A));
appk(V,        []) \(\smashedrightarrow{\iota}\) V.
\end{alltt}
Le cadre vide restant est destiné à être rempli avec le résultat de
l'appel \erlcode{flat0(Y,[\{k1,T\}|A])}. Pour cela, deux conditions
doivent être satisfaites. D'abord, l'accumulateur dans le motif de
\erlcode{appk/2} doit être le même qu'au moment de l'appel,
c'est-à-dire qu'il doit être filtré par \erlcode{[\{k1,T\}|A]}. En
théorie, nous devrions prouver que les deux occurrences de~\erlcode{A}
dénotent bien la même valeur, mais cela nous entrainerait trop
loin. Finalement, nous devons nous assurer que lorsqu'un appel à
\erlcode{flat0/2} a terminé, un appel à \erlcode{appk/2} est effectué
avec le résultat. Quand la transformation en forme terminale sera
terminée, il ne restera aucun contexte, par définition, donc tous les
appels à \erlcode{flat0/2} aboutiront à des clauses qui ne contiennent
aucun autre appel à traiter. Un examen rapide des clauses révèle que
la clause~\(\gamma\) est la seule concernée et que \erlcode{A}~y était
inutilisé jusqu'à présent. Remplaçons donc le membre droit de cette
clause par un appel à \erlcode{appk/2}, dont le premier argument est
le résultat de l'appel courant à \erlcode{flat0/2}, c'est-à-dire le
membre droit courant, et dont le second argument est l'accumulateur
qui peut contenir encore des informations au sujet de contextes à
reconstruire et à appliquer. Nous avons
\begin{alltt}
flat0(       [],A) \(\smashedrightarrow{\gamma}\) \textbf{appk(}[],\textbf{A)};
\end{alltt}
Maintenant nous comprenons que~\erlcode{V} à la clause~\(\kappa\) est
la valeur de l'appel de fonction \erlcode{flat0(Y,[\{k1,T\}|A])}, donc
nous pouvons poursuivre en plaçant~\erlcode{V} dans le cadre vide de la clause~\(\kappa\):
\begin{alltt}
appk(V,[\{k1,T\}|A]) \(\smashedrightarrow{\kappa}\) cat(\textbf{V},flat0(T,A));
\end{alltt}
Un coup d'{\oe}il suffit pour comprendre que la clause~\(\kappa\)
n'est pas en forme terminale. Par conséquent, itérons la même
technique. Le premier appel qui doit être réécrit
est~\erlcode{flat0(T,A)}, dont le contexte est
\erlcode{cat(V,\textvisiblespace)}. Associons la variable~\erlcode{V}
dans ce contexte avec un nouvel atome~\erlcode{k2} et empilons les
deux sur l'accumulateur:
\begin{alltt}
appk(V,[\{k1,T\}|A]) \(\smashedrightarrow{\kappa}\) flat0(T,\textbf{[\{k2,V\}|}A\textbf{]});
\end{alltt}
Nous avons besoin d'une nouvelle clause de \erlcode{appk/2} qui traite
le cas correspondant, c'est-à-dire lorsque la valeur de l'appel aura
été obtenue et le contexte devra être reconstruit et évalué:
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) appk([],A);
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[\{k1,T\}|A]);
flat0(      [Y|T],A) \(\smashedrightarrow{\zeta}\) [Y|flat0(T,A)].
cat(   [],T)         \(\smashedrightarrow{\eta}\) T;
cat([X|S],T)         \(\smashedrightarrow{\theta}\) [X|cat(S,T)].
\textbf{appk(V,[\{k2,W\}|A])   \(\smashedrightarrow{\lambda}\) cat(W,V);}\hfill% A \emph{inutile pour le moment}
appk(V,[\{k1,T\}|A])   \(\smashedrightarrow{\kappa}\) flat0(T,[\{k2,V\}|A]);
appk(V,        [])   \(\smashedrightarrow{\iota}\) V.
\end{alltt}
Remarquons qu'à la clause~\(\lambda\), nous avons renommé~\erlcode{V}
(dans l'accumulateur) en~\erlcode{W}, de manière à éviter une
collision avec le premier argument de \erlcode{appk/2}.

D'ailleurs, pourquoi avons-nous \erlcode{cat(W,V)} et non
\erlcode{cat(V,W)}?  L'explication est trouvée en nous souvenant que
\erlcode{W}~dénote la valeur de l'appel \erlcode{flat0(Y)} (dans la
définition originelle), alors que \erlcode{V}~représente la valeur de
\erlcode{flat0(T)} (dans la définition originelle). Rien n'a été fait
encore avec le reste de l'accumulateur~\erlcode{A}, ce qui entraîne
que nous devons le passer à \erlcode{cat/2}, tout comme aux autres
fonctions:
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) appk([],A);
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[\{k1,T\}|A]);
flat0(      [Y|T],A) \(\smashedrightarrow{\zeta}\) [Y|flat0(T,A)].
cat(   [],T,\textbf{A})       \(\smashedrightarrow{\eta}\) T;\hfill% A \emph{inutile pour le moment}
cat([X|S],T,\textbf{A})       \(\smashedrightarrow{\theta}\) [X|cat(S,T,\textbf{A})].
appk(V,[\{k2,W\}|A])   \(\smashedrightarrow{\lambda}\) cat(W,V,\textbf{A});\hfill% A \emph{transmis}
appk(V,[\{k1,T\}|A])   \(\smashedrightarrow{\kappa}\) flat0(T,[\{k2,V\}|A]);
appk(V,        [])   \(\smashedrightarrow{\iota}\) V.
\end{alltt}
Après la clause~\(\epsilon\), la première clause qui n'est pas en
forme terminale est la clause~\(\zeta\). Accouplons la
variable~\erlcode{Y} du contexte \erlcode{[Y|\textvisiblespace]} avec
un nouvel atome~\erlcode{k3}, et sauvegardons la paire ainsi formée
dans l'accumulateur~\erlcode{A}, tout en reconstruisant le contexte effacé dans
une nouvelle clause~\(\mu\) de \erlcode{appk/2}:
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) appk([],A);
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[\{k1,T\}|A]);
flat0(      [Y|T],A) \(\smashedrightarrow{\zeta}\) flat0(T,\textbf{[\{k3,Y\}|}A\textbf{]}).\hfill% \emph{Empilage de} Y
cat(   [],T,\textbf{A})       \(\smashedrightarrow{\eta}\) T;\hfill% A \emph{inutile pour le moment}
cat([X|S],T,\textbf{A})       \(\smashedrightarrow{\theta}\) [X|cat(S,T,\textbf{A})].
\textbf{appk(V,[\{k3,Y\}|A])   \(\smashedrightarrow{\mu}\) [Y|V];}\hfill% A \emph{inutile pour le moment}
appk(V,[\{k2,W\}|A])   \(\smashedrightarrow{\lambda}\) cat(W,V,A);
appk(V,[\{k1,T\}|A])   \(\smashedrightarrow{\kappa}\) flat0(T,[\{k2,V\}|A]);
appk(V,        [])   \(\smashedrightarrow{\iota}\) V.
\end{alltt}
Il est intéressant de remarquer que le tout nouveau membre droit de la
clause~\(\mu\) n'utilise pas le reste de
l'accumulateur~\erlcode{A}. Nous avons rencontré exactement la même
situation avec la clause~\(\gamma\): un membre droit ne contenant
aucun autre appel. Dans ce cas, nous avons besoin de vérifier s'il y a
encore des évaluations à faire avec les données sauvegardées
précédemment dans~\erlcode{A}. Ceci est la même tâche que celle
réalisée par \erlcode{appk/2}, par conséquent un appel à cette
fonction doit être effectué dans le membre droit de la clause~\(\mu\)
comme suit:
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) appk([],A);
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[\{k1,T\}|A]);
flat0(      [Y|T],A) \(\smashedrightarrow{\zeta}\) flat0(T,[\{k3,Y\}|A]).
cat(   [],T,A)       \(\smashedrightarrow{\eta}\) T;\hfill% A \emph{inutile pour le moment}
cat([X|S],T,A)       \(\smashedrightarrow{\theta}\) [X|cat(S,T,A)].
appk(V,[\{k3,Y\}|A])   \(\smashedrightarrow{\mu}\) \textbf{appk(}[Y|V],\textbf{A)};
appk(V,[\{k2,W\}|A])   \(\smashedrightarrow{\lambda}\) cat(W,V,A);
appk(V,[\{k1,T\}|A])   \(\smashedrightarrow{\kappa}\) flat0(T,[\{k2,V\}|A]);
appk(V,        [])   \(\smashedrightarrow{\iota}\) V.
\end{alltt}
La clause à examiner par la suite est la clause~\(\eta\), parce que son
membre droit ne contient aucun appel, donc il doit contenir maintenant
un appel à \erlcode{appk/2} avec le membre droit courant~\erlcode{T}
et l'accumulateur~\erlcode{A}. Nous obtenons alors
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) appk([],A);
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[\{k1,T\}|A]);
flat0(      [Y|T],A) \(\smashedrightarrow{\zeta}\) flat0(T,[\{k3,Y\}|A]).
cat(   [],T,A)       \(\smashedrightarrow{\eta}\) \textbf{appk(}T,\textbf{A)};
cat([X|S],T,A)       \(\smashedrightarrow{\theta}\) [X|cat(S,T,A)].
appk(V,[\{k3,Y\}|A])   \(\smashedrightarrow{\mu}\) appk([Y|V],A);
appk(V,[\{k2,W\}|A])   \(\smashedrightarrow{\lambda}\) cat(W,V,A);
appk(V,[\{k1,T\}|A])   \(\smashedrightarrow{\kappa}\) flat0(T,[\{k2,V\}|A]);
appk(V,        [])   \(\smashedrightarrow{\iota}\) V.
\end{alltt}
Enfin, la clause~\(\theta\) doit être transformée comme nous l'avons
fait pour toutes les autres clauses qui n'étaient pas en forme
terminale. Choisissons un nouvel atome, par exemple~\erlcode{k4}, et
accouplons-le avec l'unique variable~\erlcode{Y} du contexte
\erlcode{[Y|\textvisiblespace]}, puis empilons la paire ainsi formée
sur l'accumulateur~\erlcode{A}. Nous devons ajouter une clause~\(\nu\)
à \erlcode{appk/2} pour filtrer ce cas, reconstruire le contexte ôté
et appliquer celui-ci au résultat de l'appel courant à
\erlcode{flat0/2}, à savoir, son premier argument:
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) appk([],A);
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[\{k1,T\}|A]);
flat0(      [Y|T],A) \(\smashedrightarrow{\zeta}\) flat0(T,[\{k3,Y\}|A]).
cat(   [],T,A)       \(\smashedrightarrow{\eta}\) appk(T,A);
cat([X|S],T,A)       \(\smashedrightarrow{\theta}\) cat(S,T,\textbf{[X|}A\textbf{]}).
\textbf{appk(V,[\{k4,X\}|A])   \(\smashedrightarrow{\nu}\) [X|V];}\hfill% A \emph{inutile pour le moment}
appk(V,[\{k3,Y\}|A])   \(\smashedrightarrow{\mu}\) appk([Y|V],A);
appk(V,[\{k2,W\}|A])   \(\smashedrightarrow{\lambda}\) cat(W,V,A);
appk(V,[\{k1,T\}|A])   \(\smashedrightarrow{\kappa}\) flat0(T,[\{k2,V\}|A]);
appk(V,        [])   \(\smashedrightarrow{\iota}\) V.
\end{alltt}
Le membre droit de la clause nouvellement créée ne contient aucun
appel, donc nous devons le passer à
\erlcode{appk/2} avec le reste de l'accumulateur, dans le but de
traiter tout contexte en attente:
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) appk([],A);
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[\{k1,T\}|A]);
flat0(      [Y|T],A) \(\smashedrightarrow{\zeta}\) flat0(T,[\{k3,Y\}|A]).
cat(   [],T,A)       \(\smashedrightarrow{\eta}\) appk(T,A);
cat([X|S],T,A)       \(\smashedrightarrow{\theta}\) cat(S,T,[\{k4,X\}|A]).
appk(V,[\{k4,X\}|A])   \(\smashedrightarrow{\nu}\) \textbf{appk(}[X|V],\textbf{A)};
appk(V,[\{k3,Y\}|A])   \(\smashedrightarrow{\mu}\) appk([Y|V],A);
appk(V,[\{k2,W\}|A])   \(\smashedrightarrow{\lambda}\) cat(W,V,A);
appk(V,[\{k1,T\}|A])   \(\smashedrightarrow{\kappa}\) flat0(T,[\{k2,V\}|A]);
appk(V,        [])   \(\smashedrightarrow{\iota}\) V.
\end{alltt}
La transformation est maintenant terminée. Elle est correcte au sens
où le programme résultant est équivalent à l'original, c'est-à-dire
que \erlcode{flat0/1} et \erlcode{flat0\_tf/1} calculent les mêmes
valeurs pour les mêmes entrées, et toutes les clauses de
\erlcode{flat0\_tf/1} sont en forme terminale. Elle est aussi complète
au sens où toute définition peut être ainsi transformée en forme
terminale. Comme nous l'avons annoncé, le principal intérêt de cette
méthode réside dans son uniformité et nous ne devrions pas nous
attendre à ce qu'elle produise des programmes qui sont plus rapides
que les originaux.

Il est possible, après un examen approfondi, de raccourcir un peu la
définition de \erlcode{appk/2}. En effet, les clauses
\(\nu\)~et~\(\mu\) sont identiques, si ce n'est pour la présence d'une
marque différente, \erlcode{k4}~d'un côté, et \erlcode{k3}~de l'autre.
Fusionnons-les en une seule clause et utilisons un nouvel
atome~\erlcode{k34} en lieu et place de toute occurrence de \erlcode{k3}~et~\erlcode{k4}.\label{code_flat0_tf}
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) appk([],A);
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[\{k1,T\}|A]);
flat0(      [Y|T],A) \(\smashedrightarrow{\zeta}\) flat0(T,[\{\textbf{k34},Y\}|A]).
cat(   [],T,A)       \(\smashedrightarrow{\eta}\) appk(T,A);
cat([X|S],T,A)       \(\smashedrightarrow{\theta}\) cat(S,T,[\{\textbf{k34},X\}|A]).
appk(V,[\{\textbf{k34},Y\}|A])  \(\smashedrightarrow{\mu}\) appk([Y|V],A);
appk(V, [\{k2,W\}|A])  \(\smashedrightarrow{\lambda}\) cat(W,V,A);
appk(V, [\{k1,T\}|A])  \(\smashedrightarrow{\kappa}\) flat0(T,[\{k2,V\}|A]);
appk(V,         [])  \(\smashedrightarrow{\iota}\) V.
\end{alltt}
Autorisons-nous une courte digression et transformons
\erlcode{flat0\_tf/1} davantage, de telle sorte que l'appel
\erlcode{flat0\_tf(\(T\))} soit réécrit en une paire constituée de la
valeur de \erlcode{flat0(\(T\))} et de son coût. Étant donné que la
définition initiale est en forme terminale, nous n'avons alors qu'à
ajouter un compteur et à l'incrémenter dans chaque clause qui
correspond à une clause dans la définition originale, sinon le
compteur reste inchangé. Nous devons aussi ajouter une clause pour
définir la valeur initiale du compteur. Rappelons d'abord la
définition originelle de \erlcode{flat0/1} (nous renommons les flèches
ici pour faciliter l'écriture des étapes ultérieures):
\begin{alltt}
flat0(         []) \(\smashedrightarrow{\gamma}\) [];
flat0(     [[]|T]) \(\smashedrightarrow{\delta}\) flat0(T);
flat0([Y=[\_|\_]|T]) \(\smashedrightarrow{\epsilon}\) cat(flat0(Y),flat0(T));
flat0(      [Y|T]) \(\smashedrightarrow{\zeta}\) [Y|flat0(T)].
cat(   [],T)       \(\smashedrightarrow{\eta}\) T;
cat([X|S],T)       \(\smashedrightarrow{\theta}\) [X|cat(S,T)].
\end{alltt}
Identifions et nommons de façon identique dans la version en forme
terminale de \erlcode{flat0\_tf/1} les clauses qui ont leur
contrepartie dans la définition de \erlcode{flat0/1}:
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\phantom{\gamma}}\) flat0(T,[]).
flat0(       [],A)   \(\smashedrightarrow{\gamma}\) appk([],A);
flat0(   [[]|T],A)   \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[\{k1,T\}|A]);
flat0(    [Y|T],A)   \(\smashedrightarrow{\zeta}\) flat0(T,[\{k34,Y\}|A]).
cat(   [],T,A)       \(\smashedrightarrow{\eta}\) appk(T,A);
cat([X|S],T,A)       \(\smashedrightarrow{\theta}\) cat(S,T,[\{k34,X\}|A]).
appk(V,[\{k34,Y\}|A])  \(\smashedrightarrow{\phantom{\theta}}\) appk([Y|V],A);
appk(V, [\{k2,W\}|A])  \(\smashedrightarrow{\phantom{\theta}}\) cat(W,V,A);
appk(V, [\{k1,T\}|A])  \(\smashedrightarrow{\phantom{\theta}}\) flat0(T,[\{k2,V\}|A]);
appk(V,         [])  \(\smashedrightarrow{\phantom{\theta}}\) V.
\end{alltt}
\index{pile!aplatissement!forme terminale|)}

En nous inspirant de notre compréhension pratique de la transformation
jusqu'à présent, nous pouvons essayer de la résumer de façon
systématique comme suit.
\begin{enumerate}

  \item Considérons toutes les définitions impliquées, en prenant soin
    d'inclure transitivement toutes celles dont elles dépendent;

  \item ajoutons une pile d'accumulation à toutes ces définitions et
    ajoutons une définition qui initialise cet accumulateur avec la
    pile vide;

  \item pour chaque corps constitué d'un appel en forme terminale,
    nous passons simplement l'accumulateur inchangé;

  \item nous remplaçons chaque corps ne contenant aucun appel par un
    appel à une nouvelle fonction \erlcode{appk/2} avec le corps et
    l'accumulateur inchangés;

  \item pour chaque corps qui n'est pas en forme terminale, ceux de
    \erlcode{appk/2} inclus,
    \begin{enumerate}

      \item nous identifions ou choisissons le premier appel à évaluer;

      \item nous prenons toutes les valeurs et variables dans le
        contexte d'appel qui sont des paramètres, sauf l'accumulateur,
        et nous les regroupons dans un \(n\)-uplet avec un unique atome;

      \item nous remplaçons le corps en question par l'appel à faire
        en premier et nous passons à ce dernier l'accumulateur où nous
        avons empilé le \(n\)-uplet;

      \item \label{add_appk1} nous créons une clause de
        \erlcode{appk/2} qui filtre ce cas et dont le corps est le
        contexte mentionné précédemment;

      \item \label{add_appk2} nous remplaçons
        le~\erlcode{\textvisiblespace} dans le contexte par le premier
        argument de \erlcode{appk/2} et nous nous assurons qu'il n'y
        a pas de collision de variables;

    \end{enumerate}

  \item nous ajoutons la clause \erlcode{appk(V,[]) -> V} à \erlcode{appk/2}.

\end{enumerate}
Cet algorithme est \emph{global} dans la mesure où \emph{tous} les pas
doivent être franchis avant qu'un programme équivalent à l'original
soit obtenu. Il est possible de réarranger l'ordre dans lequel les
étapes sont effectuées pour que l'algorithme devienne
\emph{incrémental}, mais ce n'est probablement pas la peine de se
compliquer tant la vie (en analysant le graphe des appels).

\index{fonction de Fibonacci!forme terminale|(} Appliquons la méthode
à une définition \emph{a priori} difficile, comme celle de la fonction
de Fibonacci~\erlcode{fib/1}:
\begin{alltt}
fib(0)            \(\smashedrightarrow{\beta}\) 1;
fib(1)            \(\smashedrightarrow{\gamma}\) 1;
fib(N) when N > 1 \(\smashedrightarrow{\delta}\) fib(N-1) + fib(N-2).
\end{alltt}
Les étapes de la transformation sont les suivantes.
\begin{enumerate}

  \item Cette définition est complète (pas d'appels à d'autre fonction).

  \item Renommons~\erlcode{fib/1} en \erlcode{fib/2}, puis ajoutons
    une pile d'accumulation et elle devient \erlcode{fib/2}, puis nous
    créons une clause~\(\alpha\) définissant \erlcode{fib\_tf/1} avec
    un appel à \erlcode{fib/2} où l'accumulateur est la pile vide:
\begin{alltt}
\textbf{fib_tf(N)           \(\smashedrightarrow{\alpha}\) fib(N,[]).}\hfill% \emph{Nouveau}
fib(0,\textbf{A})            \(\smashedrightarrow{\beta}\) 1;
fib(1,\textbf{A})            \(\smashedrightarrow{\gamma}\) 1;
fib(N,\textbf{A}) when N > 1 \(\smashedrightarrow{\delta}\) fib(N-1,\textbf{A}) + fib(N-2,\textbf{A}).
\end{alltt}

  \item Il n'y a pas de corps en forme terminale qui contienne un appel.

  \item Les clauses \(\beta\)~et~\(\gamma\) sont en forme terminale et
    ne contiennent aucun appel, donc nous devons remplacer les corps
    avec un appel à \erlcode{appk/2}, dont le premier argument est le
    corps originel (ici, \erlcode{1}) et le second est l'accumulateur
    inchangé:
\begin{alltt}
fib_tf(N)           \(\smashedrightarrow{\alpha}\) fib(N,[]).
fib(0,A)            \(\smashedrightarrow{\beta}\) \textbf{appk(}1,\textbf{A)};
fib(1,A)            \(\smashedrightarrow{\gamma}\) \textbf{appk(}1,\textbf{A)};
fib(N,A) when N > 1 \(\smashedrightarrow{\delta}\) fib(N-1,A) + fib(N-2,A).
\end{alltt}

\item La clause~\(\delta\) n'est pas en forme terminale et contient
  deux appels, donc nous devons choisir celui à évaluer en premier,
  par exemple \erlcode{fib(N-2,A)}. Le contexte de celui-ci est
  \erlcode{fib(N-1,A) + \textvisiblespace}. Les valeurs dans le
  contexte, en dehors de l'accumulateur, sont réduites à la seule
  valeur de~\erlcode{N}. Utilisons un nouvel atome~\erlcode{k1} pour
  distinguer cet appel et formons la paire
  \erlcode{\{k1,N\}}. Remplaçons le corps de~\(\delta\) par
  \erlcode{fib(N-2,\textbf{[\{k1,N\}|A]})}. Ensuite, ajoutons une
  clause à \erlcode{appk/2} qui filtre cette paire. Son corps est le
  contexte que nous venons d'enlever du corps de~\(\delta\). Dans
  celui-ci, substituons à~\erlcode{\textvisiblespace} le premier paramètre.
\begin{alltt}
fib_tf(N)           \(\smashedrightarrow{\alpha}\) fib(N,[]).
fib(0,A)            \(\smashedrightarrow{\beta}\) appk(1,A);
fib(1,A)            \(\smashedrightarrow{\gamma}\) appk(1,A);
fib(N,A) when N > 1 \(\smashedrightarrow{\delta}\) fib(N-2,\textbf{[\{k1,N\}|A]}).
\textbf{appk(V,[\{k1,N\}|A])  \(\smashedrightarrow{\epsilon}\) fib(N-1,A) + V.}
\end{alltt}

  Le corps de~\(\epsilon\) n'est pas en forme terminale, car il contient
un appel qui n'est pas à la racine de l'arbre de syntaxe abstraite. Le
contexte de cet appel est~\erlcode{\textvisiblespace{} + V} et sa
seule variable est~\erlcode{V}. Produisons un unique
atome~\erlcode{k2} et accouplons-le avec~\erlcode{V}. Nous remplaçons
alors le corps~\(\epsilon\) par l'appel à évaluer en premier et nous
lui passons l'accumulateur sur lequel nous avons empilé la paire. Nous
ajoutons une clause à \erlcode{appk/2} qui filtre ce cas et dans son
corps nous mettons le contexte mentionné. Nous substituons
à~\erlcode{\textvisiblespace} le premier paramètre.
\begin{alltt}
\textbf{appk(V,[\{k2,W\}|A]) \(\smashedrightarrow{\zeta}\) V + W;}
appk(V,[\{k1,N\}|A]) \(\smashedrightarrow{\epsilon}\) fib(N-1,\textbf{[\{k2,V\}|A]}).
\end{alltt}
    Nous avons renommé la variable~\erlcode{V} dans l'accumulateur
    en~\erlcode{W} pour éviter une collision avec le premier
    paramètre~\erlcode{V}. Ce nouveau corps \erlcode{V+W} est en forme
    terminale et ne contient aucun autre appel, donc il doit être
    utilisé par un appel récursif car l'accumulateur~\erlcode{A} peut
    ne pas être vide (d'autres appels sont en attente). Nous
    passons~\erlcode{A} à cet appel. Finalement, toutes les clauses
    sont en forme terminale:
\begin{alltt}
fib_tf(N)           \(\smashedrightarrow{\alpha}\) fib(N,[]).
fib(0,A)            \(\smashedrightarrow{\beta}\) appk(1,A);
fib(1,A)            \(\smashedrightarrow{\gamma}\) appk(1,A);
fib(N,A) when N > 1 \(\smashedrightarrow{\delta}\) fib(N-2,[\{k1,N\}|A]).
appk(V,[\{k2,W\}|A])  \(\smashedrightarrow{\zeta}\) \textbf{appk(}V+W,\textbf{A)};
appk(V,[\{k1,N\}|A])  \(\smashedrightarrow{\epsilon}\) fib(N-1,[\{k2,V\}|A]).
\end{alltt}

  \item Nous devons ajouter une clause pour filtrer le cas de
    l'accumulateur vide et finir avec le premier paramètre:
\begin{alltt}
fib_tf(N)           \(\smashedrightarrow{\alpha}\) fib(N,[]).
fib(0,A)            \(\smashedrightarrow{\beta}\) appk(1,A);
fib(1,A)            \(\smashedrightarrow{\gamma}\) appk(1,A);
fib(N,A) when N > 1 \(\smashedrightarrow{\delta}\) fib(N-2,[\{k1,N\}|A]).
\textbf{appk(V,        [])  \(\smashedrightarrow{\eta}\) V;}\hfill% \emph{Attention!}
appk(V,[\{k2,W\}|A])  \(\smashedrightarrow{\zeta}\) appk(V+W,A);
appk(V,[\{k1,N\}|A])  \(\smashedrightarrow{\epsilon}\) fib(N-1,[\{k2,V\}|A]).
\end{alltt}
\index{fonction de Fibonacci!forme terminale|)}
\index{pile!aplatissement!forme terminale|(}

Appliquons maintenant notre méthode générale à \erlcode{flat/1}:
\begin{alltt}
flat\_tf(T)        -> flat(T,[]).
flat(       [],A) -> [];\hfill% A \emph{inutile pour le moment}
flat(   [[]|T],A) -> flat(T,A);
flat([[X|S]|T],A) -> flat([X,S|T],A);
flat(    [Y|T],A) -> [Y|flat(T,A)].
\end{alltt}
Le seul corps qui ne contient aucun appel est celui de la première
clause de \erlcode{flat/2}, donc il doit être passé à un appel de
\erlcode{appk/2} avec l'accumulateur. Seul le dernier corps n'est pas
en forme terminale. Le seul appel effectué a pour contexte
\erlcode{[Y|\textvisiblespace]}, dont l'unique valeur est celle
de~\erlcode{Y}. Nous produisons un unique atome~\erlcode{k1} et nous
lui adjoignons~\erlcode{Y} pour former une paire. Nous remplaçons le
corps qui n'est pas en forme terminale par cet appel, auquel nous
passons l'accumulateur sur lequel nous avons empilé la paire. Nous
créons alors \erlcode{appk/2} pour filtrer ce cas. Son corps est le
contexte que nous avons ôté précédemment. Nous substituons
à~\erlcode{\textvisiblespace} dans celui-ci le premier paramètre:
\begin{alltt}
flat_tf(T)         -> flat(T,[]).
flat(       [],A)  -> \textbf{appk(}[],\textbf{A)};
flat(   [[]|T],A)  -> flat(T,A);
flat([[X|S]|T],A)  -> flat([X,S|T],A);
flat(    [Y|T],A)  -> \textbf{flat(T,[\{k1,Y\}|A])}.
\textbf{appk(V,[\{k1,Y\}|A]) -> [Y|V].}\hfill% \emph{Le contexte était} [Y|\textvisiblespace]
\end{alltt}
Puisque le corps de la nouvelle clause de \erlcode{appk/2} est une
valeur, elle doit être passée à un appel récursif parce que
l'accumulateur~\erlcode{A} peut ne pas être vide, donc il se peut que
certains appels en attente doivent être maintenant évalués:
\begin{alltt}
flat_tf(T)         -> flat(T,[]).
flat(       [],A)  -> appk([],A);
flat(   [[]|T],A)  -> flat(T,A);
flat([[X|S]|T],A)  -> flat([X,S|T],A);
flat(    [Y|T],A)  -> flat(T,[\{k1,Y\}|A]).
appk(V,[\{k1,Y\}|A]) -> \textbf{appk(}[Y|V],\textbf{A)}.
\end{alltt}
Finalement, la définition de \erlcode{appk/2} doit être complétée par
une clause correspondant au cas où l'accumulateur est vide et son
corps est simplement le premier argument, qui est, par construction,
le résultat:
\begin{alltt}
flat_tf(T)         -> flat(T,[]).
flat(       [],A)  -> appk([],A);
flat(   [[]|T],A)  -> flat(T,A);
flat([[X|S]|T],A)  -> flat([X,S|T],A);
flat(    [Y|T],A)  -> flat(T,[\{k1,Y\}|A]).
\textbf{appk(V,        []) -> V;}
appk(V,[\{k1,Y\}|A]) -> appk([Y|V],A).
\end{alltt}
Si nous comparons cette version avec
\begin{verbatim}
flat_tf(T)        -> flat(T,[]).
flat(       [],A) -> rev(A);
flat(   [[]|T],A) -> flat(T,A);
flat([[X|S]|T],A) -> flat([X,S|T],A);
flat(    [Y|T],A) -> flat(T,[Y|A]).
\end{verbatim}
\index{pile!aplatissement!forme terminale|)}
nous comprenons que cette dernière peut être dérivée de la première si
la paire \erlcode{\{k1,Y\}} est remplacée par~\erlcode{Y}. Ceci est
possible parce que c'est le seul atome qui a été produit. La
définition de \erlcode{appk/2} est alors équivalente à
\erlcode{rcat/2} (section~\vref{sec:reversal}):
\verbatiminput{rev.def}
\end{enumerate}
La philosophie sous-jacente à notre méthode générale pour transformer
un groupe de définitions en d'autres en forme terminale consiste à
ajouter un paramètre qui est une pile accumulant les valeurs des
différents contextes et nous créons une fonction (\erlcode{appk/2})
pour reconstruire lesdits contextes lorsque les appels qu'ils
contenaient ont terminé. Ces contextes reconstruits sont à leur tour
transformés en forme terminale jusqu'à ce que toutes les clauses
soient en forme terminale. Par conséquent, le nombre de clauses est
plus grand que dans le programme source, dont l'algorithme est
obscurcit à cause de tout le travail administratif sur l'accumulateur.
Dans le but de gagner du temps et d'épargner des efforts, il est sage
de considérer les définitions en forme terminale comme étant utiles
\emph{a posteriori}, si nous nous confrontons à la taille maximale de
la pile d'exécution, sauf si des données très volumineuses sont, dès
la phase de conception, probables. Une autre raison d'employer la
transformation est la compilation vers un langage de bas niveau, comme
\Clang (en utilisant seulement des sauts \texttt{goto}).

Transformons l'insertion simple (section~\ref{sec:straight_ins}
\vpageref{sec:straight_ins}) et analysons le coût de la définition
résultante. Nous débutons avec
\begin{alltt}
isrt(   [])             \(\smashedrightarrow{\beta}\) [];
isrt([X|S])             \(\smashedrightarrow{\gamma}\) ins(isrt(S),X).
ins([Y|S],X) when X > Y \(\smashedrightarrow{\delta}\) [Y|ins(S,X)];
ins(    S,X)            \(\smashedrightarrow{\epsilon}\) [X|S].
\end{alltt}
(les clause ont été renommées) et nous ajoutons une pile
d'accumulation à toutes nos fonctions et initialisons-la avec la pile
vide (nouvelle clause~\(\alpha\)):
\begin{alltt}
\textbf{isrt_tf(S)                \(\smashedrightarrow{\alpha}\) isrt(S,[]).}
isrt(   [],\textbf{A})             \(\smashedrightarrow{\beta}\) [];\hfill% A \emph{inutile pour le moment}
isrt([X|S],\textbf{A})             \(\smashedrightarrow{\gamma}\) ins(isrt(S,\textbf{A}),X,\textbf{A}).
ins([Y|S],X,\textbf{A}) when X > Y \(\smashedrightarrow{\delta}\) [Y|ins(S,X,\textbf{A})];
ins(    S,X,\textbf{A})            \(\smashedrightarrow{\epsilon}\) [X|S].\hfill% A \emph{inutile}
\end{alltt}
Nous pouvons maintenant inspecter chaque clause et, selon la forme de
leur corps (expression en forme terminale avec ou sans appel, ou pas
en forme terminale), quelque transformation est effectuée. D'abord, le
corps de~\(\beta\) est en forme terminale et ne contient aucun
appel. Donc, nous le transformons en appelant la fonction
\erlcode{appk/2}:
\begin{alltt}
isrt(   [],\textbf{A})             \(\smashedrightarrow{\beta}\) \textbf{appk(}[],\textbf{A)};
\end{alltt}
Ensuite, la clause~\(\gamma\) n'est pas en forme terminale. Le premier
appel qui est évalué est \erlcode{isrt(S,A)}, dont le contexte est
\erlcode{ins(\textvisiblespace,X,A)}. Conservons l'appel, tout en
sauvegardant dans l'accumulateur~\erlcode{A} la variable~\erlcode{X},
qui sera nécessaire pour reconstruire le contexte dans une nouvelle
clause de \erlcode{appk/2}. Cette variable a besoin a priori d'être
marquée par un atome unique, tel~\erlcode{k1}:
\begin{alltt}
isrt([X|S],\textbf{A})             \(\smashedrightarrow{\gamma}\) isrt(S,\textbf{[\{k1,X\}|A]}).
...
\textbf{appk(V,[\{k1,X\}|A])        \(\rightarrow\) ins(V,X,A).}
\end{alltt}
La prochaine clause est~\(\delta\), qui n'est pas en forme terminale.
Le seul appel à évaluer est \erlcode{ins(S,X,A)}, dont le contexte est
\erlcode{[Y|\textvisiblespace]}. Associons~\erlcode{Y} avec un unique
atome~\erlcode{k2}, puis sauvegardons les deux dans
l'accumulateur~\erlcode{A}, et ajoutons une clause à
\erlcode{appk/2} reconstruisant le contexte effacé:
\begin{alltt}
ins([Y|S],X,A) when X > Y \(\smashedrightarrow{\delta}\) ins(S,X,\textbf{[\{k2,Y\}|A]});
...
\textbf{appk(V,[\{k2,Y\}|A])        \(\rightarrow\) appk([Y|V],A);}
\end{alltt}
La dernière clause est~\(\epsilon\), qui est en forme terminale et ne
contient aucun appel, donc nous devons passer son corps à
\erlcode{appk/2} pour vérifier s'il y a encore des contextes à
reconstruire et évaluer:
\begin{alltt}
ins(    S,X,A)            \(\smashedrightarrow{\epsilon}\) \textbf{appk(}[X|S],\textbf{A)}.
\end{alltt}
Pour compléter cette transformation, nous devons ajouter une clause à
\erlcode{appk/2} pour traiter le cas où l'accumulateur et vide, donc
le résultat final a été atteint. Finalement, le programme est (la
dernière étape est un gras)\label{isrt_tf_appk}
\begin{alltt}
isrt_tf(S)                \(\smashedrightarrow{\alpha}\) isrt(S,[]).
isrt(   [],A)             \(\smashedrightarrow{\beta}\) appk([],A);
isrt([X|S],A)             \(\smashedrightarrow{\gamma}\) isrt(S,[\{k1,X\}|A]).
ins([Y|S],X,A) when X > Y \(\smashedrightarrow{\delta}\) ins(S,X,[\{k2,Y\}|A]);
ins(    S,X,A)            \(\smashedrightarrow{\epsilon}\) appk([X|S],A).
\textbf{appk(V,        [])        \(\smashedrightarrow{\zeta}\) V;}
appk(V,[\{k2,Y\}|A])        \(\smashedrightarrow{\eta}\) appk([Y|V],A);
appk(V,[\{k1,X\}|A])        \(\smashedrightarrow{\theta}\) ins(V,X,A).
\end{alltt}
Nous remarquons que l'atome~\erlcode{k1} n'est pas nécessaire à la
définition de \erlcode{isrt\_tf/1}, car toute autre valeur dans
l'accumulateur est marquée avec~\erlcode{k2}:
\begin{alltt}
isrt_tf(S)                \(\smashedrightarrow{\alpha}\) isrt(S,[]).
isrt(   [],A)             \(\smashedrightarrow{\beta}\) appk([],A);
isrt([X|S],A)             \(\smashedrightarrow{\gamma}\) isrt(S,\textbf{[X|A]}).\hfill% \emph{Ici}
ins([Y|S],X,A) when X > Y \(\smashedrightarrow{\delta}\) ins(S,X,[\{k2,Y\}|A]);
ins(    S,X,A)            \(\smashedrightarrow{\epsilon}\) appk([X|S],A).
appk(V,        [])        \(\smashedrightarrow{\zeta}\) V;
appk(V,[\{k2,Y\}|A])        \(\smashedrightarrow{\eta}\) appk([Y|V],A);
appk(V,     \textbf{[X|A]})        \(\smashedrightarrow{\theta}\) ins(V,X,A).\hfill% \emph{et là}
\end{alltt}
Il est évident maintenant que \erlcode{isrt/2} retourne son premier
argument sur l'accumulateur, qui est initialisé à la clause~\(\alpha\)
avec la pile vide. Alors, à la clause~\(\beta\), \erlcode{appk/2} est
appelée avec les mêmes arguments. Par exemple,
\erlcode{isrt([3,8,2],[])}~\(\smashedrightarrow{3}\)
\erlcode{appk([],[2,8,3])}. Donc, nous concluons
\begin{equation*}
\erlcode{isrt(\(S\),[])} \equiv \erlcode{appk([],rev(\(S\)))},
\end{equation*}
ce qui nous permet de retirer toute la définition de \erlcode{isrt/2}
ainsi:
\begin{alltt}
isrt_tf(S)                \(\smashedrightarrow{\alpha}\) \textbf{appk([],rev(S))}.
ins([Y|S],X,A) when X > Y \(\smashedrightarrow{\delta}\) ins(S,X,[\{k2,Y\}|A]);
ins(    S,X,A)            \(\smashedrightarrow{\epsilon}\) appk([X|S],A).
appk(V,        [])        \(\smashedrightarrow{\zeta}\) V;
appk(V,[\{k2,Y\}|A])        \(\smashedrightarrow{\eta}\) appk([Y|V],A);
appk(V,     [X|A])        \(\smashedrightarrow{\theta}\) ins(V,X,A).
\end{alltt}
Clairement, trier une pile ou la même pile retournée est la même chose:
\begin{equation*}
\erlcode{isrt\_tf(\(S\))} \equiv \erlcode{isrt\_tf(rev(\(S\)))}.
\end{equation*}
Via la clause~\(\alpha\), et en remarquant que
\(\erlcode{rev(rev(\(S\)))} \equiv S\), nous tirons
\begin{equation*}
  \erlcode{isrt\_tf(\(S\))} \equiv \erlcode{appk([],rev(rev(\(S\))))}
                          \equiv \erlcode{appk([],\(S\))}.
\end{equation*}
Par conséquent, nous simplifions le corps de la clause~\(\alpha\):
\begin{alltt}
isrt_tf(S)                \(\smashedrightarrow{\alpha}\) appk([],\textbf{S}).
ins([Y|S],X,A) when X > Y \(\smashedrightarrow{\delta}\) ins(S,X,[\{k2,Y\}|A]);
ins(    S,X,A)            \(\smashedrightarrow{\epsilon}\) appk([X|S],A).
appk(V,        [])        \(\smashedrightarrow{\zeta}\) V;
appk(V,[\{k2,Y\}|A])        \(\smashedrightarrow{\eta}\) appk([Y|V],A);
appk(V,     [X|A])        \(\smashedrightarrow{\theta}\) ins(V,X,A).
\end{alltt}
Nous pouvons obtenir un programme plus court aux dépens de plus de
comparaisons. Remarquons que lorsque la clause~\(\eta\) s'applique,
\erlcode{Y}~est inférieur au sommet de~\erlcode{V}, qui existe parce
que cette clause est employée seulement pour évaluer les corps des
clauses \(\epsilon\)~et~\(\eta\), où le premier argument n'est pas la
pile vide. Par conséquent, \(\erlcode{appk([Y|V],A)} \equiv
\erlcode{ins(V,Y,A)}\), car la clause~\(\epsilon\) serait utilisée. De
la même façon, changeons la clause~\(\eta\):
\begin{alltt}
isrt_tf(S)                \(\smashedrightarrow{\alpha}\) appk([],S).
ins([Y|S],X,A) when X > Y \(\smashedrightarrow{\delta}\) ins(S,X,[\{k2,Y\}|A]);
ins(    S,X,A)            \(\smashedrightarrow{\epsilon}\) appk([X|S],A).
appk(V,        [])        \(\smashedrightarrow{\zeta}\) V;
appk(V,[\{k2,Y\}|A])        \(\smashedrightarrow{\eta}\) \textbf{ins(V,Y,A)};
appk(V,     [X|A])        \(\smashedrightarrow{\theta}\) ins(V,X,A).
\end{alltt}
Nous voyons clairement maintenant que \erlcode{appk/2} appelle
\erlcode{ins/3} de la même manière dans les clauses
\(\eta\)~et~\(\theta\), ce qui signifie qu'il est inutile de
distinguer~\erlcode{Y} avec~\erlcode{k2} et nous pouvons nous
débarrasser de la clause~\(\theta\) (\erlcode{Z} peut être
un~\erlcode{X} ou un~\erlcode{Y}):
\begin{alltt}
isrt_tf(S)                \(\smashedrightarrow{\alpha}\) appk([],S).
ins([Y|S],X,A) when X > Y \(\smashedrightarrow{\delta}\) ins(S,[\textbf{Y}|A]);\hfill% \emph{Ici}
ins(    S,X,A)            \(\smashedrightarrow{\epsilon}\) appk([X|S],A).
appk(V,   [])             \(\smashedrightarrow{\zeta}\) V;
appk(V,[\textbf{Z}|A])             \(\smashedrightarrow{\eta}\) ins(V,Z,A).\hfill% \emph{et là}
\end{alltt}
Peut-être est-il plus clair de nous défaire de \erlcode{appk/2} en
intégrant ses deux opérations dans \erlcode{isrt\_tf/1} et
\erlcode{ins/3}. Séparons les clauses \(\alpha\)~et~\(\epsilon\) pour
manifester les cas où, respectivement, \erlcode{S}~et~\erlcode{A} sont vides:
\newlength\duparrow \settowidth\duparrow{\(\alpha\sb{0}\)}
\begin{alltt}
isrt_tf(   [])                \(\MyArrow{\duparrow}{\alpha\sb{0}}\) appk([],[]);
isrt_tf([X|S])                \(\MyArrow{\duparrow}{\alpha\sb{1}}\) appk([],[X|S]).
ins([Y|S],X,    A) when X > Y \(\MyArrow{\duparrow}{\delta}\) ins(S,X,[Y|A]);
ins(    S,X,[Y|A])            \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) appk([X|S],[Y|A]);
ins(    S,X,   [])            \(\MyArrow{\duparrow}{\epsilon\sb{1}}\) appk([X|S],[]).
appk(V,   [])                 \(\MyArrow{\duparrow}{\zeta}\) V;
appk(V,[Z|A])                 \(\MyArrow{\duparrow}{\eta}\) ins(V,Z,A).
\end{alltt}
Nous pouvons maintenant remplacer les corps des clauses
\(\alpha_0\)~et~\(\epsilon_1\) par leur valeur, données par la
clause~\(\zeta\), et nous pouvons éliminer la clause~\(\zeta\):
\begin{alltt}
isrt_tf(   [])                \(\MyArrow{\duparrow}{\alpha\sb{0}}\) \textbf{[]};
isrt_tf([X|S])                \(\MyArrow{\duparrow}{\alpha\sb{1}}\) appk([],[X|S]).
ins([Y|S],X,    A) when X > Y \(\MyArrow{\duparrow}{\delta}\) ins(S,X,[Y|A]);
ins(    S,X,[Y|A])            \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) appk([X|S],[Y|A]);
ins(    S,X,   [])            \(\MyArrow{\duparrow}{\epsilon\sb{1}}\) \textbf{[X|S]}.
appk(V,[Z|A])                 \(\MyArrow{\duparrow}{\eta}\) ins(V,Z,A).
\end{alltt}
Nous avons économisé une réécriture dans le cas où la pile d'entrée
est vide. Finalement, les corps des clauses
\(\alpha_1\)~et~\(\epsilon_0\) peuvent être remplacés par leur valeur,
donnée par la clause~\(\eta\), qui peut être, finalement,
enlevée. Nous renommons~\erlcode{T} l'accumulateur~\erlcode{A}.
\label{code_isrt_tf}
\begin{alltt}
isrt_tf(   [])                \(\MyArrow{\duparrow}{\alpha\sb{0}}\) [];
isrt_tf([X|S])                \(\MyArrow{\duparrow}{\alpha\sb{1}}\) \textbf{ins([],X,S)}.
ins([Y|S],X,    T) when X > Y \(\MyArrow{\duparrow}{\delta}\) ins(S,X,[Y|S]);
ins(    S,X,[Y|T])            \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) \textbf{ins([X|S],Y,T)};
ins(    S,X,   [])            \(\MyArrow{\duparrow}{\epsilon\sb{1}}\) [X|S].
\end{alltt}
Il est important de se souvenir que ces dernières étapes, relatives à
la suppression de l'atome~\erlcode{k2} etc., n'ont de sens que parce
que, en évaluant le coût, nous prenons seulement en compte le nombre
d'appels de fonction, pas le nombre de comparaisons, qui est
maintenant supérieur car nous nous passons du contexte
\erlcode{[Y|\textvisiblespace]} dans la clause originelle~\(\delta\)
de \erlcode{ins/3}. En d'autres termes, les clés empilées dans
l'accumulateur dans la nouvelle clause~\(\delta\) doivent être
réinsérées à la clause~\(\epsilon_0\).

La même analyse que nous avons faite pour déterminer le coût de
\erlcode{isrt/1} est valable ici aussi, sauf que les clés sont
insérées dans leur ordre initial. Donc, lorsque les clés sont
triées par ordre croissant, le coût ici est \emph{maximum} (à savoir,
la clause~\(\delta\) est utilisée au maximum) et quand elle est triée
par ordre non-croissant, le coût est \emph{minimum} (la
clause~\(\delta\) n'est jamais utilisée). \emph{Si les clés ne sont
  pas répétées, le meilleur des cas de \erlcode{isrt/1} est le pire des
cas de \erlcode{isrt\_tf/1}, et le pire des cas de \erlcode{isrt/1} est
le meilleur des cas de \erlcode{isrt\_tf/1}.} Ceci tient parce que
«~non-croissant~» signifie la même chose que «~croissant~» lorsqu'il n'y a
pas de répétition.

Dans le but de déterminer le coût minimum de la version finale de
\erlcode{isrt\_tf/1}, il est utile de comprendre mieux au préalable
l'évaluation en examinant la trace d'un petit exemple, comme le tri de
\erlcode{[4,3,2,1]}, qui est une pile triée par ordre décroissant:
\begin{alltt}
isrt_tf([4,3,2,1]) \(\MyArrow{\duparrow}{\alpha\sb{1}}\) ins(     [],4,[3,2,1])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins(    [4],3,  [2,1])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins(  [3,4],2,    [1])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins([2,3,4],1,     [])
                   \(\MyArrow{\duparrow}{\epsilon\sb{1}}\) [1,2,3,4]\textrm{.}
\end{alltt}
Notons \(\B{\fun{isrt\_tf}}{n}\) le coût minimum pour trier
\(n\)~clés. Alors \(\B{\fun{isrt\_tf}}{0} = 1\), via la
clause~\(\alpha_0\). Supposons ensuite que \(n > 0\). Alors
\begin{itemize}

  \item la clause~\(\alpha\sb{1}\) est utilisée une fois;
\medskip
  \item la clause~\(\delta\) n'est pas employée, puisque nous avons
    supposé ici que les clés sont déjà triées par ordre non-croissant;
\medskip
  \item la clause~\(\epsilon\sb{0}\) est utilisée une fois pour chaque
  clé dans son troisième argument, ce qui, par la
  clause~\(\alpha\sb{1}\), veut dire toutes les clés sauf la première,
  à savoir \(n-1\) fois; \medskip
  \item la clause~\(\epsilon\sb{1}\) est utilisée une fois.

\end{itemize}

\medskip

\noindent En somme, la trace d'évaluation est
\(\alpha_1\epsilon_0^{n-1}\epsilon_1\), donc le coût total est
\begin{equation*}
\B{\fun{isrt\_tf}}{n} = \len{\alpha_1\epsilon_0^{n-1}\epsilon_1} = n+1,
\end{equation*}
si~\(n>0\). Étant donné que nous avons trouvé \(\B{\fun{isrt\_tf}}{0}
= 1 = 0 + 1\), nous pouvons étendre la formule précédente pour le cas
\(n=0\). Ce résultat peut être rapproché directement de
\(\W{\fun{isrt}}{n} = (n^2 + 3n + 2)/2\), parce que le meilleur des
cas de \erlcode{isrt\_tf/1} correspond au pire des cas de
\erlcode{isrt/1} quand les clés sont uniques. Nous pouvons de plus
raisonner que ce coût minimum de \erlcode{isrt\_tf/1} est aussi un
minimum absolu pour un algorithme de tri quand l'entrée est triée par
ordre non-croissant, car il s'agit simplement du coût pour retourner
l'entrée.

Soit \(\W{\fun{isrt\_tf}}{n}\) le coût maximum de
\erlcode{isrt\_tf(\(S\))}, où la pile~\(S\) contient \(n\)~clés (en
ordre croissant). Pour la pile vide, la trace d'évaluation
est~\(\alpha_0\). Pour les singletons, par exemple \erlcode{[5]}, nous
avons \(\alpha_1\epsilon_1\). Pour comprendre le cas général \(n >
1\), nous pouvons procéder ainsi:
\begin{alltt}
isrt_tf([1,2,3,4]) \(\MyArrow{\duparrow}{\alpha\sb{1}}\) ins(     [],1,[2,3,4])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins(    [1],2,  [3,4])
                   \(\MyArrow{\duparrow}{\delta}\) ins(     [],2,[1,3,4])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins(    [2],1,  [3,4])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins(  [1,2],3,    [4])
                   \(\MyArrow{\duparrow}{\delta}\) ins(    [2],3,  [1,4])
                   \(\MyArrow{\duparrow}{\delta}\) ins(     [],3,[2,1,4])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins(    [3],2,  [1,4])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins(  [2,3],1,    [4])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins([1,2,3],4,     [])
                   \(\MyArrow{\duparrow}{\delta}\) ins(  [2,3],4,    [1])
                   \(\MyArrow{\duparrow}{\delta}\) ins(    [3],4,  [2,1])
                   \(\MyArrow{\duparrow}{\delta}\) ins(     [],4,[3,2,1])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins(    [4],3,  [2,1])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins(  [3,4],2,    [1])
                   \(\MyArrow{\duparrow}{\epsilon\sb{0}}\) ins([2,3,4],1,     [])
                   \(\MyArrow{\duparrow}{\epsilon\sb{1}}\) [1,2,3,4]\textrm{.}
\end{alltt}
Remarquons le jeu entre les clauses \(\delta\)~et~\(\epsilon_0\). Une
suite d'applications de la clause~\(\delta\) mène à un appel dont le
premier argument est la pile vide. La raison est que l'effet de la
clause~\(\delta\) est de sauvegarder le contenu de cet argument en le
retournant sur le troisième argument. En d'autres termes, dans le pire
des cas, la clause~\(\delta\) est équivalente à
\begin{alltt}
ins([Y|S],X,T) when X > Y \(\rightarrow\) ins(\textbf{[]},X,\textbf{rcat(S,[Y|T])});
\end{alltt}
Une séquence de~\(\delta\) est suivie par une série de~\(\epsilon_0\)
\emph{de même longueur}, suivie par une clause
\(\epsilon_0\)~ou~\(\epsilon_1\). La raison est que la
clause~\(\epsilon_0\) restaure sur le premier argument les clés
précédemment sauvées par la clause~\(\delta\). Alors, s'il reste des
clés dans le dernier argument (donc qui doivent être triées), une
application de plus de la clause~\(\epsilon_0\) est nécessaire,
c'est-à-dire que la trace d'évaluation générale, quand \(n > 1\), est
\begin{equation*}
\alpha_1\prod_{p=0}^{n-2}{\left(\delta^p\epsilon_0^{p+1}\right)} \cdot
\delta^{n-1}\epsilon_0^{n-1} \cdot \epsilon_1
= \alpha_1\prod_{p=0}^{n-2}{\left((\delta\epsilon_0)^p\epsilon_0\right)}
\cdot (\delta\epsilon_0)^{n-1} \cdot \epsilon_1.
\end{equation*}
Cette observation est déterminante pour obtenir le coût maximum car
elle suggère de compter les emplois des clauses~\(\delta\)
et~\(\epsilon_0\) \emph{ensemble}, comme cela est montré dans le
membre droit de l'égalité qui précède. Nous pouvons maintenant
directement dériver le coût maximum:
\begin{align*}
  \W{\fun{isrt\_tf}}{n}
  &= \left|\alpha_1\prod_{p=0}^{n-2}{\left((\delta\epsilon_0)^p\epsilon_0\right)}
     \cdot (\delta\epsilon_0)^{n-1} \cdot \epsilon_1\right|\\
  &= \len{\alpha_1} +
     \left|\prod_{p=0}^{n-2}{\left((\delta\epsilon_0)^p\epsilon_0\right)}\right|
     + \left|(\delta\epsilon_0)^{n-1}\right| + \len{\epsilon_1}\\
  &= 1 + \sum_{p=0}^{n-2}{\left|(\delta\epsilon_0)^p\epsilon_0\right|}
     + (n-1)\len{\delta\epsilon_0} + 1\\
\W{\fun{isrt\_tf}}{n}
  &= 1 + \sum_{p=0}^{n-2}{(2p+1)} + 2(n-1) + 1 = n^2 + 1.
\end{align*}
Puisque le pire des cas de \erlcode{isrt\_tf/1} et \erlcode{isrt/1}
sont identiques, nous pouvons comparer leur coût dans ce cas, si
\(n\geqslant{}0\):
\begin{equation*}
\W{\fun{isrt}}{n}     = (n^2 + 3n + 2)/2
\quad\text{et}\quad
\W{\fun{isrt\_tf}}{n} = 2 \cdot \W{\fun{isrt}}{n}  + 3n + 1.
\end{equation*}
Mettons en relation maintenant le meilleur et le pire des cas de
\erlcode{isrt/1} et \erlcode{isrt\_tf/1}. Nous avons, pour~\(n>3\),
\(\B{\smash[t]{\fun{isrt\_tf}}}{n} < \B{\fun{isrt}}{n} <
\W{\fun{isrt}}{n} < \W{\smash[t]{\fun{isrt\_tf}}}{n}\). Si nous notons
\(\C{\fun{isrt}}{n}\) le coût de \erlcode{isrt/1} sur une entrée de
longueur~\(n\), ces inégalités sont équivalentes aux inégalités \(
\B{\smash[t]{\fun{isrt\_tf}}}{n} < \C{\fun{isrt}}{n} <
\W{\smash[t]{\fun{isrt\_tf}}}{n}\).  C'est ce que nous pouvons faire
de mieux, parce que nous avons seulement les inégalités évidentes
\(\B{\smash[t]{\fun{isrt\_tf}}}{n} \leqslant
\C{\smash[t]{\fun{isrt\_tf}}}{n} \leqslant
\W{\smash[t]{\fun{isrt\_tf}}}{n}\), qui ne nous permettent pas de
comparer \(\C{\fun{isrt}}{n}\) et
\(\C{\smash[t]{\fun{isrt\_tf}}}{n}\). Pour obtenir un résultat plus
fort, nous avons besoin d'une analyse du coût moyen, de façon à
départager \erlcode{isrt\_tf/1} et \erlcode{isrt/1}. En effet, il se
pourrait que, pour une entrée de longueur~\(n\), la plupart des
configurations de l'entrée mènent à un coût de \erlcode{isrt\_tf/1}
qui est en fait inférieur à celui de \erlcode{isrt/1}. Notons
\(\M{\smash[t]{\fun{isrt\_tf}}}{n}\) la nombre moyen de réécritures
nécessaires pour évaluer \erlcode{isrt\_tf}{(\(S\))}, où la longueur
de la pile~\(S\) est~\(n\). De façon similaire, nous notons
\(\M{\fun{ins}}{p,q}\) le coût moyen de l'appel
\erlcode{ins(\(P\),\(X\),\(Q\))}, où la pile~\(P\) a la longueur~\(p\)
et la pile~\(Q\) la longueur~\(q\).

Voici un raisonnement pas très rigoureux mais intuitif: puisque les
clés sont aléatoires, le nombre moyen de fois que la clause~\(\delta\)
est utilisée est~\(p/2\). Puisque le but de la clause~\(\epsilon_0\),
comme nous l'avons observé plus tôt, est de remettre à leur place les
clés précédemment déplacées par la clause~\(\delta\), nous nous
attendons, en moyenne, au même nombre \(p/2\), plus~\(1\) parce que la
clause~\(\epsilon_0\) prépare aussi l'usage possible de la
clause~\(\delta\). En d'autres termes, la différence avec la trace
d'évaluation la plus longue de \(\W{\fun{isrt}}{n}\) est que les
sous-suites contiguës~\(\delta\epsilon_0\) sont en moyenne 50\% plus
courtes, donc la trace d'évaluation est, en moyenne,
\begin{equation*}
\alpha_1\prod_{p=0}^{n-2}{\left((\delta\epsilon_0)^{p/2}\epsilon_0\right)}
\cdot (\delta\epsilon_0)^{(n-1)/2} \cdot \epsilon_1,
\end{equation*}
dont nous déduisons que le coût moyen de~\(n>1\):
\begin{equation*}
  \M{\fun{isrt\_tf}}{n} = 1 +
  \sum_{p=0}^{n-2}{\left(2\cdot\frac{p}{2}+1\right)}
                       + \left(2\cdot\frac{n-1}{2}\right) + 1
                     = \frac{1}{2}{n^2} + \frac{1}{2}{n} + 1.
\end{equation*}
Élégamment, cette formule est valable même si \(n=0,1\) et nous
pouvons comparer maintenant \(\M{\fun{isrt\_tf}}{n}\) à
\(\M{\fun{isrt}}{n}\), si \(n\geqslant{}0\):
\begin{equation*}
\M{\fun{isrt\_tf}}{n}
  = \tfrac{1}{2}{n^2} + \tfrac{1}{2}{n} + 1
  \sim \tfrac{1}{2}{n^2} \sim 2 \cdot \M{\fun{isrt}}{n}.
\end{equation*}
En d'autres termes, \erlcode{isrt\_tf/1}, bien qu'optimisée, est
néanmoins 50\% plus lente que la fonction originelle, \emph{en
  moyenne pour de grandes valeurs de \(n\)}. Ceci ne devrait pas être
trop surprenant, car une transformation en forme terminale ne devrait
être entreprise que pour soulager la pile de contrôle, pas améliorer
l'efficacité.
\index{langage fonctionnel!forme terminale|)}

\paragraph{Exercice}

Considérez la variante
{\small
\begin{verbatim}
isrt0(L)                            -> isrt0(    L,   [],   []).
isrt0(   [],   [],    Q)            -> Q;
isrt0(   [],[J|P],    Q)            -> isrt0(   [],    P,[J|Q]);
isrt0([I|L],    P,[K|Q]) when K > I -> isrt0([I|L],[K|P],    Q);
isrt0([I|L],[J|P],    Q) when I > J -> isrt0([I|L],    P,[J|Q]);
isrt0([I|L],    P,    Q)            -> isrt0(    L,    P,[I|Q]).
\end{verbatim}
}
\noindent Ici, une réécriture implique le déplacement d'une clé
exactement, donc le coût de \erlcode{isrt0/3} est le nombre de
mouvements de clés pour trier la pile originelle. Analysez le nombre
minimum, maximum et moyen de mouvements de clés.

\paragraph{Codage léger des piles d'accumulation}
\index{pile!codage avec des \(n\)-uplets|(}

Les accumulateurs utilisés pour transformer les définitions en forme
terminale sont, dans leur cas le plus général, des piles ou des
\(n\)-uplets. Bien que l'usage d'une pile incarne bien la fonction de
l'accumulateur, il encoure une pénalité proportionnelle à la mémoire
nécessaire parce que, dans les arbres de syntaxe abstraite, un
empilage correspond à un n{\oe}ud, tout comme un \(n\)-uplet. \emph{En
  utilisant des \(n\)-uplets dans des \(n\)-uplets, nous pouvons nous
  passer de la pile complètement.} Ainsi, au lieu de
\erlcode{[\{k3,\(X_1\)\},\{k1,\(V\),\(E\)\},\{k3,\(X_2\)\}]}, nous
écririons les \(n\)-uplets imbriqués
\erlcode{\{k3,\(X_1\),\{k1,\(V\),\(E\),\{k3,\(X_2\),\{\}\}\}\}}. Les
deux arbres de syntaxe abstraite sont facilement comparés à la
\fig~\ref{fig:tuple_vs_stack}.
\begin{figure}
\centering
\subfloat[Avec une pile de \(n\)-uplets\label{fig:acc_stack}]{
  \includegraphics[bb=72 642 220 721]{acc_stack}
}
\subfloat[Avec des \(n\)-uplets imbriqués\label{fig:acc_tup}]{
  \includegraphics[bb=71 659 195 721]{acc_tup}
}
\caption{Deux mises en {\oe}uvre du même accumulateur linéaire}
\label{fig:tuple_vs_stack}
\end{figure}
Le codage d'une pile d'accumulation par le biais de \(n\)-uplets
uniquement suppose d'ajouter une composante à chaque \(n\)-uplet, qui
contient ce qui était le «~prochain~» \(n\)-uplet dans la pile. La
mémoire ainsi économisée consiste en une référence (arc) pour chaque
\(n\)-uplet initial, plus tous les n{\oe}uds d'empilage, c'est-à-dire
que s'il y avait \(m\)~\(n\)-uplets, nous économisons \(m\)~références
(souvent appelées \emph{pointeurs} dans les langages impératifs) et
\(m\)~n{\oe}uds. Ceci est un gain significatif. Pour l'illustrer,
améliorons donc le programme que nous avons obtenu précédemment:
\index{pile!aplatissement|(}
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,[]).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) appk([],A);
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) flat0(Y,[\{k1,T\}|A]);
flat0(    [Y|T],A)   \(\smashedrightarrow{\zeta}\) flat0(T,[\{k34,Y\}|A]).
cat(   [],T,A)       \(\smashedrightarrow{\eta}\) appk(T,A);
cat([X|S],T,A)       \(\smashedrightarrow{\theta}\) cat(S,T,[\{k34,X\}|A]).
appk(V,[\{k34,Y\}|A])  \(\smashedrightarrow{\mu}\) appk([Y|V],A);
appk(V, [\{k2,W\}|A])  \(\smashedrightarrow{\lambda}\) cat(W,V,A);
appk(V, [\{k1,T\}|A])  \(\smashedrightarrow{\kappa}\) flat0(T,[\{k2,V\}|A]);
appk(V,         [])  \(\smashedrightarrow{\iota}\) V.
\end{alltt}
Il devient le programme suivant, moins gourmand:
\begin{alltt}
flat0\_tf(T)          \(\smashedrightarrow{\alpha}\) flat0(T,\{\}).
flat0(         [],A) \(\smashedrightarrow{\gamma}\) appk([],A);
flat0(     [[]|T],A) \(\smashedrightarrow{\delta}\) flat0(T,A);
flat0([Y=[\_|\_]|T],A) \(\smashedrightarrow{\epsilon}\) flat0(Y,\{k1,T,A\});
flat0(      [Y|T],A) \(\smashedrightarrow{\zeta}\) flat0(T,\{k34,Y,A\}).
cat(   [],T,A)       \(\smashedrightarrow{\eta}\) appk(T,A);
cat([X|S],T,A)       \(\smashedrightarrow{\theta}\) cat(S,T,\{k34,X,A\}).
appk(V,\{k34,Y,A\})    \(\smashedrightarrow{\mu}\) appk([Y|V],A);
appk(V, \{k2,W,A\})    \(\smashedrightarrow{\lambda}\) cat(W,V,A);
appk(V, \{k1,T,A\})    \(\smashedrightarrow{\kappa}\) flat0(T,\{k2,V,A\});
appk(V,       \{\})    \(\smashedrightarrow{\iota}\) V.
\end{alltt}
\index{pile!aplatissement|)}
\index{pile!codage avec des \(n\)-uplets|)}

\paragraph{Améliorations}
\label{par:fib_ameliorations}
\index{fonction de Fibonacci!coût|(}

Juste pour illustrer le fait que les améliorations effectuées sur une
définition qui n'est pas en forme terminale sont plus bénéfiques
qu'une simple transformation en forme terminale, nous allons examiner
à nouveau la fonction de Fibonacci:
\begin{verbatim}
fib(0)            -> 1;
fib(1)            -> 1;
fib(N) when N > 1 -> fib(N-1) + fib(N-2).
\end{verbatim}
Les équations définissant le coût de cette fonction sont simplement
\begin{equation*}
\C{\fun{fib}}{0} := 1;\quad
\C{\fun{fib}}{1} := 1;\quad
\C{\fun{fib}}{n} := 1 + \C{\fun{fib}}{n-1} +
\C{\fun{fib}}{n-2},\,\; \text{avec} \,\; n > 1.
\end{equation*}
Ajoutons~\(1\) aux deux côtés de la dernière équation et réordonnons
les termes:
\begin{equation*}
\C{\fun{fib}}{n} + 1
  = (\C{\fun{fib}}{n-1} + 1) + (\C{\fun{fib}}{n-2} + 1).
\end{equation*}
Ceci nous donne l'idée de poser \(D_n := \C{\fun{fib}}{n} + 1 \),
ce qui donne, si~\(n > 1\):
\begin{equation*}
D_0 = \C{\fun{fib}}{0} + 1 = 2,\quad
D_1 = \C{\fun{fib}}{1} + 1 = 2,\quad
D_n = D_{n-1} + D_{n-2}.
\end{equation*}
La récurrence est la même que pour la séquence de Fibonacci (troisième
clause de \erlcode{fib/1}), sauf pour \(D_0\)~et~\(D_1\), dont les
valeurs sont~\(2\) au lieu de~\(1\). Dans le but de les faire
coïncider avec les valeurs de \erlcode{fib/1}, nous devons poser \(F_n
:= D_n/2\):
\begin{equation*}
\C{\fun{fib}}{n} = 2 \cdot F_n - 1.
\end{equation*}
Nous avons maintenant \(F_0 = F_1 = 1\) et \(F_n = F_{n-1} +
F_{n-2}\), pour tout \(n > 1\); il est important que \(F_n\)~calcule
les mêmes valeurs que~\erlcode{fib/1}, c'est-à-dire que nous avons
\(F_n \equiv \erlcode{fib(\(n\))}\). La \emph{fonction
  génératrice}\index{dénombrement combinatoire!fonction génératrice}
associée à la séquence \((F_n)_{n \geqslant 0}\) est
\begin{equation}
f(x) := \sum_{k \geqslant 0}{F_kx^k}.
\label{eq:Fib}
\end{equation}
Laissons de côté pour un instant la convergence et recherchons une
forme close de \(f(x)\). On a \(xf(x) = \sum_{k > 0}{F_{k-1}x^k}\) et
\(x^2f(x) = \sum_{k>1}{F_{k-2}x^k}\):
\begin{equation*}
f(x) - xf(x) - x^2f(x) = F_0 + F_1x - F_0x
                         + \sum_{k>1}{(F_k - F_{k-1} - F_{k-2})x^k}
                       = x.
\end{equation*}
Donc
\begin{equation*}
\abovedisplayskip=0pt
\abovedisplayshortskip=0pt
\belowdisplayskip=4pt
f(x) = \frac{x}{1 - x - x^2}.
\end{equation*}
Développons \(f(x)\) en série entière en posant \(\phi :=
\frac{1+\sqrt{5}}{2}\) et \(\hat\phi := \frac{1-\sqrt{5}}{2}\), les
racines de \(1 - x - x^2\), et factorisons le dénominateur:
\begin{equation*}
f(x) = \frac{x}{(1-\phi x)(1-\hat\phi x)}
     = \frac{1}{\sqrt{5}}\left(\frac{1}{1 - \phi x}
                              - \frac{1}{1 - \hat\phi x}\right).
\end{equation*}
Utilisons la série entière géométrique \(\frac{1}{1-\alpha x} =
\sum_{k \geqslant 0}{\alpha^kx^k}\) pour obtenir
\begin{equation*}
f(x) = \sum_{k \geqslant 0}{\frac{\phi^k-\hat\phi^k}{\sqrt{5}}}x^k,
\end{equation*}
donc, par identification avec les coefficients de
l'équation~\eqref{eq:Fib},
\begin{equation*}
\abovedisplayskip=4pt
\abovedisplayshortskip=4pt
\belowdisplayskip=4pt
F_n = \frac{1}{\sqrt{5}}(\phi^n - \hat\phi^n).
\end{equation*}
(Lire \cite{GrahamKnuthPatashnik_1994}, \S~6.6, pour plus de détails.)
Nous pourrions douter de ce résultat, car la méthode a négligé de
vérifier les domaines de convergence, donc
prouvons\index{induction!exemple|(} par induction sur \(n > 0\) que
\begin{equation*}
F_0 = 1;\quad F_n = \frac{1}{\sqrt{5}}(\phi^n - \hat\phi^n).
\end{equation*}
D'abord, vérifions la formule pour la plus petite valeur de~\(n\):
\begin{equation*}
F_1 = \frac{1}{\sqrt{5}}(\phi - \hat\phi)
   = \frac{1}{\sqrt{5}}(\phi - (1 - \phi)) = 1,
\end{equation*}
où nous avons fait usage du fait que \(\hat\phi = 1 -
\phi\). Supposons maintenant que l'équation à établir est valide pour
toutes les valeurs de \(1\)~à~\(n\) (l'hypothèse d'induction complète)
et prouvons qu'elle est vraie pour \(n+1\). Nous avons \( F_{n+1} :=
F_n + F_{n-1}\). Nous pouvons appliquer l'hypothèse d'induction pour
les cas \(n-1\) et~\(n\):
\begin{align*}
F_{n+1} &= \frac{1}{\sqrt{5}}(\phi^n - \hat\phi^n) +
          \frac{1}{\sqrt{5}}(\phi^{n-1} - \hat\phi^{n-1})\\
       &= \frac{1}{\sqrt{5}}(\phi^{n-1}(\phi + 1) -
          \hat\phi^{n-1}(\hat\phi + 1)).
\end{align*}
La clé est que \(\phi\)~et~\(\hat\phi\) sont les racines de \(x^2 = x
+ 1\), donc
\begin{equation*}
  F_{n+1} = \frac{1}{\sqrt{5}}(\phi^{n-1} \cdot \phi^2 -
          \hat\phi^{n-1} \cdot \hat\phi^2)
       = \frac{1}{\sqrt{5}}(\phi^{n+1} - \hat\phi^{n+1}),
\end{equation*}
ce qui est la proposition à prouver. Le principe d'induction complète
implique alors que l'équation est vraie pour tout \(n>0\).
\index{induction!exemple|)} Maintenant que nous avons une forme close
pour~\(F_n\), étudions son comportement asymptotique. Ceci est facile
si nous commençons par remarquer que \(\hat\phi < 1\), donc
\(\hat\phi^n \rightarrow 0\), pour des valeurs croissantes de~\(n\)
et, puisque \(\phi > 1\),
\begin{equation*}
F_n \sim \frac{1}{\sqrt{5}}\phi^n,\,\; \text{ce qui implique}
\,\; \C{\fun{fib}}{n} \sim \frac{2}{\sqrt{5}}\phi^n.
\end{equation*}
En d'autres termes, le coût est \emph{exponentiel}\index{coût!$\sim$ exponentiel}
et, puisque \(\phi > 1\), il sera toujours supérieur à tout coût
polynomial, sauf peut-être pour un nombre fini de petites valeurs
de~\(n\). L'affaire est donc sans espoir.

Comment pouvons-nous améliorer cette définition?

Nous devons résister la tentation de la transformer en forme terminale
parce que cela ne rendrait service qu'à la pile de contrôle, pas au
coût, en général. En regardant l'arbre des appels de \erlcode{fib(5)}
à la \fig~\vref{fig:fib5tree},
\begin{figure}[b]
\centering
\includegraphics{fib5tree}
\caption{Arbre des appels de \texttt{fib(5)}}
\label{fig:fib5tree}
\end{figure}
nous réalisons que quelques petits sous-arbres sont dupliqués, comme
ceux dont la racine est \erlcode{fib(2)}, et des plus grands comme
\erlcode{fib(3)}. Étudions la branche la plus à gauche, de la feuille
à la racine. Elle est faite des n{\oe}uds successifs \erlcode{fib(1)},
\erlcode{fib(2)}, \erlcode{fib(3)}, \erlcode{fib(4)} et
\erlcode{fib(5)}, à savoir \erlcode{fib(N)} pour toutes les valeurs
de~\erlcode{N} allant de~\erlcode{1} à~\erlcode{5}. En généralisant
cette observation, nous pouvons dire que la suite
\((\erlcode{fib(N)})_{\erlcode{N}}\) est entièrement décrite, sauf
\erlcode{fib(0)}, par la branche la plus à gauche dans l'arbre des
appels de \erlcode{fib(N)}. Par conséquent, en commençant avec le
petit arbre
\begin{center}
\includegraphics[bb=72 693 156 721]{fib2tree}
\end{center}
nous pouvons obtenir l'arbre des appels complet pour \erlcode{fib(5)}
en faisant croître l'arbre à partir de la racine, tout en partageant
certains sous-arbres, c'est-à-dire en les réutilisant plutôt qu'en les
recalculant, donc l'arbre ressemble maintenant à la
\fig~\vref{fig:fib5shared}
\begin{figure}
\centering
\includegraphics[bb=71 671 349 718]{fib5shared}
\caption{Arbre des appels de \erlcode{fib(5)} avec partage maximum}
\label{fig:fib5shared}
\end{figure}
où les arcs fléchés dénotent le partage de sous-arbres. À proprement
parler, il s'agit d'un graphe orienté sans circuits, et cette
représentation nous amène à penser que si deux nombres de Fibonacci
successifs sont conservés à tout moment, nous pouvons réaliser ce
partage maximum. Dénotons par~\(F_n\) le \(n^\text{e}\)~nombre de
Fibonacci dans la suite. Alors chaque étape de calcul est
\((F_{n-1},F_{n}) \rightarrow (F_{n}, F_{n+1}) :=
(F_{n},F_{n}+F_{n-1})\). Définissons~\(f\) telle que \(f(x,y) :=
(y,x+y)\), alors \((F_{n},F_{n+1}) = f(F_{n-1},F_{n})\) et
\begin{equation*}
(F_n,F_{n+1}) = f(F_{n-1},F_{n}) = f(f(F_{n-2},F_{n-1})) =
f^2(F_{n-2},F_{n-1})
\end{equation*}
etc. jusqu'à ce que nous atteignions \((F_{n},F_{n+1}) = f^n(F_0,F_1)
:= f^{n}(1,1)\), pour tout \(n \geqslant 0\). Soit \(\pi_1\) la
fonction telle que \(\pi_1(x,y) = x\), c'est-à-dire qu'elle projette
la première composante d'une paire, par conséquent \(F_n = \pi_1 \circ
f^n(1,1)\), pour tout \(n \geqslant 0\). L'itération de~\(f\) est
facile à définir par les récurrences
\begin{equation*}
f^0(x,y) = (x,y),\quad
f^n(x,y) = f^{n-1}(f(x,y)) := f^{n-1}(y,x+y).
\end{equation*}
Le programme \Erlang est maintenant aisé:
\begin{verbatim}
fib_opt(N) -> pi1(f(N,{1,1})).
pi1({X,_}) -> X.
f(0,{X,Y}) -> {X,Y};
f(N,{X,Y}) -> f(N-1,{Y,X+Y}).
\end{verbatim}
Une définition en forme terminale est extrêmement facile à obtenir,
sans même appliquer la méthode générale:
\begin{alltt}
fib\_opt\_tf(N) -> f(N,\{1,1\}).
f(0,\{X,\_\})    -> X;\hfill% \emph{Projection ici}
f(N,\{X,Y\})    -> f(N-1,\{Y,X+Y\}).
\end{alltt}
Nous déduisons que son coût est \(n + 2\). Ceci est une amélioration
impressionnante par rapport à \erlcode{fib/1} et, en cadeau surprise,
la définition est en forme terminale et est faite du même nombre de
clauses que l'original.
\index{fonction de Fibonacci!coût|)}

L'algorithme général que nous avons présenté dans cette section
transforme toutes les définitions des fonctions utilisées par une
définition donnée. En supposant que la taille limitée de la pile de
contrôle est un véritable problème, est-il possible de ne pas
transformer toutes les fonctions impliquées? Considérons à nouveau
\erlcode{slst0/2}, définie par l'équation~\eqref{eq:slst0}
\vpageref{eq:slst0}:
\begin{verbatim}
slst0(S,X) -> rev(sfst(rev(S),X)).
\end{verbatim}
Si nous employons la variante \erlcode{sfst0/2}, qui est en forme
terminale, au lieu de \erlcode{sfst/2}, et, puisque \erlcode{rev/1}
est déjà en forme terminale, nous avons
\begin{verbatim}
slst0(S,X) -> rev(sfst0(rev(S),X)).
\end{verbatim}
où toutes les fonctions composées sont en forme terminale. Bien sûr,
une composition de fonctions, comme \erlcode{sfst0/2}, n'est pas, par
définition, en forme terminale, mais ce n'est pas un problème. La
taille de la pile de contrôle nécessaire pour évaluer les appels à
\erlcode{slst0/2} sera majorée par une petite constante, parce qu'elle
n'est pas récursive.


\section{Fonctions d'ordre supérieur}
\index{langage fonctionnel!$\sim$ d'ordre supérieur|(}

\mypar{Tri polymorphe}
\index{tri par insertion!$\sim$ polymorphe|(}

Il y a un aspect du tri par insertion simple avec \erlcode{isrt/1}
(section~\ref{sec:straight_ins} \vpageref{sec:straight_ins}) qui
mérite une seconde réflexion. Les fonctions en \Erlang sont
\emph{polymorphes}\index{langage fonctionnel!polymorphisme},
c'est-à-dire qu'elles peuvent opérer sur certains arguments d'une
manière uniforme, quelque soit leur type. Par exemple, le retournement
d'une pile ne dépend pas de la nature des clés qu'elle contient ---
c'est un algorithme purement structurel. Par contraste, notre
définition de \erlcode{isrt/1} repose sur l'usage d'une comparaison
prédéfinie (\erlcode{>}) dans une garde. Ceci implique que toutes les
clés dans la pile doivent être comparables deux à deux; elles peuvent
être des entiers, par exemple. Mais comment faire si nous souhaitons
trier d'autres sortes de valeurs, comme des piles?

Considérons le besoin très concret d'ordonner un ensemble de factures:
chacune peut être représentée par une pile de prix arrondis à l'entier
le plus proche et l'ensemble lui-même par une pile; nous voudrions
alors trier par insertion les factures, disons, par totaux
non-décroissants. Si nous écrivons une version de \erlcode{isrt/1}
dédiée aux clés qui sont des piles d'entiers, nous dupliquons du code
et nous devrions écrire une version légèrement différente pour chaque
type de valeurs à ordonner. Par conséquent, nous avons besoin de
polymorphisme pour \emph{des paramètres fonctionnels}, plus
précisément, nous voulons qu'une fonction puisse être une valeur, donc
puisse être un argument. \Erlang offre cette possibilité d'une façon
naturelle et de nombreux langages fonctionnels aussi.

Dans notre cas, il faut que l'appelant de \erlcode{isrt/1} fournisse
un argument additionnel qui soit une fonction de comparaison de deux
clés. Alors la nouvelle version de \erlcode{isrt/2} utiliserait cette
comparaison définie par le programmeur, au lieu de toujours utiliser
l'opérateur prédéfini (\erlcode{>}) qui s'applique seulement (ou
presque) aux entiers. Voici encore la définition de \erlcode{isrt/1}:
\input{isrt_alpha} Par la suite, notre première tentative de
modification nous mène directement à
\begin{alltt}
isrtf(   [],\textbf{\_})             \(\smashedrightarrow{\beta}\) [];
isrtf([X|S],\textbf{F})             \(\smashedrightarrow{\gamma}\) ins(isrtf(S,\textbf{F}),X,\textbf{F}).
ins([Y|S],X,\textbf{F}) when \textbf{F(X,Y)} \(\smashedrightarrow{\delta}\) [Y|ins(S,X,\textbf{F})];
ins(    S,X,\textbf{\_})             \(\smashedrightarrow{\epsilon}\) [X|S].
\end{alltt}
Mais le compilateur rejetterait ce programme parce que \Erlang ne
permet pas l'appel d'une fonction dans les gardes. La raison est que
l'appel \erlcode{F(X,Y)} ci-dessus pourrait ne pas terminer et \Erlang
garantit que le filtrage termine. Comme il est impossible de vérifier
automatiquement pour toute fonction que tout appel termine (ce
problème est équivalent au fameux \emph{problème de l'arrêt d'une
  machine de Turing}, qui est \emph{indécidable}), le compilateur
n'essaie même pas et préfère rejeter toute garde avec des appels de
fonction. Par conséquent, nous devons déplacer l'appel
\erlcode{F(X,Y)} à l'intérieur du corps de la clause, ce qui engendre
la question de la fusion des clauses \(\delta\)~et~\(\epsilon\) en une
clause~\(\delta_0\).

Une façon élémentaire est de créer une autre fonction,
\erlcode{triage/4}, dont la tâche est de prendre le résultat de la
comparaison et de poursuivre avec le reste de l'évaluation. Bien sûr,
cela signifie que \erlcode{triage/4} doit aussi recevoir toutes les
informations nécessaire pour continuer:
\newlength\dblarrow\settowidth\dblarrow{\(\delta\sb{0}\)}
\begin{alltt}
isrtf(   [],\_)          \(\MyArrow{\dblarrow}{\beta}\) [];
isrtf([X|S],F)          \(\MyArrow{\dblarrow}{\gamma}\) ins(isrtf(S,F),X,F).
ins([Y|S],X,F)          \(\MyArrow{\dblarrow}{\delta\sb{0}}\) triage(F(X,Y),[Y|S],X,F).
triage(\fbcode{CCCCC},[Y|S],X,F) \(\MyArrow{\dblarrow}{\zeta}\) [Y|ins(S,X,F)];
triage(\fbcode{CCCCC},[Y|S],X,F) \(\MyArrow{\dblarrow}{\eta}\) [X|S].
\end{alltt}
Les cadres vides doivent être remplis avec le résultat d'une
comparaison. Dans notre cas, nous voulons une comparaison avec deux
résultats possibles (bivaluée), selon que le premier argument est
inférieur ou non au second. Par définition, le résultat de
\erlcode{X~>~Y} est l'atome~\erlcode{true} si la valeur de~\erlcode{X}
est supérieure à~\erlcode{Y}, sinon \erlcode{false}. Suivons la même
convention avec~\erlcode{F} et imposons que la valeur de
\erlcode{F(X,Y)} soit l'atome \erlcode{true} si~\erlcode{X} est
supérieur à~\erlcode{Y}, sinon \erlcode{false}. C'est encore mieux de
changer le paramètre~\erlcode{F} en quelque nom plus parlant, en
rapport avec son comportement, comme~\erlcode{Gt} (anglais,
\emph{\textbf{G}reater \textbf{t}han}):
\begin{alltt}
triage( \textbf{true},[Y|S],X,Gt) \(\MyArrow{\dblarrow}{\zeta}\) [Y|ins(Gt,X,S)];
triage(\textbf{false},[Y|S],X,Gt) \(\MyArrow{\dblarrow}{\eta}\) [X|S].
\end{alltt}
Remarquons que la clause~\(\eta\) ne fait aucun usage de~\erlcode{Y},
ce qui veut dire que nous perdons une clé. Que s'est-il passé et
quand? L'erreur s'est produite en ne réalisant pas que la
clause~\(\epsilon\) couvrait deux cas, \erlcode{S}~est vide ou non,
par conséquent nous aurions dû démêler ces deux cas avant de fusionner
la clause~\(\epsilon\) avec~\(\delta\), car dans~\(\delta\) nous avons
le motif \erlcode{[Y|S]}, à savoir le cas non-vide. Revenons donc sur
nos pas et séparons~\(\epsilon\) en \(\epsilon_0\)~et~\(\epsilon_1\):
\begin{alltt}
isrtf(   [], \_)              \(\MyArrow{\dblarrow}{\beta}\) [];
isrtf([X|S],Gt)              \(\MyArrow{\dblarrow}{\gamma}\) ins(isrtf(S,Gt),X,Gt).
ins([Y|S],X,Gt) when Gt(X,Y) \(\MyArrow{\dblarrow}{\delta}\) [Y|ins(S,X,Gt)];
ins(\textbf{[Y|S]},X,\textbf{Gt})              \(\MyArrow{\dblarrow}{\epsilon\sb{0}}\) [X|\textbf{[Y|S]}];
ins(   \textbf{[]},X, \_)              \(\MyArrow{\dblarrow}{\epsilon\sb{1}}\) \textbf{[X]}.
\end{alltt}
Remarquons que nous n'avons pas écrit
\begin{alltt}
ins([],X,\_) \(\MyArrow{\dblarrow}{\epsilon\sb{1}}\) [X];
ins( S,X,\_) \(\MyArrow{\dblarrow}{\epsilon\sb{0}}\) [X|S].
\end{alltt}
même si cela aurait été correct, parce que nous avions en tête la
fusion avec la clause~\(\delta\), donc nous avions besoin de rendre le
motif \erlcode{[Y|S]} explicite dans~\(\epsilon_0\). Pour encore plus
de clarté, nous avons mis en avant le paramètre~\erlcode{Gt}: les
motifs des clauses \(\delta\)~et~\(\epsilon_0\) sont maintenant
identiques et prêts à être fusionnés en une nouvelle
clause~\(\delta_0\):
\begin{alltt}
isrtf(   [], \_)          \(\MyArrow{\dblarrow}{\beta}\) [];
isrtf([X|S],Gt)          \(\MyArrow{\dblarrow}{\gamma}\) ins(isrtf(S,Gt),X,Gt).
ins([Y|S],X,Gt)          \(\MyArrow{\dblarrow}{\delta\sb{0}}\) triage(Gt(X,Y),[Y|S],X,Gt).
ins(   [],X, \_)          \(\MyArrow{\dblarrow}{\epsilon\sb{1}}\) [X].
triage( true,[Y|S],X,Gt) \(\MyArrow{\dblarrow}{\zeta}\) [Y|ins(S,X,Gt)];
triage(false,[Y|S],X, \_) \(\MyArrow{\dblarrow}{\eta}\) [X|[Y|S]].
\end{alltt}
Nous pouvons améliorer un petit peu la clause~\(\eta\) en ne
distinguant pas \erlcode{Y}~de~\erlcode{S}:
\begin{alltt}
triage(false,    \textbf{S},X, \_) \(\MyArrow{\dblarrow}{\eta}\) [X|\textbf{S}].
\end{alltt}
Cette transformation est correcte parce que \erlcode{S}~n'est jamais
vide. Au lieu d'utiliser une fonction auxiliaire comme
\erlcode{triage/4}, qui prend deux arguments et ne sert à rien d'autre
que tester la valeur de \erlcode{Gt(X,Y)} et, selon le résultat,
enchaîner la suite des calculs, nous pourrions employer la
construction \erlcode{case} :
\begin{alltt}
isrtf(   [], \_) \(\MyArrow{\dblarrow}{\beta}\) [];
isrtf([X|S],Gt) \(\MyArrow{\dblarrow}{\gamma}\) ins(isrtf(S,Gt),X,Gt).
ins([Y|S],X,Gt) \(\MyArrow{\dblarrow}{\delta\sb{0}}\) \textbf{case Gt(X,Y) of
                      true  \(\smashedrightarrow{\zeta}\) [Y|ins(S,X,Gt)];
                      false \(\smashedrightarrow{\eta}\) [X|[Y|S]]
                    end;}
ins(   [],X, \_) \(\MyArrow{\dblarrow}{\epsilon\sb{1}}\) [X].
\end{alltt}
Nous pouvons diminuer l'usage de la mémoire à nouveau dans la
clause~\(\eta\) (cas \erlcode{false}), cette fois-ci par le biais d'un
synonyme pour le motif \erlcode{[Y|S]}, d'où la meilleure version du
programme que voici:
\begin{alltt}
isrtf(   [], \_)   \(\MyArrow{\dblarrow}{\beta}\) [];
isrtf([X|S],Gt)   \(\MyArrow{\dblarrow}{\gamma}\) ins(isrtf(S,Gt),X,Gt).
ins(\textbf{T=}[Y|S],X,Gt) \(\MyArrow{\dblarrow}{\delta\sb{0}}\) case Gt(X,Y) of
                        true  \(\smashedrightarrow{\zeta}\) [Y|ins(S,X,Gt)];
                        false \(\smashedrightarrow{\eta}\) [X|\textbf{T}]
                      end;
ins(     [],X, \_) \(\MyArrow{\dblarrow}{\epsilon\sb{1}}\) [X].
\end{alltt}

Comment pourrions-nous appeler \erlcode{isrtf/2} de telle sorte que le
résultat soit le même qu'en appelant \erlcode{isrt/1}? Tout d'abord,
nous avons besoin d'une fonction de comparaison qui se comporte
exactement comme l'opérateur~(\erlcode{>}):
\begin{verbatim}
gt_int(X,Y) when X > Y -> true;
gt_int(_,_)            -> false.
\end{verbatim}
Si nous essayons maintenant de former l'appel
\begin{center}
\erlcode{isrtf([5,3,1,4,2],gt\_int)},
\end{center}
nous voyons qu'une erreur se produit à l'exécution parce que
\erlcode{gt\_int} est un atome, pas une fonction. C'est pourquoi
\Erlang fournit une syntaxe spéciale pour dénoter les fonctions
utilisées comme des valeurs:
\begin{center}
\erlcode{isrtf([5,3,1,4,2],\textbf{fun gt\_int/2})}.
\end{center}
Remarquons que le nouveau mot-clé~\erlcode{fun} et l'indication
habituelle du nombre des arguments sont présents (ici, deux).

Si nous passions en argument la fonction \erlcode{lt\_int/2},
définie ainsi
\begin{verbatim}
lt_int(X,Y) when X < Y -> true;
lt_int(X,Y)            -> false.
\end{verbatim}
la conséquence serait que le résultat est trié en ordre non-croissant
et tout ce que nous avions à faire pour cela était donc de changer la
fonction de comparaison, \emph{pas la fonction de tri elle-même}.

C'est un peu pénible d'avoir à nommer de simples fonctions de
comparaisons comme \erlcode{lt\_int/2}, qui n'est rien d'autre que
l'opérateur prédéfini~(\erlcode{<}). Heureusement, \Erlang fournit un
moyen de définir des fonctions sans leur donner un nom. La syntaxe
consiste à user des mot-clés \erlcode{fun} avec \erlcode{end} et à
mettre entre eux la définition normale, sans le nom de
fonction. Reconsidérons par exemple les appels précédents, mais en
utilisant des fonctions anonymes (appelées parfois
\emph{lambdas}). L'évaluation de
\begin{center}
\erlcode{isrtf([5,3,1,4,2],\textbf{fun}(X,Y) -> X > Y \textbf{end})}
\end{center}
est \erlcode{[1,2,3,4,5]} et l'évaluation de
\begin{center}
\erlcode{isrtf([5,3,1,4,2],\textbf{fun}(X,Y) -> X < Y \textbf{end})}
\end{center}
résulte en \erlcode{[5,4,3,2,1]}.

Utilisons maintenant \erlcode{isrtf/2} pour ordonner des piles de
piles d'entiers, selon la somme des entiers dans chaque pile --- ceci
est l'application du tri de factures que nous avons mentionné
précédemment. Comme l'exemple du tri d'entiers en ordre non-croissant
le suggère, nous n'avons seulement besoin ici que d'écrire comment
comparer deux piles d'entiers au moyen de la fonction \erlcode{sum0/1}
à la \fig~\vref{fig:sum0}). Nous avons \(\C{\fun{sum}_0}{n} = n +
2\). Nous pouvons alors définir la comparaison \erlcode{gt\_bill/2},
fondée sur l'opérateur~(\erlcode{>}):
\begin{alltt}
gt_bill(P,Q) -> sum0(P) > sum0(Q).
\end{alltt}
Remarquons en passant que la comparaison prédéfinie~(\erlcode{>})
calcule l'atome \erlcode{true} ou \erlcode{false}, donc il n'y a pas
besoin d'employer une construction \erlcode{case}. Par suite, nous
pouvons trier nos factures simplement en appelant
\begin{center}
\erlcode{isrtf([[1,5,2,9],[7],[2,5,11],[4,3]],fun gt\_bill/2)}
\end{center}
ou bien
\begin{alltt}
      isrtf([[1,5,2,9],[7],[2,5,11],[4,3]],
            \textbf{fun}(P,Q) -> sum0(P) < sum0(Q) \textbf{end}).
\end{alltt}
(D'ailleurs, est-ce que~\erlcode{[7]} devrait se trouver avant ou
après \erlcode{[4,3]}, dans le résultat? Que faudrait-il modifier pour
que l'ordre relatif de ces deux piles soit inversé?) Il est tout aussi
facile de trier les factures en ordre non-croissant. Cette grande
aisance qui consiste à passer des fonctions en argument, comme
n'importe quel autre type de valeurs, est ce qui justifie l'adjectif
\emph{fonctionnel} pour un langage comme \Erlang et d'autres. Une
fonction prenant une autre fonction en argument est une \emph{fonction
  d'ordre supérieur}.\index{tri par insertion!$\sim$ polymorphe|)}

\mypar{Listes d'associations ordonnées}
\label{sorted_association_lists} \index{liste d'association|(}

Nous pourrions améliorer la définition précédente de
\erlcode{isrtf/2}. Trier au moyen de comparaisons peut impliquer que
certaines clés sont comparées plus d'une fois, comme le pire des cas
du tri par insertion le montre bien. Il se pourrait qu'une comparaison
ait un coût modeste, mais, cumulé de nombreuses fois, nous pourrions
obtenir un total non négligeable. Dans le cas du tri de factures, il
est encore plus efficace de calculer tous les totaux d'abord et
ensuite utiliser ces montants durant le tri lui-même, parce que
comparer un entier à un autre est plus rapide que recalculer une somme
d'entiers dans une longue pile. Donc ce qui est ordonné est une pile
de paires dont la première composante, appelée la \emph{clé}, est un
représentant simple et petit de la seconde composante, appelée dans ce
contexte la \emph{valeur} (pas très correctement, car les clés sont
des valeurs \Erlang aussi, mais telle est la nomenclature
traditionnelle).

Cette structure de donnée est parfois appelée \emph{liste
  d'association}. Seule la clé est utilisée pour le tri, pas la
valeur, par conséquent, si la clé est un entier, la comparaison de
clés est probablement plus rapide que ne serait celle de
valeurs. L'unique pénalité est que toutes les clés doivent être
précalculées lors d'une première passe sur les données initiales et
elles doivent être écartées du résultat final, dans une passe finale.
Nous allons concevoir ces deux phases de la manière la plus générale
qui soit en paramétrant l'évaluation des clés~\erlcode{Mk}:
\begin{verbatim}
% Calcul des clés
mk_keys( _,        []) -> [];
mk_keys(Mk,[V|Values]) -> [{Mk(V),V}|mk_keys(Mk,Values)].

% Élimination des clés
rm_keys(            []) -> [];
rm_keys([{_,V}|KeyVal]) -> [V|rm_keys(KeyVal)].
\end{verbatim}
Le coût de \erlcode{mk\_keys/2} dépend du coût de~\erlcode{Mk}. Le
coût de \erlcode{rm\_keys(\(S\))} est~\(n+1\) si \(S\)~contient
\(n\)~paires clé-valeur. Nous pouvons maintenant trier en appelant
\erlcode{isrtf/2} avec une comparaison entre clés et avec une fonction
pour fabriquer lesdites clés, \erlcode{sum0/1}. Par exemple
\begin{verbatim}
 rm_keys(isrtf(mk_keys(fun sum0/1,
                       [[1,5,2,9],[7],[2,5,11],[4,3]]),
               fun({K1,_},{K2,_}) -> K1 > K2 end))
\end{verbatim}
Il est très important de noter que nous n'avons pas eu besoin de
redéfinir \erlcode{isrtf/2}. En fait, \erlcode{isrtf/2},
\erlcode{mk\_keys/2} et \erlcode{rm\_keys/1} pourraient très bien
former une bibliothèque en regroupant leur définition dans le même
module. Le client, à savoir, l'utilisateur de la bibliothèque,
fournirait alors la fonction de comparaison qui sied à ses données et
la fonction qui calcule les clés. Cette \emph{modularité} est rendue
possible par le polymorphisme et les fonctions d'ordre supérieur.

Illustrons la versatilité de notre programme avec un dernier exemple
où nous trions des piles par leur longueurs non-croissantes:
\begin{verbatim}
 rm_keys(isrtf(mk_keys(fun len0/1,
                       [[1,5,2,9],[7],[2,5,11],[4,3]]),
               fun({K1,_},{K2,_}) -> K1 < K2 end))
\end{verbatim}
où \erlcode{len0/1} est définie à la \fig~\vref{fig:len0}.
\begin{figure}[b]
\begin{equation*}
\boxed{
\begin{array}{@{}r@{\;}l@{\;}l@{}}
\fun{len}_0(s) & \rightarrow & \fun{len}_0(s,0).\\
\fun{len}_0(\el,n) & \rightarrow & n;\\
\fun{len}_0(\cons{x}{s},n) & \rightarrow & \fun{len}_0(s,n+1).
\end{array}}
\end{equation*}
\caption{Calcul de la longueur d'une pile (forme terminale)}
\label{fig:len0}
\end{figure}
Le résultat est
\begin{center}
\erlcode{[[1,5,2,9],[2,5,11],[4,3],[7]]}.
\end{center}
Remarquons que \erlcode{[4,3]} apparaît avant~\erlcode{[7]} parce que
la première pile est plus longue.

Spécialisons davantage \erlcode{isrtf/1}. En voici la définition à
nouveau:
\begin{alltt}
isrtf(   [], \_)   \(\MyArrow{\dblarrow}{\beta}\) [];
isrtf([X|S],Gt)   \(\MyArrow{\dblarrow}{\gamma}\) ins(isrtf(S,Gt),X,Gt).
ins(T=[Y|S],X,Gt) \(\MyArrow{\dblarrow}{\delta\sb{0}}\) case Gt(X,Y) of
                        true  \(\smashedrightarrow{\zeta}\) [Y|ins(S,X,Gt)];
                        false \(\smashedrightarrow{\eta}\) [X|T]
                      end;
ins(     [],X, \_) \(\MyArrow{\dblarrow}{\epsilon\sb{1}}\) [X].
\end{alltt}
Il est clair que si les clés sont répétées dans la pile d'entrée,
l'appel \erlcode{Gt(X,Y)} devrait être réécrit en \erlcode{false} au
moins une fois, donc les doublons sont conservés par la
clause~\(\eta\) et leur ordre relatif est préservé, c'est-à-dire que
l'algorithme de tri est stable. Si nous ne souhaitons pas préserver de
tels doublons, nous devons réécrire la définition. Ce choix devrait
naturellement être réalisé par un paramètre supplémentaire,
comme~\erlcode{Eq}. De plus, nous aurions besoin d'une comparaison
trivaluée, de façon à mettre en avant le test d'égalité. Modifions la
variable~\erlcode{Gt} pour refléter ce niveau de détail supplémentaire
et appelons-la, avec plus de généralité, \erlcode{Cmp}
(\emph{compare}). Ses arguments devraient être des valeurs parmi les
atomes~\erlcode{lt} (anglais, \emph{lower than}), \erlcode{gt}
(anglais, \emph{greater than}) et~\erlcode{eq} (anglais,
\emph{equal}). Nous avons
\begin{alltt}
isrtf(   [],  \_, \_)   \(\MyArrow{\dblarrow}{\beta}\) [];
isrtf([X|S],Cmp,\textbf{Eq})   \(\MyArrow{\dblarrow}{\gamma}\) ins(isrtf(S,Cmp,\textbf{Eq}),X,Cmp,\textbf{Eq}).
ins(T=[Y|S],X,Cmp,\textbf{Eq}) \(\MyArrow{\dblarrow}{\delta\sb{0}}\) case Cmp(X,Y) of
                            gt \(\smashedrightarrow{\zeta}\) [Y|ins(S,X,Cmp,\textbf{Eq})];
                            lt \(\smashedrightarrow{\eta}\) [X|T];
                            eq \(\smashedrightarrow{\theta}\) \textbf{Eq(X,T)}\hfill% \emph{Nouveau cas}
                          end;
ins(     [],X,  \_, \_) \(\MyArrow{\dblarrow}{\epsilon\sb{1}}\) [X].
\end{alltt}
À présent, exprimons notre volonté de trier par ordre non-décroissant
une pile d'entier et de retenir les nombres redondants, comme dans la
version précédente. Nous avons (la nouveauté est graissée):
\begin{alltt}
isrtf([5,3,1,4,3],fun(X,Y) -> X>Y end,\textbf{fun(X,T) ->\! [X|T] end})
\end{alltt}
qui résulte en \erlcode{[1,3,3,4,5]}. Si nous ne voulons pas de
répétitions, nous formons à la place l'appel
\begin{alltt}
isrtf([5,3,1,4,3],fun(X,Y) -> X>Y end,\textbf{fun(\_,T) -> T end})
\end{alltt}
qui aboutit à \erlcode{[1,3,4,5]}. En passant, cette technique résout
le problème de l'élimination des doublons dans une pile de clés pour
lesquelles il existe un ordre total. Néanmoins, si nous ne souhaitons
ôter que les clés identiques contiguës, la fonction \erlcode{red/1},
définie à la \fig~\vref{fig:red}, est plus efficace parce que son coût
est linéaire en la taille de l'entrée.

Nous devons préciser qu'une fonction d'ordre supérieur n'est pas
seulement une fonction dont au moins un paramètre est une fonction,
mais que ce peut être aussi une fonction dont les appels s'évaluent en
une fonction. Cette sorte de fonction est dite
\emph{curryfiée},\index{langage fonctionnel!$\sim$ d'ordre
  supérieur!fonction curryfiée} en hommage au logicien Haskell
Curry. La possibilité était déjà présente quand nous avons présenté
les mots-clés \erlcode{fun}~et~\erlcode{end}, parce qu'ils permettent
de définir une fonction anonyme et de l'utiliser comme n'importe
quelle autre valeur, donc rien ne nous empêchait d'employer une telle
valeur fonctionnelle comme le résultat d'une fonction nommée, comme
dans la fonction suivante qui compose deux autres fonctions:
\begin{verbatim}
compose(F,G) -> (fun(X) -> F(G(X)) end).
\end{verbatim}
En fait, les parenthèses autour de la valeur fonctionnelle sont
inutiles si nous nous souvenons que \emph{les mots-clés
  \erlcode{fun}~et~\erlcode{end} jouent le rôle de parenthèse quand la
  fonction anonyme n'est pas appelée}:
\begin{verbatim}
compose(F,G) -> fun(X) -> F(G(X)) end.
\end{verbatim}
La fonction d'ordre supérieur \erlcode{compose/2} peut être utilisée
pour calculer la composition de deux autres fonctions, le résultat
étant une fonction, bien sûr.
\index{liste d'association|)}

%\medskip

\paragraph{Itérateurs fonctionnels}
\addcontentsline{toc}{subsection}{Mappage et compositions itérées}
\label{par:maps}

Nous pourrions désirer une fonction qui additionne les images d'une
pile~\(S\) d'entiers par une fonction donnée~\(f\). En notation
mathématique, le résultat final serait exprimé ainsi:
\begin{equation*}
\sum_{k \in S}{f(k)}.
\end{equation*}
Dans le but de mettre en {\oe}uvre ceci en \Erlang, nous devons
procéder en deux temps: d'abord, nous avons besoin d'une fonction
d'ordre supérieur qui calcule les images des éléments d'une pile par
une fonction; ensuite, nous avons besoin d'une fonction qui somme les
entiers d'une pile. Nous avons déjà rencontré cette dernière, à la
\fig~\vref{fig:sum0} en la personne de \erlcode{sum0/1}. La première
fonction est une \emph{projection} (en anglais, \emph{map}) et nommée
\erlcode{map/2}, de telle sorte que l'appel \erlcode{map(\(F\),\(S\))}
applique la fonction~\(F\) à tous les éléments de la pile~\(S\) et
s'évalue en la pile des résultats. C'est-à-dire,
\begin{equation*}
\erlcode{map(\(F\),[\(X_1\),\(X_2\),\(\ldots\),\(X_{n}\)])}
\equiv
\erlcode{[\(F\)(\(X_1\)),\(F\)(\(X_2\)),\(\ldots\),\(F\)(\(X_{n}\))]}.
\end{equation*}
Avec ce but en tête, il est facile de définir \erlcode{map/2}:
\begin{verbatim}
map(_,   []) -> [];
map(F,[X|S]) -> [F(X)|map(F,S)].
\end{verbatim}
La fonction que nous recherchons est maintenant définie de façon
compacte comme la composition de \erlcode{map/2} et \erlcode{sum0/1}:
\begin{verbatim}
sumf(F) -> fun(S) -> sum0(map(F,S)) end.
\end{verbatim}
Par exemple, l'appel de fonction
\begin{center}
\erlcode{sumf(fun(X) -> X*X end)}
\end{center}
dénote la fonction qui somme les carrés des nombres dans une pile à
fournir. Elle est équivalente à la valeur
\begin{center}
\erlcode{fun(S) -> sum0(map(fun(X) -> X*X end,S)) end.}
\end{center}
Il est possible d'appeler cette fonction juste après qu'elle a été
calculée par \erlcode{sumf/1}, mais \emph{des parenthèses doivent être
  ajoutées autour d'une fonction anonyme appelée}. Par exemple, ces
parenthèses sont en gras souligné dans l'appel suivant:
\begin{center}
\erlcode{\underline{\textbf{(}}sumf(fun(X) -> X*X end)\underline{\textbf{)}}([1,2,3])}.
\end{center}
La fonction \erlcode{map/2} est souvent employée parce qu'elle capture
une opération fréquente sur les piles. Par exemple,
\begin{verbatim}
push(_,       []) -> [];
push(X,[P|Perms]) -> [[X|P]|push(X,Perms)].
\end{verbatim}
est équivalente à
\begin{alltt}
push(X,Perms) -> map(fun(P) -> [X|P] end,Perms).
\end{alltt}
Ce style conduit à des programmes plus clairs et il montre
l'évaluation récursive sous-jacente sans avoir à lire ou écrire une
définition pour cela. En d'autres termes, utiliser une fonction
d'ordre supérieur comme \erlcode{map/2} nous permet d'identifier un
motif récursif fréquent et cela laisse tout loisir au programmeur de
se concentrer sur le traitement spécifique des éléments. Nous
rencontrerons d'autres exemples, mais imaginons un instant que nous
ayons saisi plutôt
\begin{alltt}
push(X,Perms) -> map(fun(\textbf{Perms}) -> [X|\textbf{Perms}] end,Perms).
\end{alltt}
Le compilateur \Erlang afficherait l'avertissement suivant:
\begin{center}
\emph{\texttt{Warning: variable 'Perms' shadowed in
    'fun'.}}\label{shadowing}
\end{center}
qui veut dire: «~Avertissement: la variable \erlcode{Perms} est
occultée par \erlcode{fun}.~» En d'autres termes, dans le corps de la
fonction anonyme, toute occurrence de \erlcode{Perms} fait référence à
\erlcode{fun(Perms)}, mais pas à \erlcode{push(X,Perms)}. Dans ce cas,
ce n'est pas une erreur, mais les concepteurs du compilateur ont voulu
avertir d'une possible confusion. Par exemple,
\begin{alltt}
push(X,Perms) -> map(fun(X) -> [X|X] end,Perms).\hfill% \emph{Capture}
\end{alltt}
est clairement erronée parce que les deux variables~\erlcode{X} dans
\erlcode{[X|X]}, qui est le corps de la fonction anonyme, sont le
paramètre de la fonction anonyme. Une occultation erronée est appelée
une \emph{capture}. Ici, le paramètre~\erlcode{X} lié par
\erlcode{push(X,Perms)} a été capturé pour désigner en fait le
paramètre de \erlcode{fun(X)}. En règle générale, il vaut mieux éviter
d'occulter un paramètre, comme le compilateur \Erlang nous le
rappelle. Notons que l'appel
\begin{center}
\erlcode{sumf(fun(S) -> S*S end)}
\end{center}
ne pose pas problème car il équivaut à
\begin{center}
\erlcode{fun(S) -> sum0(map(fun(S) -> S*S end,S)) end}
\end{center}
qui est une occultation correcte.

\paragraph{Composition itérée}
\label{par:folds}

D'autres schémas récursifs fréquemment utiles peuvent être réifiés en
une autre fonction d'ordre supérieur. Considérons une fonction qui
traverse complètement une pile tout en administrant un accumulateur
dont le contenu peut dépendre de l'élément couramment visité. Au bout
du compte, le résultat est la valeur finale de l'accumulateur, ou bien
une autre fonction est appelée pour le finaliser. Un exemple simple
est \fun{len0/1} à la \fig~\vref{fig:len0}. Dans ce cas,
l'accumulateur est un entier et l'opération à laquelle il est soumis
est l'incrémentation, indépendamment de l'élément courant. Une autre
fonction retourne une pile (équation~\eqref{def:rev}
\vpageref{def:rev}):
\verbatiminput{rev.def}
Ici, l'accumulateur est une pile et l'opération consiste à empiler
l'élément courant. Abstrayons séparément ces deux tâches en une seule
fonction d'ordre supérieur
\begin{enumerate}

  \item qui prend en argument une fonction qui crée un nouvel
  accumulateur à partir de l'élément courant et l'accumulateur
  précédent,

  \item puis qui applique à celle-ci tous les éléments d'une pile en
  paramètre.

\end{enumerate}
Une fonction célèbre qui fait cela en \Erlang est \erlcode{foldl/3},
ce qui signifie en anglais \emph{fold left}, ou \emph{pliage à gauche}
parce qu'une fois que le nouvel accumulateur a été formé, le préfixe
de la pile peut être «~plié~» derrière la page où elle est écrite car il
n'est plus utile. Donc le nom devrait être compris comme «~composition
itérée de gauche à droite~» ou \emph{composition itérée à droite}. Nous
voulons
\begin{equation*}
\erlcode{foldl(\(F\),\(A\),[\(X_1\),\(X_2\),\(\ldots\),\(X_{n}\)])}
\equiv
\erlcode{\(F\)(\(X_{n}\),\(\ldots\),\(F\)(\(X_2\),\(F\)(\(X_1\),\(A\)))\(\ldots\))},
\end{equation*}
où \(A\)~est la valeur initiale de l'accumulateur. La
\fig~\vref{fig:foldl} montre les arbres de syntaxe abstraite
correspondants.
\begin{figure}
\centering
\subfloat[Pile \erlcode{S}]{%
  \includegraphics{a_stack}%[bb=71 650 148 721]
}
\qquad
\subfloat[\erlcode{foldl(F,A,S)}]{%
  \includegraphics[bb=62 660 135 721]{foldl}%[bb=69 651 164 721]
}
\caption{Résultat de \erlcode{foldl/3} sur une pile non-vide}
\label{fig:foldl}
\end{figure}
La définition suivante réalise l'effet désiré:
\begin{verbatim}
foldl(_,A,   []) -> A;
foldl(F,A,[X|S]) -> foldl(F,F(X,A),S).
\end{verbatim}
Nous pouvons alors écrire de nouvelles définitions de \erlcode{len0/1}
et \erlcode{rev/1}:
\begin{verbatim}
lenl(S) -> foldl(fun(_,A) ->   A+1 end, 0,S).
revl(S) -> foldl(fun(X,A) -> [X|A] end,[],S).
\end{verbatim}
La fonction \erlcode{foldl/3} n'est pas en forme terminale à cause de
l'appel imbriqué \erlcode{F(X,A)}, mais seule une portion constante de
pile de contrôle est utilisée pour la récursivité de \erlcode{foldl/3}
elle-même (un n{\oe}ud). Dans nos deux exemples, \erlcode{F}~est en
forme terminale, donc ces deux nouvelles définitions sont
\emph{presque} en forme terminale et peuvent tenir face aux
originaux. D'autres définitions presque en forme terminale sont
\begin{verbatim}
suml([N|S]) -> foldl(fun(X,A) ->      X+A end, N,S).
rcatl(S,T)  -> foldl(fun(X,A) ->    [X|A] end, T,S).
rmap(F,S)   -> foldl(fun(X,A) -> [F(X)|A] end,[],S).
\end{verbatim}
À nouveau, la raison pour laquelle ces définitions ne sont pas
exactement en forme terminale est due à l'appel \erlcode{F(X,A)} dans
la définition de \erlcode{foldl/3}, \emph{pas} à cause des arguments
fonctionnels \erlcode{fun(X,A) -> ... end} dans les appels à
\erlcode{foldl/3}: ceux-ci ne sont pas des appels de fonctions mais
des définitions de fonctions anonymes, c'est-à-dire des données. Le
principal avantage d'user de \erlcode{foldl/3} est qu'elle permet au
programmeur de se concentrer exclusivement sur le traitement de
l'accumulateur, pendant que \erlcode{foldl/3} elle-même fournit le
transport gratuitement. De plus, nous pouvons aisément comparer
différentes fonctions définies au moyen de \erlcode{foldl/3}.

Lorsque l'accumulateur est une pile sur laquelle des valeurs sont
empilées, le résultat est en ordre inverse par rapport à
l'entrée. C'est pourquoi \erlcode{rmap/2}, ci-dessus, n'est pas
équivalent à \erlcode{map/2}. La première doit être privilégiée si
l'ordre des éléments n'est pas significatif, parce que \erlcode{map/2}
a besoin d'une pile de contrôle aussi longue que la pile
d'entrée. Ceci nous amène naturellement à présenter une autre fonction
d'ordre supérieur: \erlcode{foldr/3}, dont le nom signifie
«~composition itérée de droite à gauche~» (anglais, \emph{fold right}),
ou \emph{composition itérée à gauche}. Nous voulons dire:
\begin{equation*}
\erlcode{foldr(\(F\),\(A\),[\(X_1\),\(X_2\),\(\ldots\),\(X_{n}\)])}
\equiv
\erlcode{\(F\)(\(X_1\),\(F\)(\(X_2\),\(\ldots\),\(F\)(\(X_{n}\),\(A\)))\(\ldots\))}.
\end{equation*}
La \fig~\vref{fig:foldr} montre les arbres de syntaxe abstraite
correspondants.
\begin{figure}
\centering
\subfloat[Pile \erlcode{S}]{%
  \includegraphics{a_stack}
}
\qquad
\subfloat[\erlcode{foldr(F,A,S)}]{%
  \includegraphics[bb=62 660 132 721]{foldr}
}
\caption{Résultat de \erlcode{foldr/3} sur une pile non-vide}
\label{fig:foldr}
\end{figure}
Nous parvenons à ce comportement avec la définition suivante:
\begin{verbatim}
foldr(_,A,   []) -> A;
foldr(F,A,[X|S]) -> F(X,foldr(F,A,S)).
\end{verbatim}
Cette définition, comme \erlcode{foldl/3}, n'est pas en forme
terminale, mais, au contraire de \erlcode{foldl/3}, elle requiert une
pile de contrôle aussi longue que la pile d'entrée.

Avec l'aide de \erlcode{foldr/3}, nous pouvons redéfinir
\erlcode{map/2} et \erlcode{cat/2} ainsi:
\begin{verbatim}
mapr(F,S) -> foldr(fun(X,A) -> [F(X)|A] end,[],S).
catr(S,T) -> foldr(fun(X,A) ->    [X|A] end, S,T).
\end{verbatim}
Comparons \erlcode{rcatl/2}, définie ci-dessus, avec \erlcode{catr/2}:
le rôle de l'accumulateur et de la pile d'entrée ont été échangés,
tout comme \erlcode{foldl/3} et \erlcode{foldr/3}. Il est aussi
loisible de définir
\begin{alltt}
lenr(S)     -> foldr(fun(_,A) -> 1+A end, 0,S).\hfill% \emph{Mauvais}
sumr([N|S]) -> foldr(fun(X,A) -> X+A end, N,S).\hfill% \emph{Mauvais}
isrtr(S)    -> foldr(fun(X,A) -> ins(A,X) end,[],S).\hfill% \emph{Non}
\end{alltt}
mais cela ne serait pas judicieux parce que \erlcode{foldr/3}
n'utilise pas une quantité bornée de la pile de contrôle,
contrairement à \erlcode{foldl/3}. Dans le cas de \erlcode{isrt/1}, il
vaut mieux appeler \erlcode{foldl/3}, parce que l'ordre d'insertion
n'est pas significatif en moyenne (bien qu'il échange le pire des cas
et le meilleur des cas si les éléments ne sont pas
répétés). Remarquons aussi, dans le cas de \erlcode{isrtr/1}, que
l'ordre des arguments de la fonction \erlcode{ins/2} est important.

Ceci nous amène à formuler des règles d'usage à propos de la
transformation en forme terminale. Nous savons déjà qu'une définition
en forme terminale est bénéfique ou même nécessaire si la taille
maximum de la pile de contrôle est inférieure à celle d'une entrée
traversée récursivement dans sa plus grande étendue. Aucune
accélération ne devrait être attendue a priori de la transformation en
forme terminale --- bien que ceci se produise parfois. Habituellement,
\begin{itemize}

  \item il est préférable, si possible, d'user de \erlcode{foldl/3} au
  lieu de \erlcode{foldr/3}, parce que, en supposant que le paramètre
  fonctionnel soit défini en forme terminale, l'appel utilisera une
  quantité limitée de la pile de contrôle (si le paramètre n'est pas
  en forme terminale, au moins \erlcode{foldl/3} ne pèsera pas
  davantage sur la pile de contrôle, contrairement à
  \erlcode{foldr/3});

  \item lorsque nous écrivons notre propre récursivité, c'est-à-dire
  sans ressortir aux compositions itérées, il vaut mieux faire en
  sorte qu'elle soit en forme terminale si l'accumulateur est un
  entier, sinon la taille maximum de la pile de contrôle utilisée peut
  être proportionnelle à la taille de l'entrée, bien que le résultat
  soit un entier. (Contraster \erlcode{sum/1} et \erlcode{sum0/2},
  mais aussi \erlcode{len/1} et \erlcode{len0/1}.)

\end{itemize}
Indépendamment de l'allocation de la pile, il peut y avoir une
différence significative en termes de coût lorsque nous utilisons une
composition itérée plutôt qu'une autre. Prenons par exemple les deux
appels suivants:
\begin{center}
\erlcode{foldl(fun cat/2,[],S)}
\(\equiv\)
\erlcode{foldr(fun cat/2,[],S)}.
\end{center}
Le premier sera plus lent que le second, comme
l'inégalité~\eqref{ineq:cat_assoc} \vpageref{ineq:cat_assoc} le
démontre.

Qu'est-ce qui ne peut être programmé par compositions itérées? Com\-me
leur propriété caractéristique le montrent, les compositions itérées
traversent la pile d'entrée dans sa totalité, donc il n'y a pas moyen
de descendre du train pendant qu'il roule. Par exemple, \fun{sfst/2} à
la section~\ref{sec:skipping}, \vpageref{sec:skipping}, est, en
\Erlang,
\begin{alltt}
sfst(   [],X) \(\smashedrightarrow{\theta}\) [];
sfst([X|S],X) \(\smashedrightarrow{\iota}\) S;
sfst([Y|S],X) \(\smashedrightarrow{\kappa}\) [Y|sfst(S,X)].
\end{alltt}
et ne peut être définie au moyen d'une composition itérée parce qu'il
y a deux fins possibles pour tout appel: soit l'élément n'a pas été
trouvé et nous rencontrons la fin de la pile à la clause~\(\theta\),
ou bien il a été trouvé quelque part dans la pile à la
clause~\(\iota\). Toutefois, en théorie, si nous acceptons une
traversée complète de la pile à chaque appel, alors \erlcode{sfst/2}
peut être programmée par le biais d'une composition itérée vers la
droite. La technique usuelle est d'avoir un accumulateur qui est soit
un atome signifiant «~absent~» ou une paire avec un atome signifiant
«~présent~» et la pile reconstruite. Si le résultat est «~absent,~» alors
nous retournons simplement la pile originelle. La fonction suivante
est un cas plus fort parce qu'elle ne peut absolument pas être
exprimée au moyen de compositions itérées, même au prix de
l'inefficacité. Il s'agit de
\label{code_ctail} \verbatiminput{ctail.def} En général, une
fonction~\(F\) peut être exprimée de manière équivalente par un appel
à une composition itérée si, et seulement si, pour toutes piles
\(S\)~et~\(T\), pour tout élément~\(X\), nous avons
\begin{equation*}
\erlcode{\(F\)(\(S\))} \equiv \erlcode{\(F\)(\(T\))}
\Rightarrow
\erlcode{\(F\)([\(X\)|\(S\)])}
\equiv
\erlcode{\(F\)([\(X\)|\(T\)])}.
\end{equation*}
(Voir \cite{GibbonsHuttonAltenkirch_2001,WeberCaldwell_2004}.) Par
exemple, on a \(\erlcode{ctail([])} \equiv \erlcode{ctail([2])}\) mais
\(\erlcode{ctail([1])} \mathrel{\not\equiv} \erlcode{ctail([1,2])}\).

Un effet secondaire positif de l'emploi de projections et compositions
itérées est qu'ils permettent parfois au programmeur de reconnaître
certaines compositions qui peuvent être améliorées au moyen d'une
équivalence. Par exemple, nous avons, pour toutes fonctions~\(F\)
et~\(G\):
\begin{equation*}
\erlcode{map(\(F\),map(\(G\),\(S\)))}
\equiv
\erlcode{map(compose(\(F\),\(G\)),\(S\))}.
\end{equation*}
Sans compter les coûts de \(F\)~et~\(G\), le membre gauche induit un
coût \(2n+2\), si \(S\)~contient \(n\)~éléments, alors que le membre
droit a pour coût \(n+2\), donc il est supérieur à l'autre. Une autre
équation intéressante est
\begin{equation}
\erlcode{foldl(\(F\),\(A\),\(S\))}
\equiv
\erlcode{foldr(\(F\),\(A\),\(S\))}\label{eq:foldlr}
\end{equation}
\emph{si \(F\)~est associative est symétrique.} Prouvons cela. Les
premières clauses des définitions de \erlcode{foldl/3} et
\erlcode{foldr/3} impliquent, pour tout \(F\)~et~\(A\),
\begin{equation*}
\erlcode{foldl(\(F\),\(A\),[])} \equiv A
\equiv \erlcode{foldr(\(F\),\(A\),[])}.
\end{equation*}
Pour des piles non-vides, cette équation signifie
\begin{equation*}
F(X_{n},\ldots,F(X_2,F(X_1,A))\ldots)
\equiv
F(X_1,F(X_2,\ldots,F(X_{n},A))\ldots).
\end{equation*}
Bien que les ellipses dans l'équivalence soient intuitives, elles ne
constituent pas une fondation solide pour un argument mathématique
rigoureux. À la place, par définition, nous avons
\begin{align*}
  \erlcode{foldl(\(F\),\(A\),[\(X\)|\(S\)])}
  &\equiv
   \erlcode{foldl(\(F\),\(F\)(\(X\),\(A\)),\(S\))}.
\intertext{Par définition aussi, nous avons}
\erlcode{foldr(\(F\),\(A\),[\(X\)|\(S\)])}
  &\equiv
   \erlcode{\(F\)(\(X\),foldr(\(F\),\(A\),\(S\)))}.
\intertext{L'équation originelle serait donc établie pour toutes
  les piles si}
\erlcode{foldl(\(F\),\(F\)(\(X\),\(A\)),\(S\))}
  &\equiv
   \erlcode{\(F\)(\(X\),foldr(\(F\),\(A\),\(S\)))}.
\end{align*}
Appelons cette conjecture~\(\predName{Fold}\) et prouvons-la par
induction structurelle. Rappelons ici que ce principe énonce que,
étant donné une structure de donnée finie~\(S\), une
propriété~\(\pred{Fold}{S}\) à prouver à son sujet, alors
\begin{enumerate}

  \item si \(\pred{Fold}{S}\)~est prouvable pour toutes les~\(S\)
  atomiques, à savoir, les configurations de~\(S\) qui ne peuvent être
  décomposées;

  \item si, en supposant \(\pred{Fold}{T}\) pour toutes les
    sous-structures immédiates~\(T\) de~\(S\), alors
    \(\pred{Fold}{S}\)~est vraie;

  \item alors \(\pred{Fold}{S}\)~est vraie pour \emph{toute}
    structure~\(S\).

\end{enumerate}
Ici, la structure de donnée~\(S\) étant une pile, il n'y a qu'une pile
atomique: la pile vide. Donc nous devons d'abord prouver
\(\pred{Fold}{\erlcode{[]}}\). Les premières clauses des définitions
de \erlcode{foldl/3} et \erlcode{foldr/3} impliquent que, pour tout
\(F\)~et~\(A\),
\begin{equation*}
\erlcode{foldl(\(F\),\(F\)(\(X\),\(A\)),[])}
\equiv \erlcode{\(F\)(\(X\),\(A\))}
\equiv
\erlcode{\(F\)(\(X\),foldr(\(F\),\(A\),[]))},
\end{equation*}
qui est \(\pred{Fold}{\erlcode{[]}}\). Ensuite, considérons une pile
non-vide \erlcode{[\(Y\)|\(S\)]}. Quelles sont ses sous-structures
immédiates? Par construction des piles, il n'y a qu'une sous-pile
immédiate de \erlcode{[\(X\)|\(S\)]}, à savoir~\(S\). Par conséquent,
supposons \(\pred{Fold}{S}\) pour une pile donnée~\(S\) et supposons
que \(F\)~est associative et symétrique (ceci est l'hypothèse
d'induction structurelle), puis prouvons
\(\pred{Fold}{\erlcode{[\(Y\)|\(S\)]}}\), pour
tout~\(Y\). L'associativité de~\(F\) signifie que pour toutes
valeurs~\(I\), \(J\)~et~\(K\), nous avons
\begin{align*}
F(I,F(J,K)) &\equiv F(F(I,J),K).
\intertext{La symétrie de~\(F\) veut dire que, pour tout~\(I\) et~\(J\),
nous avons}
F(I,J) &\equiv F(J,I).
\end{align*}
Commençons par le membre gauche de
\(\pred{Fold}{\erlcode{[\(Y\)|\(S\)]}}\):
\begin{equation*}
\begin{array}{@{}ll@{}}
\erlcode{foldl(\(F\),\(F\)(\(X\),\(A\)),[\(Y\)|\(S\)])}\\
\;\equiv
   \erlcode{foldl(\(F\),\(F\)(\(Y\),\(F\)(\(X\),\(A\))),\(S\))}
& \text{(définition de \erlcode{foldl/3})}\\
\;\equiv
   \erlcode{foldl(\(F\),\(F\)(\(F\)(\(Y\),\(X\)),\(A\)),\(S\))}
& \text{(associativité de~\(F\))}\\
\;\equiv
   \erlcode{foldl(\(F\),\(F\)(\(F\)(\(X\),\(Y\)),\(A\)),\(S\))}
& \text{(symétrie de~\(F\))}\\
\;\equiv
   \erlcode{\(F\)(\(F\)(\(X\),\(Y\)),foldr(\(F\),\(A\),\(S\)))}
& \text{(hypothèse d'induction \(\pred{Fold}{S}\))}\\
\;\equiv
   \erlcode{\(F\)(\(X\),\(F\)(\(Y\),foldr(\(F\),\(A\),\(S\))))}
& \text{(associativité de~\(F\))}\\
\;\equiv
   \erlcode{\(F\)(\(X\),foldr(\(F\),\(A\),[\(Y\)|\(S\)]))}
& \text{(définition de \erlcode{foldr/3}).}\hfill\Box
\end{array}
\end{equation*}
Ce raisonnement prouve \(\pred{Fold}{\erlcode{[\(Y\)|\(S\)]}}\). Le
principe d'induction structurelle implique alors que
\(\pred{Fold}{S}\) est vraie pour toutes les piles~\(S\), donc
l'équation~\eqref{eq:foldlr} \vpageref{eq:foldlr}. La dérivation
précédente suggère une variation de la définition de
\erlcode{foldl/3}:
\begin{alltt}
foldl\_alt(_,A,   []) -> A;
foldl\_alt(F,A,[X|S]) -> foldl_alt(F,F(\underline{\textbf{A,X}}),S).
\end{alltt}
La différence réside dans l'ordre des paramètres de~\erlcode{F}. Nous
aurions alors à prouver une conjecture légèrement différente:
\begin{equation*}
\erlcode{foldl\_alt(\(F\),\(F\)(\(A\),\(X\)),\(S\))}
\equiv
\erlcode{\(F\)(\(X\),foldr(\(F\),\(A\),\(S\)))}.
\end{equation*}
La dérivation précédente prendrait alors ici la forme suivante:
\begin{equation*}
\begin{array}{@{}l@{\;}l@{}}
\erlcode{foldl\_alt(\(F\),\(F\)(\(A\),\(X\)),[\(Y\)|\(S\)])}\\
\;\equiv
\erlcode{foldl\_alt(\(F\),\(F\)(\(F\)(\(A\),\(X\)),\(Y\)),\(S\))}
& \text{(définition)}\\
\;\equiv
   \erlcode{fold\_alt(\(F\),\(F\)(\(A\),\(F\)(\(X\),\(Y\))),\(S\))}
& \text{(associativité de~\(F\))}\\
\;\equiv
   \erlcode{\(F\)(\(F\)(\(X\),\(Y\)),foldr(\(F\),\(A\),\(S\)))},
& \text{(hypothèse d'induction \(\pred{Fold}{S})\)}\\
\;\equiv
   \erlcode{\(F\)(\(X\),\(F\)(\(Y\),foldr(\(F\),\(A\),\(S\))))}
& \text{(associativité de~\(F\))}\\
\;\equiv
   \erlcode{\(F\)(\(X\),foldr(\(F\),\(A\),[\(Y\)|\(S\)]))},
& \text{(définition de \erlcode{foldr/3}).}\hfill\Box
\end{array}
\end{equation*}
Nous voyons que la symétrie de~\(F\) n'est plus nécessaire que dans un
seul cas: lorsque la pile est vide. En effet, nous avons
\begin{align*}
\erlcode{foldl\_alt(\(F\),\(F\)(\(A\),\(X\)),[])}
  &\equiv \erlcode{\(F\)(\(A\),\(X\))},
  &&\text{par définition;}\\
\erlcode{\(F\)(\(X\),foldr(\(F\),\(A\),[]))}
  &\equiv \erlcode{\(F\)(\(X\),\(A\))},
  &&\text{par définition de \erlcode{foldr/3}.}
\end{align*}
Par conséquent, dans le but de prouver notre nouvelle conjecture à
propos de \erlcode{foldl\_alt/3} et \erlcode{foldr/3}, nous devons
avoir
\begin{equation*}
\erlcode{\(F\)(\(A\),\(X\))}
\equiv
\erlcode{\(F\)(\(X\),\(A\))},
\end{equation*}
c'est-à-dire que~\(A\), qui est la valeur initiale de l'accumulateur,
doit commuter avec tous les éléments par~\(F\). Ceci n'est pas une
nette amélioration par rapport au premier théorème sur
\erlcode{foldl/3}, qui exigeait que toutes les paires d'éléments
successifs commutent. Néanmoins, il existe un cas particulier
intéressant, qui est lorsque \(A\)~est un élément neutre pour~\(F\),
c'est-à-dire que, pour tout~\(X\),
\begin{equation*}
\erlcode{\(F\)(\(A\),\(X\))}
\equiv
\erlcode{\(F\)(\(X\),\(A\))} \equiv A.
\end{equation*}
Alors la symétrie n'est plus nécessaire du tout. Par conséquent, la
fonction \erlcode{foldl\_alt/3} est préférable à \erlcode{foldl/3},
parce qu'elle fournit plus d'occasions de transformation. Mais,
puisque la bibliothèque standard de \Erlang offre la définition
\erlcode{foldl/3}, nous continuerons à l'employer. La bibliothèque
standard de \OCaml, toutefois, propose la fonction
\erlcode{fold\_left}, qui correspond à \erlcode{foldl\_alt/3}.

De toute façon, le théorème~\eqref{eq:foldlr} nous permet de
transformer immédiatement certains appels à \erlcode{foldr/3}, qui
exige une quantité de pile de contrôle au moins proportionnelle à la
taille de la pile d'entrée, en appels à \erlcode{foldl/3}, dont le
paramètre~\(F\) est la seule fonction qui n'utilise peut-être pas une
portion constante de la pile de contrôle (si elle le fait, le gain est
alors encore plus évident). C'est pourquoi les définitions suivantes
sont équivalentes:
\begin{verbatim}
lenl(S) -> foldl(fun(_,A) -> A+1 end,0,S).
lenr(S) -> foldr(fun(_,A) -> A+1 end,0,S).
\end{verbatim}
Prouver que les deux définitions suivantes sont équivalentes est un
peu plus compliqué:
\begin{verbatim}
suml([N|S]) -> foldl(fun(X,A) -> X+A end,N,S).
sumr([N|S]) -> foldr(fun(X,A) -> X+A end,N,S).
\end{verbatim}
La raison est que le premier élément de la pile sert de valeur
initiale à l'accumulateur dans les deux cas, bien que l'ordre de
visite de la pile est inverse (vers la droite ou vers la gauche). Il
est bien plus clair de voir que les définitions suivantes sont
équivalentes:
\begin{verbatim}
sum1(S=[_|_]) -> foldl(fun(X,A) -> X+A end,0,S).
sum2(S=[_|_]) -> foldr(fun(X,A) -> X+A end,0,S).
\end{verbatim}
simplement parce que l'addition est associative et symétrique.

\paragraph{Codage fonctionnel des projections}
\addcontentsline{toc}{subsection}{Codages fonctionnels}
%\mypar{Mappings without association lists}

Pour illustrer davantage la puissance d'expression des fonctions
d'ordre supérieur, jouons avec un petit exemple, même s'il est un peu
improbable. Nous avons vu à la \vpageref{sorted_association_lists} que
les listes d'association sont des collections de paires clé-valeur,
réalisées simplement au moyen de piles, par exemple,
\erlcode{[\{a,0\},\{b,1\},\{a,5\}]}.

Une \emph{projection} est une liste d'association qui est fouillée en
fonction des clés. Typiquement, nous avons
\begin{alltt}
find(_,       []) -> absent;
find(X,[\{X,V\}|\_]) -> V;\hfill% \emph{Valeur associée trouvée}
find(X,    [\_|S]) -> find(X,S).\hfill% \emph{La recherche continue}
\end{alltt}
Remarquons que si une clé est répétée, seule la première paire sera
prise en compte, par exemple,
\erlcode{find(a,[\{a,0\},\{b,1\},\{a,5\}])} résultera en~\erlcode{0},
pas~\erlcode{5}. Ces paires sont appelées \emph{liaisons}. Supposons
maintenant que nous voulions présenter symboliquement ce qu'est une
projection, mais sans employer aucun langage de programmation
particulier. Dans ce cas, nous devons user des mathématiques pour
exprimer le concept, plus précisément, des fonctions mathématiques.

Nous dirions qu'une projection~\(M\) est une fonction d'un ensemble
fini de valeurs~\(\mathcal{K}\) vers un ensemble fini de
valeurs~\(\mathcal{V}\). Par conséquent, ce qui était précédemment la
conjonction d'un type de donnée (une pile) et d'une recherche
(\erlcode{find/2}) est maintenant une seule fonction, représentant la
projection \emph{et} la recherche en même temps. Une liaison \(x
\mapsto y\) n'est qu'une autre notation pour la paire~\((x, y)\), où
\(x \in \mathcal{K}\) et \(y \in \mathcal{V}\). Nous avons besoin
alors d'exprimer comment une projection est mise à jour, c'est-à-dire,
comment une projection est étendue avec une nouvelle liaison.

Avec une pile, ceci est simplement réalisé en empilant une nouvelle
paire mais, sans pile, nous dirions qu'une mise à jour est une
fonction prenant une projection et une liaison en arguments et
calculant une nouvelle projection. \emph{Une projection est donc une
fonction d'ordre supérieur.} Soit la fonction~\((\oplus)\) telle que
\(M \mathrel{\oplus} x_1 \mapsto y\) est la \emph{mise à jour} de la
projection~\(M\) par la liaison \(x_1 \mapsto y\), définie par
\begin{equation*}
(M \mathrel{\oplus} x_1 \mapsto y)(x_2) :=
\begin{cases}
  y      & \text{si} \; x_1 = x_2,\\
  M(x_2) & \text{sinon.}
\end{cases}
\end{equation*}
Nous pouvons vérifier que nous trouvons la valeur associée à la
première clé qui correspond à la donnée, comme nous nous y
attendions. La projection vide serait une fonction spéciale retournant
un symbol spécial signifiant «~absent,~» comme \(M_\varnothing(x) =
\bot\), pour tout~\(x\). La projection contenant la liaison \((1,5)\)
serait \(M_\varnothing \mathrel{\oplus} 1 \mapsto 5\).

Tout ceci est très abstrait et indépendant de tout langage de
programmation, tout en étant totalement précis. Si le besoin alors se
fait sentir de montrer comment cette définition peut être programmée,
c'est l'occasion pour les langages fonctionnels de briller. Une mise à
jour serait directement écrite en \Erlang ainsi:
\begin{verbatim}
update(M,{X1,Y}) -> fun(X2) -> case X2 of X1 -> Y;
                                           _ -> M(X2)
                               end
                    end.
\end{verbatim}
La correspondance avec la définition formelle est presque immédiate,
il n'y a pas besoin d'introduire une structure de donnée et son
interprétation, ni de prouver sa correction. La projection vide est
simplement
\begin{verbatim}
empty(_) -> absent.
\end{verbatim}
Par exemple, la projection représentée par la pile
\erlcode{[\{a,0\},\{b,1\},\{a,5\}]} peut être modelé avec des
fonctions d'ordre supérieur seulement ainsi:
\begin{center}
\erlcode{update(update(update(fun empty/1,\{a,5\}),\{b,1\}),\{a,0\})}.
\end{center}
Peut-être ce qui vaut la peine d'être retenu de tout cela est que les
piles dans les langages fonctionnels, bien qu'elles possèdent une
syntaxe dédiée et qu'elles soient amplement utilisées, elles ne sont
pas un type de donnée fondamental: les fonctions le sont.

\paragraph{Codage fonctionnel des \(n\)-uplets}

Commençons par abstraire un \(n\)-uplet en son essence et, parce que
dans un langage fonctionnel, les fonctions jouent un rôle proéminent,
nous devrions nous demander ce qui est \emph{fait} avec ce que nous
pensons être des \(n\)-uplets. En fait, nous nous sommes un peu
précipités car nous aurions dû nous rendre compte d'abord que tous les
\(n\)-uplets sont exprimables en termes du \(0\)-uplet et des
paires. Par exemple, \erlcode{\{5,foo,\{fun(X) -> X*X end\}\}} peut
être réécrit avec des paires imbriquées: \erlcode{\{5,\{foo,\{fun(X)
  -> X*X end,\{\}\}\}\}}. Reprenons alors notre question en termes de
paires uniquement. Fondamentalement, une paire est construite (ou
\emph{injectée}) et filtrée, c'est-à-dire déconstruite (ou
\emph{projetée}). Cette analyse mène à la conclusion qu'un codage
fonctionnel des paires requiert trois fonctions: une pour créer,
\erlcode{mk\_pair/2}, et deux pour défaire, \erlcode{fst/1} et
\erlcode{snd/1}. Une fois que la paire est construite, elle est
représentée comme une fonction, donc les fonctions qui extraient les
composantes prennent en argument une autre fonction dénotant la paire,
ce qui veut dire qu'elles sont d'ordre supérieur.
\begin{alltt}
mk\_pair(X,Y) \(\smashedrightarrow{\alpha}\) fun(Pr) \(\smashedrightarrow{\beta}\) Pr(X,Y) end.\hfill% \emph{Projection} Pr
fst(P) \(\smashedrightarrow{\gamma}\) P(fun(X,\_) \(\smashedrightarrow{\delta}\) X end).\hfill% P \emph{dénote une paire}
snd(P) \(\smashedrightarrow{\epsilon}\) P(fun(_,Y) \(\smashedrightarrow{\zeta}\) Y end).
\end{alltt}
Comme prévu, nous avons alors l'évaluation suivante:
\begin{alltt}
fst(mk\_pair(3,5)) \(\smashedrightarrow{\alpha}\) fst(fun(Pr) \(\smashedrightarrow{\beta}\) Pr(3,5))
                  \(\smashedrightarrow{\gamma}\) (fun(Pr) \(\!\smashedrightarrow{\beta}\!\) Pr(3,5))(fun(X,\_) \(\!\smashedrightarrow{\delta}\!\) X end)
                  \(\smashedrightarrow{\beta}\) (fun(X,\_) \(\smashedrightarrow{\delta}\) X end)(3,5)
                  \(\smashedrightarrow{\delta}\) 3.
\end{alltt}
Pour mettre à l'épreuve la versatilité de ce codage, définissons une
fonction \erlcode{add/1} qui somme les composantes de la paire passée
en argument:
\begin{alltt}
add(P) \(\smashedrightarrow{\eta}\) fst(P) + snd(P).
\end{alltt}
Un appel à \erlcode{add/1} se déroulerait comme suit, en supposant que
les arguments sont évalués vers la droite:
\begin{alltt}
add(mk\_pair(3,5))
  \(\smashedrightarrow{\alpha}\) add(fun(Pr) \(\smashedrightarrow{\beta}\) Pr(3,5) end)
  \(\smashedrightarrow{\eta}\)   fst(fun(Pr) \(\smashedrightarrow{\beta}\) Pr(3,5) end)
     + snd(fun(Pr) \(\smashedrightarrow{\beta}\) Pr(3,5) end)
  \(\smashedrightarrow{\gamma}\)   (fun(Pr) \(\smashedrightarrow{\beta}\) Pr(3,5) end)(fun(X,\_) \(\smashedrightarrow{\delta}\) X end)
     + snd(fun(Pr) \(\smashedrightarrow{\beta}\) Pr(3,5) end)
  \(\smashedrightarrow{\beta}\)   (fun(X,\_) \(\smashedrightarrow{\delta}\) X end)(3,5)
     + snd(fun(Pr) \(\smashedrightarrow{\beta}\) Pr(3,5) end)
  \(\smashedrightarrow{\delta}\) 3 + snd(fun(Pr) \(\smashedrightarrow{\beta}\) Pr(3,5) end)
  \(\smashedrightarrow{\epsilon}\) 3 + (fun(Pr) \(\smashedrightarrow{\beta}\) Pr(3,5) end)(fun(\_,Y) \(\smashedrightarrow{\zeta}\) Y end)
  \(\smashedrightarrow{\beta}\) 3 + (fun(\_,Y) \(\smashedrightarrow{\zeta}\) Y end)(3,5)
  \(\smashedrightarrow{\zeta}\) 3 + 5 \(=\) 8.
\end{alltt}
Le lecteur attentif pourrait se sentir néanmoins lésé parce que nous
aurions pu tout aussi bien définir \erlcode{add/2} ainsi:
\begin{verbatim}
add(X,Y) -> X + Y.
\end{verbatim}
En effet, cette critique est valide. La possibilité pour une fonction
de recevoir \(n\)~valeurs en argument équivaut à recevoir \emph{un}
\(n\)-uplet exactement, dont les composantes sont ces diverses
valeurs. Par conséquent, nous devons essayer à nouveau et nous assurer
que nos fonctions ne prennent aucun argument ou bien un. Ceci est
réalisé en prenant une valeur en argument puis en réécrivant l'appel
en une fonction qui, à son tour, prendra la prochaine valeur
etc. Cette traduction est appelée \emph{curryfication}.
\begin{alltt}
mk\_pair(X) \(\smashedrightarrow{\alpha}\) fun(Y) \(\smashedrightarrow{\beta}\) fun(Pr) \(\smashedrightarrow{\gamma}\) (Pr(X))(Y) end end.
fst(P) \(\smashedrightarrow{\delta}\) P(fun(X) \(\smashedrightarrow{\epsilon}\) fun(\_) \(\smashedrightarrow{\zeta}\) X end end).
snd(P) \(\smashedrightarrow{\eta}\) P(fun(\_) \(\smashedrightarrow{\theta}\) fun(Y) \(\smashedrightarrow{\iota}\) Y end end).
add(P) \(\smashedrightarrow{\kappa}\) fst(P) + snd(P).
\end{alltt}
Rappelons-nous que \erlcode{fun(X) -> fun(P) -> ...} est équivalente à
l'expression \erlcode{fun(X) -> (fun(P) -> ...)} Les parenthèses autour
de \erlcode{Pr(X)} sont nécessaires en \Erlang parce cet appel se
trouve en lieu et place d'une fonction qui est appelée. Maintenant
\begin{alltt}
add((mk\_pair(3))(5))
  \(\smashedrightarrow{\alpha}\) add((fun(Y) \(\smashedrightarrow{\beta}\) fun(Pr) \(\smashedrightarrow{\gamma}\) (Pr(3))(Y) end end)(5))
  \(\smashedrightarrow{\beta}\) add(fun(Pr) \(\smashedrightarrow{\gamma}\) (Pr(3))(5) end)
  \(\smashedrightarrow{\kappa}\)   fst(fun(Pr) \(\smashedrightarrow{\gamma}\) (Pr(3))(5) end)
     + snd(fun(Pr) \(\smashedrightarrow{\gamma}\) (Pr(3))(5) end)
  \(\smashedrightarrow{\delta}\)   (fun(Pr)\(\smashedrightarrow{\gamma}\)(Pr(3))(5) end)(fun(X)\(\smashedrightarrow{\epsilon}\)fun(_)\(\smashedrightarrow{\zeta}\)X end end)
     + snd(fun(Pr) \(\smashedrightarrow{\gamma}\) (Pr(3))(5) end)
  \(\smashedrightarrow{\gamma}\)   ((fun(X) \(\smashedrightarrow{\epsilon}\) fun(\_) \(\smashedrightarrow{\zeta}\) X end end)(3))(5)
     + snd(fun(Pr) \(\smashedrightarrow{\gamma}\) (Pr(3))(5) end)
  \(\smashedrightarrow{\epsilon}\) (fun(\_) \(\smashedrightarrow{\zeta}\) 3 end)(5) + snd(fun(Pr) \(\smashedrightarrow{\gamma}\) (Pr(3))(5) end)
  \(\smashedrightarrow{\zeta}\) 3 + snd(fun(Pr) \(\smashedrightarrow{\gamma}\) (Pr(3))(5) end)
  \(\smashedrightarrow{\eta}\) 3
     + (fun(Pr)\(\smashedrightarrow{\gamma}\)(Pr(3))(5) end)(fun(\_)\(\smashedrightarrow{\theta}\)fun(Y)\(\smashedrightarrow{\iota}\)Y end end)
  \(\smashedrightarrow{\gamma}\) 3 + ((fun(\_) \(\smashedrightarrow{\theta}\) fun(Y) \(\smashedrightarrow{\iota}\) Y end end)(3))(5)
  \(\smashedrightarrow{\theta}\) 3 + (fun(Y) \(\smashedrightarrow{\iota}\) Y end)(5)
  \(\smashedrightarrow{\iota}\) 3 + 5 \(=\) 8.
\end{alltt}
Évidemment, ce codage n'est pas intéressant en pratique, parce que le
nombre d'appels de fonctions est plus élevé que si nous utilisions une
structure de donnée. Son principal intérêt est de montrer le pouvoir
théorique d'expression des fonctions d'ordre supérieur.

\paragraph{Codage fonctionnel des piles}

Pour comprendre mieux la nature des piles en tant que structures de
données, nous pouvons les coder avec seulement des fonctions d'ordre
supérieur. Une pile peut être vue comme une infrastructure, une sorte
de conteneur inerte pour des données sur lequel les fonctions peuvent
opérer. Une autre possibilité consiste à la voir comme une composition
de fonctions qui contiennent des données en argument et qui attendent
d'être appelées pour \emph{faire} quelque chose avec. La différence
entre les deux points de vue n'est pas une dichotomie imaginaire entre
données et fonctions, qui est estompée dans les langages à objets
aussi, mais le fait que les fonctions d'ordre supérieur \emph{à elles
  seules} peuvent remplacer les piles.

Puisque nous savons déjà comment coder une paire avec des fonctions
d'ordre supérieur, une première approche pour coder une pile avec des
fonctions est de simplement coder d'abord la pile par des
paires. Abstraitement, une pile est soit vide ou construite en
empilant une valeur sur une autre pile, donc tout ce dont nous avons
besoin est de traduire ces deux concepts. La pile vide peut être
facilement représentée par le \(0\)-uplet \erlcode{\{\}} et l'empilage
devient l'accouplement:
\begin{verbatim}
push(X,S) -> {X,S}.
\end{verbatim}
Ce codage a été présenté à la \fig~\vref{fig:tuple_vs_stack} pour
économiser de la mémoire avec les accumulateurs linéaires. Ici, nous
voulons aller plus loin et nous débarrasser des paires elles-mêmes par
le biais de leur interprétation fonctionnelle vue plus haut, donc
\erlcode{push/2} devient un renommage de \erlcode{mk\_pair/2}:
\begin{alltt}
push(X,S) -> fun(Pr) -> Pr(X,S) end.\hfill% \emph{Voir} mk_pair/2
\end{alltt}
Pour comprendre le statut de la pile vide, nous devons considérer les
projections de piles: une pour le sommet (appelé \emph{head} en
anglais) et une pour la sous-pile immédiate (appelée \emph{tail} en
anglais). Nous les réalisons comme les versions originelles de
\erlcode{fst/2} et \erlcode{snd/2}, où~\erlcode{S},
\erlcode{H}~et~\erlcode{T} dénotent, respectivement, le codage d'une
pile, le sommet et la sous-pile:
\begin{alltt}
head(S) -> S(fun(H,\_) -> H end).\hfill% \emph{Voir} fst/2
tail(S) -> S(fun(\_,T) -> T end).\hfill% \emph{Voir} snd/2
\end{alltt}
Réfléchissons maintenant à la manière dont une pile vide est
utilisée. C'est une pile telle que toute projection de son contenu
supposé échoue, c'est-à-dire que la projection de la première
composante (le sommet) échoue et la projection de la seconde
composante (la sous-pile immédiate) aussi. Un truc consiste à définir
\begin{alltt}
empty() -> fail.\hfill% \emph{L'atome} fail \emph{est arbitraire}
\end{alltt}
Ce qui importe est que \erlcode{empty/0} ne prend aucun argument, donc
l'appeler avec un argument échoue, comme \erlcode{head(fun
  empty/0)}. Par exemple, la pile \erlcode{[a,b,c]} est codée ainsi:
\begin{center}
\erlcode{push(a,push(b,push(c,fun empty/0))).}
\end{center}
La solution repose sur l'\emph{arité}, c'est-à-dire le nombre de
paramètres, de \erlcode{empty/0} pour échouer. Cet échec est
consistant avec la façon dont les piles classiques, à savoir les
structures de données, sont utilisées. En effet, si
\erlcode{tail([\_|S]) -> S}, alors l'appel \erlcode{tail([])} échoue
par manque de clause qui le filtre. La limitation de ce codage est
que, étant fondé sur des fonctions, les piles codées ne peuvent être
filtrées par les motifs des clauses. Par exemple, la fonction
\erlcode{ctail/1} \vpageref{code_ctail} \verbatiminput{ctail.def} ne
peut être codée parce que nous aurions besoin d'une manière de
vérifier si une pile codée est vide sans pour autant faire échouer le
programme si elle ne l'est pas. Si nous préférons plutôt que
l'appelant soit gentiment informé du problème, donc si nous voulons
que les définitions des projections soient complètes, nous pourrions
permettre à \erlcode{empty/1} de prendre une projection qui est alors
écartée:
\begin{verbatim}
empty(_) -> fail.
\end{verbatim}
Nous aurions la réécriture \erlcode{head(fun empty/1) \(\rightarrow\)
  fail}, qui n'est pas un échec du point de vue de l'environnement
d'exécution, mais est interprétée par l'application comme un échec
\emph{logique}. Bien sûr, l'appelant doit prendre la responsabilité de
s'assurer que l'atome \erlcode{fail} est retourné et le constructeur
de pile doit faire en sorte de ne pas empiler cet atome dans la pile
codée, sinon un appelant confondrait la pile vide avec un
élément. (Une meilleure solution consiste à employer des
\emph{exceptions}.)

\mypar{Combinateurs de point fixe}
\index{langage fonctionnel!Erlang@\Erlang!récursivité locale|(}
\index{langage fonctionnel!$\sim$ d'ordre supérieur!combinateur de
  point fixe|(}

De nombreuses fonctions ont besoin d'auxiliaires pour mener à bien des
tâches secondaires ou discrètes. Par exemple, considérons la
\fig~\vref{fig:len0} où \erlcode{len0/2} est la fonction
auxiliaire. Pour interdire son usage en dehors de la portée du module,
elle doit être omise dans la clause \erlcode{-export} dans l'en-tête,
mais elle pourrait toujours être appelée depuis l'intérieur du module
où elle est définie. Pour éviter cela aussi, les fonctions anonymes
sont utiles:
\begin{alltt}
len0(S) ->
  Len = fun(   [],N) -> N;
           ([\_|S],N) -> \textbf{Len}(S,N+1)\hfill% \emph{Ne compile pas}
        end,
  Len(S,0).
\end{alltt}
Ceci restraint la visibilité de la fonction anonyme liée à la variable
\erlcode{Len} au corps de \erlcode{len0/1}, ce qui est exactement ce
que nous voulions. Le problème ici est que cette définition est
rejetée par le compilateur \Erlang parce que
l'affectation~(\erlcode{=}) ne rend pas la variable du membre gauche
visible dans le membre droit, donc \erlcode{Len}~est inconnue dans
l'appel \erlcode{Len(S,N+1)}. Dans certains autres langages
fonctionnels, il existe une construction spécifique pour permettre des
définitions récursives locales, comme nous tentons de le faire, par
exemple \erlcode{let~rec} en \OCaml, mais l'hypotypose suivante est
néanmoins théoriquement pertinente. Le problème originel en devient un
autre: comment pouvons-nous définir des fonctions anonymes
\emph{récursives}?

Un contournement est de passer un paramètre fonctionnel additionnel,
qui est utilisé en lieu et place de l'appel récursif:
\begin{alltt}
len1(S) -> Len = fun(_,   [],N) -> N;
                    (\textbf{F},[\_|S],N) -> \textbf{F}(\textbf{F},S,N+1)
                 end,
           Len(\textbf{Len},S,0).
\end{alltt}
Remarquons que nous avons renommé \erlcode{len0/1} en \erlcode{len1/1}
parce que nous allons envisager plusieurs variantes. De plus, la
fonction anonyme n'est pas équivalente à \erlcode{len/2} parce qu'elle
prend trois arguments. Par ailleurs, le compilateur émet les
avertissements suivants (nous avons écarté le numéro de ligne):
\begin{center}
\emph{\texttt{Warning: variable 'S' shadowed in 'fun'.}}
\end{center}
Ce qui signifie: «~Avertissement: la variable \erlcode{S} est occultée
par \erlcode{fun}.~» Nous avons déjà vu cela auparavant,
\vpageref{shadowing}. Ici, l'occultation est bénigne, parce qu'à
l'intérieur de la fonction anonyme dénotée par~\erlcode{Len}, la
valeur originelle de~\erlcode{S}, à savoir, l'argument de
\erlcode{len1/1}, n'est pas nécessaire. Néanmoins, pour plus de
tranquillité d'esprit, un simple renommage nous débarrassera de cet
avertissement:
\begin{alltt}
len1(S) -> Len = fun(_,   [],N) -> N;
                    (F,[\_|\textbf{T}],N) -> F(F,\textbf{T},N+1)\hfill% \emph{Renommage}
                 end,
           Len(Len,S,0).
\end{alltt}
Nous pouvons altérer cette définition en curryfiant la fonction
anonyme et en la renommant de telle sorte que \erlcode{Len}~équivaille
alors à \erlcode{fun len/2}:
\begin{alltt}
len2(S) -> H = \textbf{fun(F) ->} fun(   [],N) -> N;
                            ([\_|T],N) -> \textbf{(F(F))}(T,N+1)
                         end
               \textbf{end},
           Len = H(H),\hfill% \emph{Équivaut à} fun len/2
           Len(S,0).
\end{alltt}
Définissons une fonction \erlcode{u/1} qui auto-applique son argument
fonctionnel et nous laisse l'utiliser à la place de \erlcode{F(F)}:
\begin{alltt}
u(F) -> fun(X,Y) -> (F(F))(X,Y) end.\hfill% \emph{Auto-application}

len3(S) -> H = fun(F) -> fun(   [],N) -> N;
                            ([\_|T],N) -> \textbf{(u(F))}(T,N+1)
                         end
               end,
           (H(H))(S,0).\hfill% Len \emph{expansée}
\end{alltt}
Remplaçons maintenant \erlcode{u(F)} par~\erlcode{F}. Cette
transformation ne préserve pas la sémantique de~\erlcode{H}, donc
renommons la fonction résultante~\erlcode{G} et nous
redéfinissons~\erlcode{H} pour la rendre équivalente à sa précédente
instance:
\begin{alltt}
len3(S) -> G = fun(F) -> fun(   [],N) -> N;
                            ([_|T],N) -> F(T,N+1)
                         end
               end,
           \textbf{H = fun(F) -> G(u(F)) end},
           (H(H))(S,0).
\end{alltt}
L'aspect intéressant est que la fonction anonyme référencée par la
variable~\erlcode{G} est très similaire à~\erlcode{Len} au début. (Il
peut sembler paradoxal de parler de fonctions anonymes avec des noms,
mais, en \Erlang, les variables et les noms de fonctions sont deux
catégories syntaxiques distinctes, donc il n'y a pas de contradiction
dans les termes.) La voici à nouveau:
\begin{alltt}
len0(S) ->
 Len = fun(   [],N) -> N;
          ([\_|S],N) -> Len(S,N+1)\hfill% \emph{Malheureusement invalide}
       end,
 Len(S,0).
\end{alltt}
La différence est que \erlcode{G}~abstrait sur~\erlcode{F} au lieu de
prendre part à un appel récursif (problématique). Expansons l'appel à
\erlcode{u(F)} et défaisons-nous de~\erlcode{u/1}:
\begin{alltt}
len4(S) ->
  G = fun(F) -> fun(   [],N) -> N;
                   ([\_|T],N) -> F(T,N+1)
                end
      end,
  H = fun(F) -> G(\textbf{fun(X,Y) -> (F(F))(X,Y) end}) end,
  (H(H))(S,0).
\end{alltt}
Pour gagner en généralité, nous pouvons extraire les affectations à~\erlcode{H} et~\erlcode{Len}, les mettre dans une nouvelle fonction
\erlcode{x/1} et expanser \erlcode{Len} à la place:
\begin{alltt}
\textbf{x(G) -> H=fun(F) -> G(fun(X,Y)->(F(F))(X,Y) end) end, H(H).}

len5(S) -> G = fun(F) -> fun(   [],N) -> N;
                            ([\_|T],N) -> F(T,N+1)
                         end
               end,
           (x(G))(S,0).
\end{alltt}
En mettant la définition de \erlcode{x/1} dans un module dédié, nous
pouvons maintenant aisément définir une fonction anonyme récursive. Il
y a une limitation, ceci dit, qui est que \erlcode{x/1} est liée à
l'arité de~\erlcode{F}. Par exemple, nous ne pouvons l'utiliser pour
la factorielle:
\begin{alltt}
fact(N) -> G = fun(F) -> fun(0) -> 1;
                            (N) -> N * F(N-1)
                         end
               end,
           (x(G))(S,0).\hfill% \emph{Arité différente}
\end{alltt}
Par conséquent, si nous voulons réellement un schéma général, nous
devrions travailler avec des fonctions totalement curryfiées, donc
toutes les fonctions sont unaires:
\begin{alltt}
x(G) -> H = fun(F) -> G(fun(\textbf{X}) -> (F(F))(\textbf{X}) end) end, H(H).

len6(S) -> G=fun(F) -> fun(N) -> fun(   []) -> N;
                                    ([\_|T]) -> (F(N+1))(T)
                                 end
                       end
             end,
           ((x2(G))(0))(S).
\end{alltt}
Remarquons que nous avons échangé l'ordre de la pile et l'entier,
puisqu'il n'y a pas de filtrage de motif à faire dans le second
cas. La grammaire d'\Erlang nous oblige à mettre des parenthèses
autour de chaque appel de fonction qui résulte en une fonction
immédiatement appelée, donc appeler des fonctions totalement
curryfiées avec tous leurs arguments, comme \erlcode{((x2(G))(0))(S)},
devient vite fastidieux, bien qu'un bon éditeur de texte peut nous
aider à associer correctement les parenthèses.

\emph{L'argument théorique de cette dérivation est que nous pouvons
  toujours écrire une fonction non-récursive équivalente à une
  fonction récursive donnée,} puisque même \erlcode{x/1} n'est pas
récursive. En fait, rien de spécial n'est exigé tant que les appels de
fonctions ne sont pas restreints. Certains langages fortement et
statiquement typés, comme \OCaml, rejettent la définition
de~\erlcode{x/1} ci-dessus, mais d'autres définitions, bien que plus
compliquées, sont possibles. (Dans le cas d'\OCaml, l'option
\erlcode{-rectypes} permet la compilation de l'exemple précédent, ceci
dit.) Si nous nous autorisons l'usage de la récursivité, que nous
n'avons jamais banni, nous pouvons en fait écrire une définition plus
simple de~\erlcode{x/1}, appelée \erlcode{y/1}:
\begin{alltt}
y(F) -> fun(X) -> (F(y(F)))(X) end.\hfill% \emph{Récursive}
\end{alltt}
Cette définition est en fait très facile à trouver, car elle repose
sur l'équivalence suivante, pour tout~\erlcode{X}:
\begin{equation*}
\erlcode{(y(F))(X)} \equiv \erlcode{(F(y(F)))(X)},
\end{equation*}
Si nous supposons la propriété mathématique \(\forall x.f(x) = g(x)
\Rightarrow f = g\), l'équivalence précédente mène à
\begin{equation*}
\erlcode{y(F)} \equiv \erlcode{F(y(F))},
\end{equation*}
qui, par définition, montre que \erlcode{y(F)} est un point fixe
de~\erlcode{F}. Attention à
\begin{alltt}
y(F) -> F(y(F)).\hfill% \emph{Boucle infinie}
\end{alltt}
qui ne termine pas parce que l'appel \erlcode{y(\(F\))} évaluerait
\emph{immédiatement} l'appel \erlcode{y(\(F\))} dans le
corps. Certains langages fonctionnels reposent sur une stratégie
d'évaluation différente de celle d'\Erlang et ne commencent pas
toujours par évaluer les arguments, ce qui pourrait rendre correcte la
définition précédente. Un autre exemple:
\begin{verbatim}
fact(N) -> F = fun(F) -> fun(A) -> fun(0) -> A;
                                      (M) -> (F(A*M))(M-1)
                                   end
                         end
               end,
           ((y(F))(1))(N).
\end{verbatim}
La technique que nous avons développée dans les lignes précédentes
peut être employée pour réduire la quantité de pile de contrôle
utilisée par certaines fonctions. Par exemple, considérons
\begin{verbatim}
cat(   [],T) -> T;
cat([X|S],T) -> [X|cat(S,T)].
\end{verbatim}
Remarquons que le paramètre~\erlcode{T} est passé, inchangé, tout au
long des appels jusqu'à ce que le premier argument soit vide. Ceci
signifie qu'une référence à la pile~\erlcode{T} originelle est
dupliquée à chaque réécriture jusqu'à la dernière, parce que la
définition n'est pas en forme terminale. Pour éviter cela, nous
pourrions employer une fonction récursive anonyme qui lie~\erlcode{T}
non comme un paramètre mais dans la portée englobante:
\begin{alltt}
cat(S,\textbf{T}) -> G = fun(F) -> fun(   []) -> \textbf{T};\hfill% T \emph{visible}
                             ([X|U]) -> [X|F(U)]
                          end
                end,
            (y(G))(S).
\end{alltt}
Cette transformation est appelée
\emph{lambda-dropping} en anglais\index{langage
  fonctionnel!lambda-dropping@$\lambda$-dropping}, et son inverse
\emph{lambda-lifting}\index{langage
  fonctionnel!lambda-lifting@$\lambda$-lifting}. La fonction
\erlcode{y/1} est appelée le \emph{combinateur de point fixe~Y}.

Nous souhaitons parfois définir deux fonctions anonymes mutuellement
récursives. Considérons l'exemple suivante, qui est en pratique
inutile et inefficace, mais il est suffisamment simple pour illustrer
notre argument.
\begin{verbatim}
even(0) -> true;
even(N) -> odd(N-1).

odd(0) -> false;
odd(N) -> even(N-1).
\end{verbatim}
Disons que nous ne voulons pas que \erlcode{even/1} puisse être
appelée depuis une fonction autre que \erlcode{odd/1}. Cela veut dire
que nous voulons le patron suivant:
\begin{alltt}
odd(I) -> Even = fun(\fbcode{CCC}) -> \fbcode{CCCCC} end,
          Odd  = fun(\fbcode{CCC}) -> \fbcode{CCCCC} end,
          Odd(I).
\end{alltt}
où \erlcode{Even} et \erlcode{Odd} dépendent l'une de l'autre. Par la
forme de notre canevas, nous voyons que \erlcode{Even} ne peut appeler
\erlcode{Odd}. La technique pour permettre la récursivité mutuelle
consiste à abstraire la première fonction en fonction de la seconde,
c'est-à-dire que \erlcode{Even} devient une fonction dont le paramètre
est une fonction destinée à être utilisée comme \erlcode{Odd}:
\begin{alltt}
odd(I) -> Even = fun(\textbf{Odd}) -> fun(0) -> true;
                                (N) -> \textbf{Odd}(N-1)
                             end
                 end,
          Odd  = fun(\fbcode{CCC}) -> \fbcode{CCCCC} end,
          Odd(I).
\end{alltt}
La prochaine étape est plus délicate. Nous pouvons commencer
na\"{\i}vement, ceci dit, et laisser le problème surgir de lui-même:
\begin{alltt}
odd(I) -> Even = fun(\textbf{Odd}) -> fun(0) -> true;
                                (N) -> \textbf{Odd}(N-1)
                             end
                 end,
          Odd  = fun(0) -> false;
                    (N) -> (Even(\fbox{Odd}))(N-1)
                 end,
          Odd(I).
\end{alltt}
Le problème n'est pas nouveau et nous savons déjà comment définir une
fonction anonyme récursive en abstrayant sur l'appel récursif et en
passant la fonction résultante au combinateur de point fixe~Y:
\begin{alltt}
odd(I) -> Even = fun(Odd) -> fun(0) -> true;
                                (N) -> Odd(N-1)
                             end
                 end,
          Odd  = \textbf{y(fun(F) ->} fun(0) -> false;
                                (N) -> (Even(\textbf{F}))(N-1)
                             end
                   \textbf{end)},
          Odd(I).
\end{alltt}
La technique présentée ici permet la récursivité locale en \Erlang et
est intéressante au-delà de la compilation, comme l'ont montré
\cite{GoldbergWiener_2009}. Les combinateurs de point fixe peuvent
aussi être mis en {\oe}uvre dans les langages impératifs, comme
\Clang:
\begin{alltt}
\textbf{#include}<stdio.h>
\textbf{#include}<stdlib.h>

\textbf{typedef int} (*fp)();

\textbf{int} fact(fp f, \textbf{int} n) \{
  \textbf{return} n? n * ((\textbf{int} (*)(fp,\textbf{int}))f)(f,n-1) : 1; \}

\textbf{int} read(\textbf{int} dec, \textbf{char} arg[]) \{
  \textbf{return} ('0' <= *arg && *arg <= '9')?
         read(10*dec+(*arg - '0'),arg+1) : dec; \}

\textbf{int main}(\textbf{int} argc, \textbf{char}** argv) \{
  \textbf{if} (argc == 2)
     printf("%u\textbackslash{n}",fact(&fact,read(0,argv[1])));
  \textbf{else} printf("Un entier seulement.\textbackslash{n}");
  \textbf{return} 0;
\}
\end{alltt}
\index{langage fonctionnel!$\sim$ d'ordre supérieur!combinateur de
  point fixe|)}
\index{langage fonctionnel!Erlang@\Erlang!récursivité locale|)}

\mypar{Continuations}
\index{langage fonctionnel!$\sim$ d'ordre supérieur!continuations|(}

À la section~\ref{sec:into_tail_form}, la transformation en forme
terminale est appliquée à des programmes de premier ordre, à savoir
ceux sans fonctions d'ordre supérieur, et le résultat est un programme
du premier ordre aussi. Ici, nous expliquons brièvement une
transformation en forme terminale qui produit des fonctions d'ordre
supérieur \emph{avec continuations} (anglais,
\emph{continuation-passing style}, ou CPS). Le principal avantage est
que les programmes sont plus courts. Le premier exemple était
\erlcode{flat/1}: \verbatiminput{flat.def} En appliquant l'algorithme
de la section~\ref{sec:into_tail_form}, la forme terminale était
\begin{verbatim}
flat_tf(T)         -> flat(T,[]).
flat(       [],A)  -> appk([],A);
flat(   [[]|T],A)  -> flat(T,A);
flat([[X|S]|T],A)  -> flat([X,S|T],A);
flat(    [Y|T],A)  -> flat(T,[{k1,Y}|A]).

appk(V,        []) -> V;
appk(V,[{k1,Y}|A]) -> appk([Y|V],A).
\end{verbatim}
(C'est la version utilisant un accumulateur linéaire au lieu de
\(n\)-uplets imbriqués.) L'idée directrice consiste à ajouter une
pile~\erlcode{A} qui accumule les variables de tous les contextes
d'appel, chaque occurrence étant distinguée, et une fonction
auxiliaire \erlcode{appk/2} reconstruit les contextes.

L'idée qui soutient le \emph{style avec continuations}\index{style avec
  continuations|see{langage fonctionnel, $\sim$ d'ordre supérieur,
    continuations}} est de ne pas séparer les variables des contextes
et la reconstruction de ces derniers. À la place, nous sauvegardons
une fonction, à savoir une \emph{continuation}, qui correspond à une
clause de \erlcode{appk/1} reconstruisant un contexte. De cette
manière, il n'y a pas besoin de \erlcode{appk/1}. Tout d'abord, tout
comme nous avions créé un accumulateur vide, une continuation initiale
est nécessaire. Pour le moment, nous allons la laisser de côté. Tout
comme un argument supplémentaire a été ajouté pour recevoir
l'accumulateur, un argument additionnel est ajouté pour la
continuation:
\begin{alltt}
\textbf{flat\_k(T)           -> flat\_k(T,\fbcode{CCCCCCCCC}\,).}
flat\_k(       [],\textbf{K}) -> [];\hfill% K \emph{inutile pour le moment}
flat\_k(   [[]|T],\textbf{K}) -> flat\_k(T,\textbf{K});
flat\_k([[X|S]|T],\textbf{K}) -> flat\_k([X,S|T],\textbf{K});
flat\_k(    [X|T],\textbf{K}) -> [X|flat\_k(T,\textbf{K})].
\end{alltt}
Tout comme précédemment, chaque membre droit est examiné à tour de
rôle. S'il ne contient aucun appel, l'expression (où \erlcode{appk/2}
était appelée) est appliquée à la continuation~\erlcode{K}:
\begin{alltt}
flat\_k(       [],K) -> \textbf{K([])};
\end{alltt}
Si c'est un appel en forme terminale, rien n'est fait, tout comme
avant:
\begin{alltt}
flat\_k(   [[]|T],K) -> flat\_k(T,K);
flat\_k([[X|S]|T],K) -> flat\_k([X,S|T],K);
\end{alltt}
Si le membre droit n'est pas en forme terminale, nous identifions le
premier appel à évaluer. Ici, il n'y en a qu'un:
\erlcode{flat\_k(T,K)}. Maintenant, voici la principale différence
avec la transformation originelle. Au lieu d'extraire les variables du
contexte et de produire une clause de \erlcode{appk/2} reconstruisant
ce contexte, nous passons à l'appel une nouvelle continuation qui
applique le contexte en question au résultat de l'appel et ensuite
appelle~\erlcode{K}, comme \erlcode{appk/2} était appelée
récursivement:
\begin{alltt}
flat\_k(    [X|T],K) -> flat\_k(T,\textbf{fun(V) -> K([X|V]) end}).
\end{alltt}
Finalement, nous devons déterminer qu'elle est la contrepartie de
l'accumulateur vide. Plus précisément, nous voulons trouver un
équivalent à \erlcode{appk(V,[]) -> V.} C'est-à-dire que nous désirons
une continuation telle que, prenant~\erlcode{V}, elle
retourne~\erlcode{V}: il s'agit donc de l'identité. Nous avons
maintenant complété la transformation en style avec continuations:
\begin{alltt}
flat\_k(T)           -> flat\_k(T,\textbf{fun(V) -> V end}).
flat\_k(       [],K) -> K([]);
flat\_k(   [[]|T],K) -> flat\_k(T,K);
flat\_k([[X|S]|T],K) -> flat\_k([X,S|T],K);
flat\_k(    [X|T],K) -> flat\_k(T,fun(V) -> K([X|V]) end).
\end{alltt}
Le nombre de réécritures est le même qu'avec \erlcode{flat\_tf/1}; le
principal intérêt est que le programme engendré est plus court, car
chaque clause de \erlcode{appk/2} est codée ici par une fonction
anonyme dans chaque membre droit qui n'est pas en forme
terminale. (Remarquons qu'il est conventionnel de nommer les
continuations avec la lettre~\erlcode{K}.)

Examinons un autre exemple du même genre, \erlcode{flat0/1}:
\verbatiminput{flat0.def} La forme terminale du premier ordre était:
\begin{verbatim}
flat0_tf(T)          -> flat0(T,[]).
flat0(         [],A) -> appk([],A);
flat0(     [[]|T],A) -> flat0(T,A);
flat0([Y=[_|_]|T],A) -> flat0(Y,[{k1,T}|A]);
flat0(    [Y|T],A)   -> flat0(T,[{k34,Y}|A]).
cat(   [],T,A)       -> appk(T,A);
cat([X|S],T,A)       -> cat(S,T,[{k34,X}|A]).
appk(V,[{k34,Y}|A])  -> appk([Y|V],A);
appk(V, [{k2,W}|A])  -> cat(W,V,A);
appk(V, [{k1,T}|A])  -> flat0(T,[{k2,V}|A]);
appk(V,         [])  -> V.
\end{verbatim}
À nouveau, pour illustration, nous utilisons la version non-optimisée
sans \(n\)-uplets codant l'accumulateur. Tout d'abord, nous injectons
la continuation identité:
\begin{alltt}
flat0\_k(T) -> flat0\_k(T,\textbf{fun(V) -> V end}).
\end{alltt}
Le membre droit de la première clause de \erlcode{flat0/1}
ne contient aucun appel donc nous l'appliquons à la continuation
courante:
\begin{alltt}
flat0\_k(         [],K) -> \textbf{K([])};
\end{alltt}
Le membre droite de la deuxième clause de \erlcode{flat0/1} est en
forme terminale, donc sa transformée simplement transmet la
continuation courante:
\begin{alltt}
flat0\_k(     [[]|T],K) -> flat0\_k(T,\textbf{K});
\end{alltt}
La troisième clause est plus compliquée parce qu'elle contient trois
appels. Décidons que le premier à évaluer est
\erlcode{flat0(Y)}. (\Erlang ne spécifie pas l'ordre d'évaluation des
arguments.) Nous commençons par mettre en place le cadre de la
nouvelle continuation:
\begin{alltt}
flat0\_k([Y=[\_|\_]|T],K) -> flat0\_k(Y,\textbf{fun(V) -> \fbcode{HHHHH} end});
\end{alltt}
Le paramètre~\erlcode{V} sera lié, quand la nouvelle continuation sera
appelée, à la valeur de \erlcode{flat0(Y)}. Par suite, nous devons
évaluer l'appel \erlcode{flat0(T)}, donc nous posons
\begin{alltt}
flat0\_k([Y=[\_|\_]|T],K) ->
  flat0\_k(Y,fun(V) -> \textbf{flat0\_k(T,fun(W) -> \fbcode{HHHHH} end)} end);
\end{alltt}
Nous devons préparer l'appel futur à \erlcode{cat/2}, qui doit aussi
être transformé en style avec continuations. Ce qui doit être
concaténé sont les valeurs de \erlcode{flat0(Y)} et
\erlcode{flat0(T)}. La première sera liée par le paramètre~\erlcode{V}
et la seconde par~\erlcode{W}, donc:
\begin{alltt}
flat0\_k([Y=[\_|\_]|T],K) ->
  flat0\_k(Y,fun(V) ->
              flat0\_k(T,fun(W) -> \textbf{cat\_k(V,W,\fbcode{HHH}\,)} end) end);
\end{alltt}
Finalement, nous devons mettre à contribution la
continuation~\erlcode{K}: «~Appeler~\erlcode{K} avec la valeur de
\erlcode{cat(flat0(Y),flat0(T))}.~» Parvenu à ce point, nous ne
connaissons pas la valeur de cet appel, donc nous devons
passer~\erlcode{K} à \erlcode{cat\_k/3}, qui connaîtra cette valeur:
\begin{alltt}
flat0\_k([Y=[\_|\_]|T],K) ->
  flat0\_k(Y,fun(V) ->
              flat0\_k(T,fun(W) -> cat\_k(V,W,\textbf{K}) end) end);
\end{alltt}
Maintenant, nous devons transformer \erlcode{cat\_k/3} en style avec
continuations. La définition originelle de \erlcode{cat/2} est
\begin{verbatim}
cat(   [],T) -> T;
cat([X|S],T) -> [X|cat(S,T)].
\end{verbatim}
Nous avons alors
\begin{alltt}
cat\_k(   [],T,K) -> \textbf{K(T)};
cat\_k([X|S],T,K) -> cat\_k(S,\textbf{fun(V) -> K([X|V]) end}).
\end{alltt}
Remarquons que nous n'avions pas à introduire une continuation
identité, car il n'y a qu'un appel à \erlcode{cat\_k/3}. Il reste à
transformer la dernière clause de \erlcode{flat0/2}, qui contient un
appel dont le contexte est \erlcode{[Y|\textvisiblespace]}:
\begin{alltt}
flat0\_k(T)             -> flat0\_k(T,fun(V) -> V end).
flat0\_k(         [],K) -> K([]);
flat0\_k(     [[]|T],K) -> flat0\_k(T,K);
flat0\_k([Y=[_|_]|T],K) ->
  flat0\_k(Y,fun(V) ->
              flat0\_k(T,fun(W) -> cat\_k(V,W,K) end) end);
flat0\_k(      [Y|T],K) -> flat0\_k(T,\textbf{fun(V) -> [Y|V] end}).

cat\_k(   [],T,K) -> K(T);
cat\_k([X|S],T,K) -> cat\_k(S,fun(V) -> K([X|V]) end).
\end{alltt}
Toutes les fonctions sont désormais en forme terminale, car une
continuation est une fonction anonyme, donc une valeur.

Notre prochain exemple est \erlcode{fib/1}, la réalisation simple mais
inefficace de la fonction de Fibonacci:
\begin{verbatim}
fib(0) -> 1;
fib(1) -> 1;
fib(N) -> fib(N-1) + fib(N-2).
\end{verbatim}
La version en style avec continuations est
\begin{verbatim}
fib_k(N)   -> fib_k(N,fun(V) -> V end).
fib_k(0,K) -> K(0);
fib_k(1,K) -> K(1);
fib_k(N,K) ->
  fib_k(N-1,fun(V) -> fib_k(N-2,fun(W) -> K(V+W) end) end).
\end{verbatim}

\index{arbre binaire de recherche!insertion de feuilles|(} Le style
avec continuations est aussi intéressant parce qu'il permet
d'identifier certaines possibilités d'optimisation
\citep{Danvy_2004}. Le dessein de \fun{sfst\(_0\)/2} à la
\fig~\vref{fig:sfst0} était motivé par la nécessité de partager
l'entrée au cas où l'élément recherché était absent. Cette sorte
d'amélioration est fréquente dans les algorithmes qui combinent une
recherche et une mise à jour locale optionnelle. Par exemple,
considérons à nouveau l'insertion de feuilles \emph{sans doublons}
dans un arbre binaire de recherche\index{arbre binaire de recherche} à
la \fig~\vref{fig:insl0}:
\begin{alltt}
insl0(Y,\{bst,X,T1,T2\}) when X > Y -> \{bst,X,insl0(Y,T1),T2\};
insl0(Y,\{bst,X,T1,T2\}) when Y > X -> \{bst,X,T1,insl0(Y,T2)\};
insl0(Y,          ext)            -> \{bst,Y,ext,ext\};
insl0(Y,            T)            -> T.
\end{alltt}
Au cas où \erlcode{Y}~est présent dans l'arbre, la dernière clause
partagera le sous-arbre sous l'occurrence trouvée de~\erlcode{Y} dans
l'arbre d'entrée, mais les deux premières clauses, correspondant à la
phase de recherche, dupliquerons tous les n{\oe}uds de la racine
à~\erlcode{Y} (exclue). Ceci peut être évité en passant d'appel en
appel l'arbre originel et en transformant la fonction en forme
terminale, de telle sorte que si~\erlcode{Y} est trouvée, l'entrée
complète est partagée et l'évaluation s'interrompt immédiatement (pas
de contextes en attente).

D'abord, transformons la définition en style avec continuations
(nouvelles continuations en gras):
\begin{alltt}
insl0(Y,T)               -> insl0(Y,T,\textbf{fun(V) -> V end}).
insl0(Y,\{bst,X,T1,T2\},K) when X > Y ->
\hfill{}insl0(T1,Y,\textbf{fun(V) -> K(\{bst,X,V,T2\}) end});
insl0(Y,\{bst,X,T1,T2\},K) when Y > X ->
\hfill{}insl0(T2,Y,\textbf{fun(V) -> K(\{bst,X,T1,V\}) end});
insl0(Y,          ext,K) -> K(\{bst,Y,ext,ext\});
insl0(Y,            T,K) -> K(T).
\end{alltt}
Puis nous passons partout l'arbre de recherche originel~\erlcode{T}
(renommé~\erlcode{U}):
\begin{alltt}
insl0(Y,T)                 -> insl0(TmT,fun(V) -> V end,\textbf{T}).
insl0(Y,\{bst,X,T1,T2\},K,\textbf{U}) when X > Y ->
\hfill{}insl0(T1,Y,fun(V) -> K(\{bst,X,V,T2\}) end,\textbf{U});
insl0(Y,\{bst,X,T1,T2\},K,\textbf{U}) when Y > X ->
\hfill{}insl0(T2,Y,fun(V) -> K(\{bst,X,T1,V\}) end,\textbf{U});
insl0(Y,          ext,K,\textbf{U}) -> K(\{bst,Y,ext,ext\});
insl0(Y,            T,K,\textbf{U}) -> K(T).
\end{alltt}
Finalement, nous laissons de côté la continuation dans la dernière
clause de \erlcode{insl0/4} et le membre droit partage l'entrée:
\begin{alltt}
insl0(Y,T)                 -> insl0(Y,T,fun(V) -> V end,T).
insl0(Y,\{bst,X,T1,T2\},K,U) when X > Y ->
\hfill{}insl0(T1,Y,fun(V) -> K(\{bst,X,V,T2\}) end,U);
insl0(Y,\{bst,X,T1,T2\},K,U) when Y > X ->
\hfill{}insl0(T2,Y,fun(V) -> K(\{bst,X,T1,V\}) end,U);
insl0(Y,          ext,K,U) -> K(\{bst,Y,ext,ext\});
insl0(Y,            T,K,\textbf{U}) -> \textbf{U}.\hfill% \emph{Entrée partagée}
\end{alltt}
Dans les langages fonctionnels qui ont des
\emph{exceptions}\index{langage fonctionnel!Erlang@\Erlang!exception},
comme \Erlang, le même effet peut être obtenu sans continuations:
\begin{alltt}
insl0(Y,T)\hfill{}-> \textbf{try insl\_(Y,T) catch throw:dup -> T end}.
insl\_(Y,\{bst,X,T1,T2\}) when X > Y -> \{bst,X,insl\_(Y,T1),T2\};
insl\_(Y,\{bst,X,T1,T2\}) when Y > X -> \{bst,X,T1,insl\_(Y,T2)\};
insl\_(Y,          ext)            -> \{bst,Y,ext,ext\};
insl\_(Y,            T)            -> \textbf{throw(dup)}.
\end{alltt}
Ce style est préférable à celui avec continuations parce qu'il
préserve presque tout le programme originel («~style
direct~»). Néanmoins, ceci montre que les continuations sont utiles
pour écrire un compilateur, pour éliminer des constructions comme les
exceptions, du moment que les fonctions d'ordre supérieur sont
disponibles \citep{Appel_1992}. Celles-ci, à leur tour, peuvent être
transformées en fonction du premier ordre par
\emph{défonctionnalisation}
\citep{Reynolds_1972,DanvyNielsen_2001}\index{langage
  fonctionnel!$\sim$ d'ordre supérieur!défonctionnalisation}.
\index{arbre binaire de recherche!insertion de feuilles|)}

Les continuations peuvent aussi faire office de patron
conceptuel. Considérons le problème de déterminer si une pile donnée
est un \emph{palindrome}\index{palindrome|(}, c'est-à-dire, si \(s
\equiv \fun{rev}(s)\), étant donnée~\(s\). La tentative na\"{\i}ve
\begin{verbatim}
pal(S) -> S == rev(S).
\end{verbatim}
opère en \(n+2\) réécritures parce que le coût de l'opérateur
(\texttt{==}) n'a pas été compté. De façon interne, ceci dit, ce qui
se passe est que \erlcode{S}~est traversée (complètement si c'est un
palindrome). Si nous ne nous autorisons pas l'usage de l'opérateur
d'égalité sur les piles, nous pourrions essayer
\begin{verbatim}
pal(S)  -> eq(S,rev(S)).
eq(S,S) -> true;
eq(_,_) -> false.
\end{verbatim}
ce qui est de la triche, d'une certaine façon: le motif non-linéaire
\erlcode{eq(S,S)} \index{langage fonctionnel!motif!$\sim$
  non-linéaire} requiert que ses arguments soient traversés, sans
conséquence sur le coût. Si nous abandonnons aussi de tels motifs
portant sur des piles, nous pourrions parvenir à une solution fondée
sur les continuations \citep{DanvyGoldberg_2001}:
\begin{alltt}
pal(S)               -> pal(S,S,fun(\_) -> true end).
pal(    S,     [],K) -> K(S);\hfill% \emph{Longueur paire}
pal([\_|S],    [\_],K) -> K(S);\hfill% \emph{Longueur impaire}
pal([X|S],[\_,\_|T],K) ->
\hfill{}pal(S,T,fun([Y|U]) -> X == Y andalso K(U) end).
\end{alltt}
Nous réutilisons ici une idée que nous avons vue à la
\fig~\vref{fig:tms}: dupliquer la référence à~\erlcode{S} et nous
déplacer dans la seconde copie deux fois plus vite que dans la
première (dernière clause); lorsque nous atteignons la fin de la
seconde copie (première et deuxième clause de \erlcode{pal/3}), la
première contient la seconde moitié de la pile originelle, qui est
appliquée à la continuation courante. La continuation a été construite
en gardant une référence~\erlcode{X} à l'élément courant dans la
première copie et en prévoyant un test d'égalité avec le premier
élément (l'opérateur \erlcode{andalso} est \emph{séquentiel},
c'est-à-dire que si son premier argument a pour valeur
\erlcode{false}, son second argument n'est pas évalué). En effet,
l'idée est de comparer la seconde moitié de la pile originelle avec
les éléments de la première moitié \emph{en ordre inverse}, et c'est
précisément le but de la continuation. Remarquons que la continuation
prend une pile en argument, mais retourne un booléen, à la différence
des usages précédents, où la continuation initiale était l'identité
(comparer avec \erlcode{par/1}). Notons aussi que nous avons déterminé
la parité de la longueur de la pile originelle sans utiliser
d'entiers. Il est facile d'écrire une fonction équivalente du premier
ordre:
\begin{verbatim}
pal0(S)               -> pal0(S,S,[]).
pal0(    S,     [],A) -> eq(S,A);
pal0([_|S],    [_],A) -> eq(S,A);
pal0([X|S],[_,_|T],A) -> pal0(S,T,[X|A]).

eq(   [],   []) -> true;
eq([X|S],[X|T]) -> eq(S,T);
eq(    _,    _) -> false.
\end{verbatim}
La différence est que \erlcode{pal0/3}, plutôt que de construire une
continuation qui retient les éléments de la première moitié et prévoie
un test, elle retourne explicitement la première moitié et la compare
à la seconde moitié au moyen de \erlcode{eq/2}. Le coût de
\erlcode{pal/1} et \erlcode{pal0/1} sont les mêmes. Le coût minimum
est \(\B{\fun{pal}}{n} = \B{\fun{pal0}}{n} = \floor{n/2} + 2\), si
\erlcode{S}~n'est pas un palindrome et la différence est au milieu; le
pire des cas est quand \erlcode{S}~est un palindrome et le coût est
\(\W{\fun{pal}}{n} = \W{\fun{pal}_0}{n} = 2\floor{n/2} +
1\).\index{palindrome|)} Une comparaison de leur usage de la mémoire
exigerait de définir la taille occupée par une valeur fonctionnelle,
mais il est probable que, dans le cas présent, \erlcode{pal/1} et
\erlcode{pal0/1} utilisent la même quantité de mémoire, donc le choix
de l'une ou de l'autre est purement une question de style; par
exemple, nous pourrions préférer la concision.
\index{suffixe!trouver tous les suffixes}
\index{suffixe|see{recherche de motifs}}

Un autre exemple divertissant est proposé encore par
\cite{Danvy_1988,Danvy_1989}. Le but est de former tous les préfixes
d'un mot, par exemple, \(\erlcode{allp([a,b,c,d])} \twoheadrightarrow
\erlcode{[[a],[a,b],[a,b,c],[a,b,c,d]]}\), et le nom de la fonction,
\erlcode{allp/1}, veut dire «~tous les préfixes~» en anglais (\emph{all
  prefixes}). Trouver tous les suffixes en coût linéaire serait bien
plus facile; en particulier, il est aisé de maximiser le partage de la
mémoire à l'aide d'un synonyme:
\begin{verbatim}
alls(     []) -> [];
alls(S=[_|T]) -> [S|alls(T)].
\end{verbatim}
Le nom \erlcode{alls} veut dire «~tous les suffixes~» en anglais
(\emph{all suffixes}). Nous avons \(\erlcode{alls([a,b,c,d])}
\twoheadrightarrow \erlcode{[[a,b,c,d],[b,c,d],[c,d],[d]]}\) et aussi
\(\C{\fun{alls}}{n} = n + 1\).
\index{préfixe!trouver tous les préfixes}
\index{préfixe|see{recherche de motifs}}
Une solution pour les préfixes, basée sur les continuations:
\begin{verbatim}
allp(S)       -> allp(S,fun(X) -> X end).
allp(   [],_) -> [];
allp([X|S],K) -> [K([X])|allp(S,fun(T) -> K([X|T]) end)].
\end{verbatim}
Une autre solution d'ordre supérieur s'appuie sur une projection
(page~\pageref{par:maps}):
\begin{verbatim}
allp0(   []) -> [];
allp0([X|S]) -> [[X]|map(fun(T) -> [X|T] end,allp0(S))].
\end{verbatim}
Nous avons \(\C{\fun{allp}_0}{n} = (n+1) + \sum_{k=1}^{n-1}k =
\frac{1}{2}n^2 + \frac{1}{2}n + 1\).
\index{langage fonctionnel!$\sim$ d'ordre supérieur!continuations|)}
\index{langage fonctionnel!Erlang@\Erlang|)}
\index{langage fonctionnel!$\sim$ d'ordre supérieur|)}

\paragraph{Exercice}

Écrire une version de \erlcode{allp0/1} du premier ordre.
